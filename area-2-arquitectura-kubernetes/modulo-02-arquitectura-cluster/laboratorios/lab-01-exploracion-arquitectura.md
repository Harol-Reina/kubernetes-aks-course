# Laboratorio 01: ExploraciÃ³n de la Arquitectura del Cluster

## Objetivos

Al finalizar este laboratorio, serÃ¡s capaz de:
- âœ“ Identificar todos los componentes del Control Plane
- âœ“ Inspeccionar Worker Nodes y sus componentes
- âœ“ Verificar la comunicaciÃ³n entre componentes
- âœ“ Entender el flujo de creaciÃ³n de un recurso

## DuraciÃ³n Estimada

â±ï¸ 60-90 minutos

## Pre-requisitos

- Cluster Kubernetes funcional (minikube, kind, o cluster real)
- Acceso SSH a nodos (para clusters multi-nodo)
- `kubectl` configurado
- Permisos de administrador en el cluster

---

## Parte 1: InspecciÃ³n del Control Plane (25 minutos)

### ğŸ“ Ejercicio 1.1: Identificar Componentes del Sistema

**Paso 1:** Lista todos los pods del sistema

```bash
kubectl get pods -n kube-system
```

**Pregunta:** Â¿CuÃ¡ntos pods del `kube-apiserver` existen? Â¿QuÃ© significa esto sobre tu cluster?

<details>
<summary>ğŸ’¡ Pista</summary>
Si ves un solo API Server, es un cluster de un solo master. Si ves varios (3+), es un cluster HA.
</details>

**Paso 2:** Identifica los componentes principales

```bash
kubectl get pods -n kube-system -o wide | grep -E 'etcd|kube-apiserver|kube-scheduler|kube-controller'
```

**Tarea:** Completa la siguiente tabla:

| Componente | NÃºmero de Instancias | Nodo(s) |
|------------|---------------------|---------|
| etcd | | |
| kube-apiserver | | |
| kube-scheduler | | |
| kube-controller-manager | | |

---

### ğŸ“ Ejercicio 1.2: Inspeccionar el API Server

**Paso 1:** ObtÃ©n los detalles del pod del API Server

```bash
# Obtener nombre exacto del pod
API_SERVER_POD=$(kubectl get pods -n kube-system -l component=kube-apiserver -o name | head -1)

# Inspeccionar el pod
kubectl describe -n kube-system $API_SERVER_POD
```

**Preguntas:**
1. Â¿QuÃ© imagen se estÃ¡ usando?
2. Â¿CuÃ¡les son los argumentos principales del comando?
3. Â¿QuÃ© puerto escucha el API Server? (buscar `--secure-port`)

**Paso 2:** Verifica los endpoints del API Server

```bash
kubectl get endpoints kubernetes -o yaml
```

**Pregunta:** Â¿QuÃ© IP(s) aparecen en los endpoints? Â¿Coinciden con los nodos master?

---

### ğŸ“ Ejercicio 1.3: Verificar etcd

**Paso 1:** Identifica el pod de etcd

```bash
kubectl get pods -n kube-system -l component=etcd
```

**Paso 2:** Inspecciona la configuraciÃ³n de etcd

```bash
ETCD_POD=$(kubectl get pods -n kube-system -l component=etcd -o name | head -1)
kubectl describe -n kube-system $ETCD_POD | grep -A 10 "Command:"
```

**Preguntas:**
1. Â¿QuÃ© puerto usa etcd para clientes? (buscar `--listen-client-urls`)
2. Â¿EstÃ¡ configurado para clustering? (buscar `--initial-cluster`)
3. Â¿DÃ³nde estÃ¡ el directorio de datos? (buscar `--data-dir`)

**Paso 3:** (Opcional - solo si tienes acceso al nodo) Verifica el tamaÃ±o de la base de datos

```bash
# Desde dentro del nodo master
sudo du -sh /var/lib/etcd
```

---

### ğŸ“ Ejercicio 1.4: Verificar Scheduler y Controller Manager

**Paso 1:** Verifica quiÃ©n es el lÃ­der del Scheduler

```bash
kubectl get endpoints kube-scheduler -n kube-system -o yaml
```

**Busca en la secciÃ³n `annotations` â†’ `control-plane.alpha.kubernetes.io/leader`**

**Preguntas:**
1. Â¿QuÃ© nodo es actualmente el lÃ­der del Scheduler?
2. Â¿CuÃ¡nto dura el lease? (buscar `leaseDurationSeconds`)

**Paso 2:** Verifica el Controller Manager

```bash
kubectl get endpoints kube-controller-manager -n kube-system -o yaml
```

**Pregunta:** Â¿Es el mismo nodo lÃ­der para Scheduler y Controller Manager, o son diferentes?

---

## Parte 2: InspecciÃ³n de Worker Nodes (25 minutos)

### ğŸ“ Ejercicio 2.1: Listar Nodos

**Paso 1:** Lista todos los nodos del cluster

```bash
kubectl get nodes -o wide
```

**Tarea:** Completa la informaciÃ³n de tus nodos:

| Nombre | Rol | VersiÃ³n | IP Interna | Container Runtime |
|--------|-----|---------|-----------|------------------|
| | | | | |
| | | | | |

**Paso 2:** ObtÃ©n informaciÃ³n detallada de un worker node

```bash
# Reemplaza <node-name> con el nombre de un worker
kubectl describe node <node-name>
```

**Preguntas:**
1. Â¿CuÃ¡nta CPU tiene el nodo? (buscar `Capacity â†’ cpu`)
2. Â¿CuÃ¡nta memoria tiene? (buscar `Capacity â†’ memory`)
3. Â¿CuÃ¡ntos pods puede ejecutar? (buscar `Capacity â†’ pods`)
4. Â¿CuÃ¡ntos pods estÃ¡n corriendo actualmente? (buscar `Non-terminated Pods`)

---

### ğŸ“ Ejercicio 2.2: Inspeccionar kubelet

**Paso 1:** (Requiere acceso SSH al nodo) Verifica el status de kubelet

```bash
# Desde el nodo worker
sudo systemctl status kubelet
```

**Paso 2:** Ver logs de kubelet

```bash
# Desde el nodo worker
sudo journalctl -u kubelet -f
```

**Deja esto corriendo en una terminal**

**Paso 3:** Crea un pod y observa los logs de kubelet

En otra terminal:

```bash
kubectl run test-kubelet --image=nginx --restart=Never
```

**Pregunta:** Â¿QuÃ© eventos ves en los logs de kubelet al crear el pod?

**Limpieza:**
```bash
kubectl delete pod test-kubelet
```

---

### ğŸ“ Ejercicio 2.3: Inspeccionar kube-proxy

**Paso 1:** Lista los pods de kube-proxy

```bash
kubectl get pods -n kube-system -l k8s-app=kube-proxy -o wide
```

**Pregunta:** Â¿CuÃ¡ntos pods de kube-proxy existen? Â¿Por quÃ©?

<details>
<summary>ğŸ’¡ Pista</summary>
kube-proxy corre como DaemonSet, entonces hay uno por cada nodo.
</details>

**Paso 2:** Verifica el modo de kube-proxy

```bash
# Obtener nombre de un pod de kube-proxy
PROXY_POD=$(kubectl get pods -n kube-system -l k8s-app=kube-proxy -o name | head -1)

# Ver logs para encontrar el modo
kubectl logs -n kube-system $PROXY_POD | grep "Using"
```

**Pregunta:** Â¿EstÃ¡ usando iptables o IPVS?

**Paso 3:** (Requiere acceso SSH) Verifica reglas de iptables

```bash
# Desde un nodo
sudo iptables -t nat -L KUBE-SERVICES -n | head -20
```

---

### ğŸ“ Ejercicio 2.4: Inspeccionar Container Runtime

**Paso 1:** Identifica el container runtime

```bash
kubectl get nodes -o wide
```

**Busca la columna `CONTAINER-RUNTIME`**

**Paso 2:** (Requiere acceso SSH) Lista contenedores con crictl

```bash
# Desde un nodo
sudo crictl ps
```

**Paso 3:** Lista imÃ¡genes

```bash
sudo crictl images
```

**Preguntas:**
1. Â¿CuÃ¡ntos contenedores estÃ¡n corriendo en el nodo?
2. Â¿QuÃ© imagen usa el "pause container"?
3. Â¿Por quÃ© hay pause containers?

---

## Parte 3: ComunicaciÃ³n entre Componentes (20 minutos)

### ğŸ“ Ejercicio 3.1: Rastrear la CreaciÃ³n de un Deployment

**Paso 1:** Abre 3 terminales:

**Terminal 1:** Observa eventos
```bash
kubectl get events -w
```

**Terminal 2:** Observa pods
```bash
watch kubectl get pods
```

**Terminal 3:** Crea deployment
```bash
kubectl create deployment web --image=nginx --replicas=3
```

**Tarea:** Documenta la secuencia de eventos que observas:

```
1. ____________________________________
2. ____________________________________
3. ____________________________________
4. ____________________________________
```

**Preguntas:**
1. Â¿QuÃ© componente creÃ³ el ReplicaSet?
2. Â¿QuÃ© componente asignÃ³ los pods a los nodos?
3. Â¿QuÃ© componente iniciÃ³ los contenedores?

---

### ğŸ“ Ejercicio 3.2: Verificar ComunicaciÃ³n API Server â†” etcd

**Paso 1:** Consulta un recurso directamente desde etcd (si tienes acceso)

```bash
# Desde el nodo master (requiere certificados)
sudo ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  get /registry/deployments/default/web
```

**Pregunta:** Â¿Puedes ver la definiciÃ³n del Deployment en formato binario/protobuf?

**Paso 2:** Lista todas las keys en etcd

```bash
sudo ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  get / --prefix --keys-only | grep -E 'deployments|pods|services' | head -10
```

---

### ğŸ“ Ejercicio 3.3: Watch API

**Paso 1:** Simula el watch API que usa kubelet

```bash
# Obtener la IP del API Server
API_SERVER=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')

# Watch de pods (esto es lo que kubelet hace)
kubectl get pods --watch &
WATCH_PID=$!
```

**Paso 2:** Crea y elimina un pod

```bash
kubectl run test-watch --image=nginx
sleep 5
kubectl delete pod test-watch
```

**Observa cÃ³mo el watch recibe eventos en tiempo real**

**Limpieza:**
```bash
kill $WATCH_PID
```

---

## Parte 4: DesafÃ­os Avanzados (20 minutos)

### ğŸš€ DesafÃ­o 1: Mapa Completo del Cluster

**Tarea:** Crea un diagrama que muestre:
- Todos los nodos (master y workers)
- Componentes del Control Plane en cada master
- Componentes de Worker en cada worker
- Direcciones IP de cada componente
- Puertos principales

**Herramientas sugeridas:** Draw.io, Mermaid, o papel y lÃ¡piz

---

### ğŸš€ DesafÃ­o 2: Simular Fallo de Componente

**Escenario:** Imagina que el API Server en un nodo master falla.

**Preguntas:**
1. Â¿SeguirÃ¡ funcionando el cluster?
2. Â¿QuÃ© componentes se verÃ­an afectados?
3. Â¿Los pods en workers seguirÃ¡n corriendo?
4. Â¿PodrÃ¡s crear nuevos pods?

**Prueba (solo en entorno de desarrollo):**

```bash
# En un cluster multi-master, detener API Server
sudo systemctl stop kubelet  # En un nodo master

# Verificar desde otro nodo
kubectl get nodes
kubectl get pods
```

---

### ğŸš€ DesafÃ­o 3: AnÃ¡lisis de Performance

**Tarea:** Mide la latencia de las siguientes operaciones:

```bash
# 1. Listar pods
time kubectl get pods

# 2. Crear un pod
time kubectl run test-perf --image=nginx --restart=Never
time kubectl wait --for=condition=Ready pod/test-perf --timeout=60s

# 3. Eliminar pod
time kubectl delete pod test-perf --grace-period=0 --force
```

**Registra los tiempos:**
- `kubectl get pods`: ______ segundos
- `kubectl run`: ______ segundos
- Pod ready: ______ segundos
- `kubectl delete`: ______ segundos

---

## VerificaciÃ³n Final

### âœ… Checklist de Conocimientos

Marca las afirmaciones que puedes explicar:

- [ ] Puedo nombrar los 4 componentes principales del Control Plane
- [ ] Entiendo la diferencia entre Control Plane y Data Plane
- [ ] SÃ© quÃ© componentes usan leader election y cuÃ¡les no
- [ ] Puedo explicar el rol de kubelet en un Worker Node
- [ ] Entiendo cÃ³mo kube-proxy implementa Services
- [ ] SÃ© quÃ© container runtime usa mi cluster
- [ ] Puedo rastrear el flujo completo desde `kubectl create` hasta contenedor corriendo
- [ ] Entiendo quÃ© datos se almacenan en etcd
- [ ] Puedo identificar si mi cluster es single-master o HA
- [ ] SÃ© cÃ³mo verificar el health de cada componente

---

## Limpieza

```bash
# Eliminar recursos creados durante el laboratorio
kubectl delete deployment web --ignore-not-found
kubectl delete pod test-kubelet test-watch test-perf --ignore-not-found
```

---

## Recursos Adicionales

- ğŸ“– [Kubernetes Components](https://kubernetes.io/docs/concepts/overview/components/)
- ğŸ“– [etcd Documentation](https://etcd.io/docs/)
- ğŸ¥ [Kubernetes Architecture Explained (video)](https://www.youtube.com/watch?v=8C_SCDbUJTg)

---

## PrÃ³ximo Laboratorio

â¡ï¸ **Laboratorio 02**: Control Plane PrÃ¡ctico - Backup/Restore de etcd y anÃ¡lisis del API Server

---

**Â¿Completaste el laboratorio?** âœ…

Si tuviste dificultades o encontraste algo interesante, documenta tus observaciones para discutir en clase.
