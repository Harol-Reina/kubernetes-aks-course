# Laboratorio 04: Troubleshooting de Networking y Services

## Objetivos

Al finalizar este laboratorio, ser√°s capaz de:
- ‚úì Diagnosticar problemas de conectividad en Services
- ‚úì Debuggear issues de DNS resolution
- ‚úì Analizar flujo de tr√°fico en el cluster
- ‚úì Resolver problemas comunes de networking
- ‚úì Usar herramientas de debugging en producci√≥n

## Duraci√≥n Estimada

‚è±Ô∏è 90-120 minutos

## Pre-requisitos

- Cluster Kubernetes funcional
- Herramientas instaladas: `tcpdump`, `netcat`, `dig`, `curl`
- Acceso a crear/eliminar recursos
- Conocimientos b√°sicos de networking

---

## Parte 1: Troubleshooting de Services (35 minutos)

### üî¥ Problema 1: Service No Responde

**Escenario:** Un usuario reporta que su aplicaci√≥n no responde.

**Paso 1:** Crea el escenario problem√°tico

```bash
# Deployment con PUERTO INCORRECTO
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: broken-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: broken-app
  template:
    metadata:
      labels:
        app: broken-app
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: broken-service
spec:
  selector:
    app: broken-app
  ports:
  - port: 80
    targetPort: 8080  # ‚ùå INCORRECTO - nginx escucha en 80
EOF
```

**Paso 2:** Intenta conectar al Service

```bash
kubectl run test --rm -it --image=busybox -- wget -O- broken-service
```

**Deber√≠a FALLAR con timeout**

---

**üîç DEBUGGING:**

**Paso 3:** Verifica que el Service existe

```bash
kubectl get svc broken-service
```

‚úÖ Service existe

**Paso 4:** Verifica los endpoints

```bash
kubectl get endpoints broken-service
```

**Pregunta:** ¬øHay IPs en los endpoints? ¬øCu√°ntas?

‚úÖ Deber√≠as ver 3 IPs (una por cada pod)

**Paso 5:** Verifica que los pods est√°n corriendo

```bash
kubectl get pods -l app=broken-app
```

‚úÖ 3 pods en estado Running

**Paso 6:** Intenta conectar directamente a un pod

```bash
POD_IP=$(kubectl get pod -l app=broken-app -o jsonpath='{.items[0].status.podIP}')
echo "Pod IP: $POD_IP"

kubectl run test --rm -it --image=busybox -- wget -O- http://$POD_IP:80
```

‚úÖ **Esto FUNCIONA** - el pod responde en puerto 80

**Paso 7:** Compara el Service

```bash
kubectl describe svc broken-service | grep -A 3 "Port:"
```

‚ùå **ENCONTRADO EL PROBLEMA:** `targetPort: 8080` pero el pod escucha en `80`

---

**‚úÖ SOLUCI√ìN:**

```bash
kubectl patch svc broken-service -p '{"spec":{"ports":[{"port":80,"targetPort":80}]}}'

# Verifica
kubectl run test --rm -it --image=busybox -- wget -O- broken-service
```

‚úÖ Ahora funciona

---

### üî¥ Problema 2: Service Sin Endpoints

**Escenario:** Service creado pero no tiene endpoints.

**Paso 1:** Crea el escenario

```bash
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: backend-app  # Label: backend-app
  template:
    metadata:
      labels:
        app: backend-app
    spec:
      containers:
      - name: nginx
        image: nginx
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend  # ‚ùå INCORRECTO - busca "backend" no "backend-app"
  ports:
  - port: 80
EOF
```

**Paso 2:** Verifica endpoints

```bash
kubectl get endpoints backend-service
```

‚ùå **ENDPOINTS: <none>**

---

**üîç DEBUGGING:**

**Paso 3:** Compara los labels

```bash
# Labels del Service selector
kubectl get svc backend-service -o jsonpath='{.spec.selector}'
echo

# Labels de los pods
kubectl get pods -l app=backend-app -o jsonpath='{.items[0].metadata.labels}'
echo
```

‚ùå **PROBLEMA:** Selector no coincide con los labels de los pods

---

**‚úÖ SOLUCI√ìN:**

```bash
kubectl patch svc backend-service -p '{"spec":{"selector":{"app":"backend-app"}}}'

# Verifica
kubectl get endpoints backend-service
```

‚úÖ Ahora tiene endpoints

---

### üî¥ Problema 3: NodePort Inaccesible

**Escenario:** NodePort configurado pero no se puede acceder desde fuera.

**Paso 1:** Crea un NodePort Service

```bash
kubectl create deployment web --image=nginx
kubectl expose deployment web --type=NodePort --port=80
```

**Paso 2:** Obt√©n el NodePort

```bash
NODE_PORT=$(kubectl get svc web -o jsonpath='{.spec.ports[0].nodePort}')
NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')

echo "URL: http://$NODE_IP:$NODE_PORT"
```

**Paso 3:** Intenta acceder (puede fallar dependiendo de firewall)

```bash
curl http://$NODE_IP:$NODE_PORT
```

---

**üîç DEBUGGING:**

**Paso 4:** Verifica desde DENTRO de un nodo

```bash
# SSH al nodo
ssh $NODE_IP

# Desde el nodo
curl localhost:$NODE_PORT
```

‚úÖ Funciona desde el nodo

**Paso 5:** Verifica firewall

```bash
# En el nodo
sudo iptables -L -n | grep $NODE_PORT
```

**Paso 6:** Verifica que kube-proxy cre√≥ las reglas

```bash
sudo iptables -t nat -L KUBE-NODEPORTS -n | grep $NODE_PORT
```

‚úÖ Reglas existen

---

**üí° CAUSA COM√öN:** Firewall externo bloquea el puerto

**‚úÖ SOLUCIONES:**
- Abrir puerto en firewall del cloud provider
- Usar LoadBalancer en lugar de NodePort
- Usar Ingress Controller

---

## Parte 2: Troubleshooting DNS (30 minutos)

### üî¥ Problema 4: DNS No Resuelve

**Escenario:** Pods no pueden resolver nombres de Services.

**Paso 1:** Crea un Service

```bash
kubectl create deployment myapp --image=nginx
kubectl expose deployment myapp --port=80
```

**Paso 2:** Intenta resolver desde un pod

```bash
kubectl run dns-debug --rm -it --image=busybox -- sh

# Dentro del pod:
nslookup myapp
```

**Si falla, contin√∫a con el debugging...**

---

**üîç DEBUGGING:**

**Paso 3:** Verifica que CoreDNS est√° corriendo

```bash
kubectl get pods -n kube-system -l k8s-app=kube-dns
```

‚ùå Si no hay pods o est√°n en CrashLoopBackOff ‚Üí **PROBLEMA ENCONTRADO**

**Paso 4:** Verifica el Service de CoreDNS

```bash
kubectl get svc -n kube-system kube-dns
```

‚úÖ Deber√≠a tener ClusterIP (t√≠picamente 10.96.0.10)

**Paso 5:** Verifica /etc/resolv.conf en el pod

```bash
kubectl run dns-debug --rm -it --image=busybox -- cat /etc/resolv.conf
```

Deber√≠a tener:
```
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
```

‚ùå Si no est√° configurado correctamente ‚Üí **PROBLEMA EN KUBELET**

**Paso 6:** Prueba DNS directamente

```bash
kubectl run dns-debug --rm -it --image=busybox -- nslookup kubernetes 10.96.0.10
```

‚úÖ Si esto funciona, el problema est√° en la configuraci√≥n del pod, no en CoreDNS

---

**‚úÖ SOLUCIONES COMUNES:**

1. **CoreDNS no corre:**
```bash
kubectl rollout restart deployment coredns -n kube-system
```

2. **ConfigMap corrupto:**
```bash
kubectl get configmap coredns -n kube-system -o yaml
# Verifica que el Corefile est√° correcto
```

3. **Pods de CoreDNS sin recursos:**
```bash
kubectl describe pod -n kube-system -l k8s-app=kube-dns
# Verifica eventos
```

---

### üî¥ Problema 5: DNS Lento

**Escenario:** DNS funciona pero es muy lento.

**Paso 1:** Mide la latencia

```bash
kubectl run perf-test --rm -it --image=busybox -- sh

# Dentro del pod:
time nslookup kubernetes
time nslookup google.com
```

**Paso 2:** Verifica cache hits en CoreDNS

```bash
# Port-forward a las m√©tricas de CoreDNS
kubectl port-forward -n kube-system svc/kube-dns 9153:9153 &

# Ver m√©tricas de cache
curl http://localhost:9153/metrics | grep coredns_cache
```

**Paso 3:** Verifica carga de CoreDNS

```bash
kubectl top pods -n kube-system -l k8s-app=kube-dns
```

---

**‚úÖ SOLUCIONES:**

1. **Aumentar cache TTL en CoreDNS:**
```bash
kubectl edit configmap coredns -n kube-system
# Cambiar: cache 30 ‚Üí cache 300
```

2. **Escalar CoreDNS:**
```bash
kubectl scale deployment coredns -n kube-system --replicas=3
```

3. **Usar NodeLocal DNS Cache** (avanzado)

---

## Parte 3: An√°lisis de Flujo de Tr√°fico (25 minutos)

### üìù Ejercicio 3.1: tcpdump en un Pod

**Paso 1:** Crea un pod con herramientas de networking

```bash
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: netshoot
spec:
  containers:
  - name: netshoot
    image: nicolaka/netshoot
    command: ["sleep", "3600"]
EOF
```

**Paso 2:** Ejecuta tcpdump en el pod

```bash
kubectl exec -it netshoot -- tcpdump -i any -n port 80
```

**Deja esto corriendo...**

**Paso 3:** En otra terminal, genera tr√°fico

```bash
kubectl exec netshoot -- curl http://google.com
```

**Observa el tcpdump** - deber√≠as ver paquetes HTTP

---

### üìù Ejercicio 3.2: Rastrear Request de Service

**Paso 1:** Crea un Service y pods

```bash
kubectl create deployment trace-test --image=nginx --replicas=2
kubectl expose deployment trace-test --port=80
```

**Paso 2:** Desde un pod de debug, captura tr√°fico

```bash
# En netshoot pod
kubectl exec -it netshoot -- tcpdump -i any -n host $(kubectl get svc trace-test -o jsonpath='{.spec.clusterIP}')
```

**Paso 3:** En otra terminal, haz requests

```bash
kubectl exec netshoot -- curl trace-test
kubectl exec netshoot -- curl trace-test
kubectl exec netshoot -- curl trace-test
```

**Observa:** Ver√°s paquetes a diferentes pod IPs (balanceo de carga)

---

### üìù Ejercicio 3.3: iptables Tracing

**Paso 1:** Desde un worker node, habilita tracing de iptables

```bash
# ‚ö†Ô∏è Solo en entorno de prueba
sudo modprobe ipt_LOG

# Agregar regla de log
SERVICE_IP=$(kubectl get svc trace-test -o jsonpath='{.spec.clusterIP}')
sudo iptables -t nat -I KUBE-SERVICES -d $SERVICE_IP -j LOG --log-prefix "KUBE-SERVICE: "
```

**Paso 2:** Genera tr√°fico

```bash
kubectl exec netshoot -- curl trace-test
```

**Paso 3:** Ver logs de iptables

```bash
# En el nodo
sudo dmesg | grep "KUBE-SERVICE"
```

**Paso 4:** Limpieza

```bash
sudo iptables -t nat -D KUBE-SERVICES -d $SERVICE_IP -j LOG --log-prefix "KUBE-SERVICE: "
```

---

## Parte 4: Debugging Avanzado (20 minutos)

### üìù Ejercicio 4.1: Ephemeral Debug Container

**Paso 1:** Crea un pod sin herramientas de debug

```bash
kubectl run minimal --image=nginx
```

**Paso 2:** Agrega un ephemeral container para debugging

```bash
kubectl debug minimal -it --image=busybox --target=minimal
```

**Ahora tienes un shell en el namespace del pod original**

**Paso 3:** Debugging

```bash
# Dentro del debug container
ps aux  # Ver procesos del pod minimal
netstat -tulpn  # Ver puertos
ls -la /proc/1/root  # Ver filesystem del contenedor target
```

---

### üìù Ejercicio 4.2: Debug de Nodo

**Paso 1:** Crea un pod de debug en un nodo

```bash
NODE=$(kubectl get nodes -o jsonpath='{.items[0].metadata.name}')
kubectl debug node/$NODE -it --image=ubuntu
```

**Esto crea un pod privilegiado con acceso al filesystem del nodo**

**Paso 2:** Explora el nodo

```bash
# Dentro del debug pod
chroot /host

# Ahora est√°s en el nodo
ps aux | grep kubelet
journalctl -u kubelet -n 50
```

---

### üìù Ejercicio 4.3: Service Mesh Debugging (si usas Istio/Linkerd)

**Paso 1:** Verifica sidecar injection

```bash
kubectl get pod <pod-name> -o jsonpath='{.spec.containers[*].name}'
```

**Deber√≠as ver:** `app-container istio-proxy` (o `linkerd-proxy`)

**Paso 2:** Ver logs del sidecar

```bash
kubectl logs <pod-name> -c istio-proxy
```

**Paso 3:** Verificar comunicaci√≥n

```bash
kubectl exec <pod-name> -c app-container -- curl localhost:15000/stats
```

---

## Parte 5: Escenarios Reales (10 minutos)

### üö® Caso 1: "Intermittent Connection Failures"

**S√≠ntomas:**
- Algunas requests funcionan, otras fallan
- No hay patr√≥n claro

**Debugging:**
```bash
# 1. Verificar health de todos los endpoints
kubectl get endpoints <service-name> -o yaml

# 2. Probar conectividad a cada endpoint
for ip in $(kubectl get endpoints <service-name> -o jsonpath='{.subsets[*].addresses[*].ip}'); do
  echo "Testing $ip..."
  kubectl exec netshoot -- curl -m 2 http://$ip || echo "FAILED"
done

# 3. Ver readiness probes
kubectl describe pod -l app=<app>
```

**Causa com√∫n:** Uno o m√°s pods est√°n en estado "Not Ready" pero no se quitaron de endpoints.

---

### üö® Caso 2: "Service Works from Some Pods, Not Others"

**S√≠ntomas:**
- Service funciona desde pod A
- Service NO funciona desde pod B

**Debugging:**
```bash
# 1. Verificar NetworkPolicies
kubectl get networkpolicies

# 2. Ver si hay pol√≠ticas que afecten el tr√°fico
kubectl describe networkpolicy <policy-name>

# 3. Probar desde pod con label diferente
kubectl run test-1 --rm -it --image=busybox --labels=role=frontend -- wget <service>
kubectl run test-2 --rm -it --image=busybox --labels=role=backend -- wget <service>
```

**Causa com√∫n:** NetworkPolicy bloqueando tr√°fico desde ciertos pods.

---

### üö® Caso 3: "External Traffic Not Reaching Service"

**S√≠ntomas:**
- Interno funciona (ClusterIP)
- LoadBalancer/Ingress no responde

**Debugging:**
```bash
# 1. Verificar el Load Balancer
kubectl get svc <service-name>
# EXTERNAL-IP debe tener una IP (no <pending>)

# 2. Verificar Ingress
kubectl get ingress
kubectl describe ingress <ingress-name>

# 3. Ver logs del Ingress Controller
kubectl logs -n ingress-nginx -l app.kubernetes.io/name=ingress-nginx

# 4. Verificar que el Service tiene endpoints
kubectl get endpoints <service-name>
```

---

## Checklist de Troubleshooting

Usa esta checklist cuando debuggees problemas de networking:

### Para Services que no responden:

- [ ] Service existe: `kubectl get svc <name>`
- [ ] Service tiene endpoints: `kubectl get endpoints <name>`
- [ ] Pods est√°n Running: `kubectl get pods -l <selector>`
- [ ] Labels coinciden: Comparar selector del Service vs labels de pods
- [ ] Puertos correctos: targetPort coincide con containerPort
- [ ] Pods responden directamente: `curl http://<pod-ip>:<port>`
- [ ] Firewall permite tr√°fico (para NodePort/LoadBalancer)

### Para problemas de DNS:

- [ ] CoreDNS est√° corriendo: `kubectl get pods -n kube-system -l k8s-app=kube-dns`
- [ ] Service kube-dns existe: `kubectl get svc -n kube-system kube-dns`
- [ ] /etc/resolv.conf correcto en pods
- [ ] Probar resoluci√≥n directa: `nslookup <service> <dns-ip>`
- [ ] Verificar logs de CoreDNS
- [ ] Verificar ConfigMap de CoreDNS

### Para problemas de conectividad:

- [ ] NetworkPolicies no bloquean: `kubectl get networkpolicies`
- [ ] CNI plugin funciona: `kubectl get pods -n kube-system -l <cni-label>`
- [ ] Routing entre nodos funciona
- [ ] iptables/IPVS rules correctas en nodos

---

## Herramientas √ötiles

```bash
# Debug pod todo-en-uno
kubectl run netshoot --rm -it --image=nicolaka/netshoot -- bash

# Dentro de netshoot tienes:
# - curl, wget
# - dig, nslookup, host
# - tcpdump
# - netstat, ss
# - iperf3
# - traceroute
# - nmap
# y muchas m√°s...
```

---

## Limpieza

```bash
kubectl delete deployment broken-app backend web trace-test myapp --ignore-not-found
kubectl delete service broken-service backend-service web trace-test myapp --ignore-not-found
kubectl delete pod netshoot minimal --ignore-not-found
```

---

## Verificaci√≥n Final

### ‚úÖ Checklist de Conocimientos

- [ ] Puedo diagnosticar por qu√© un Service no responde
- [ ] S√© c√≥mo verificar que selector y labels coinciden
- [ ] Puedo troubleshootear problemas de DNS
- [ ] Entiendo c√≥mo usar tcpdump en pods
- [ ] Puedo crear ephemeral debug containers
- [ ] S√© c√≥mo verificar NetworkPolicies
- [ ] Puedo analizar iptables rules de kube-proxy
- [ ] Conozco las causas comunes de problemas de networking
- [ ] Tengo un proceso sistem√°tico para debugging

---

## Recursos Adicionales

- üìñ [Debugging Services](https://kubernetes.io/docs/tasks/debug/debug-application/debug-service/)
- üìñ [DNS Troubleshooting](https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/)
- üõ†Ô∏è [Netshoot - Network Troubleshooting Tool](https://github.com/nicolaka/netshoot)
- üìñ [Network Policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/)

---

**¬°Felicitaciones!** Has completado todos los laboratorios del M√≥dulo 02 ‚úÖ

**Siguiente paso:** Revisa el resumen del m√≥dulo y prep√°rate para el M√≥dulo 03.
