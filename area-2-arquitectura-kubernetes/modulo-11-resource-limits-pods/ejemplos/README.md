# Ejemplos Pr√°cticos - Resource Limits en Pods

Este directorio contiene ejemplos completos y bien documentados sobre gesti√≥n de recursos en Kubernetes.

## üìë √çndice de Ejemplos

| # | Nombre | Archivo | Conceptos | Dificultad |
|---|--------|---------|-----------|------------|
| 1 | Requests y Limits B√°sicos | [01-basico/requests-limits-basic.yaml](./01-basico/requests-limits-basic.yaml) | Requests, Limits, Multi-container, Init containers | ‚≠ê B√°sico |
| 2 | Quality of Service Classes | [02-qos/qos-classes.yaml](./02-qos/qos-classes.yaml) | Guaranteed, Burstable, BestEffort | ‚≠ê‚≠ê Intermedio |
| 3 | Ephemeral Storage | [03-ephemeral/ephemeral-storage.yaml](./03-ephemeral/ephemeral-storage.yaml) | emptyDir, sizeLimit, tmpfs, eviction | ‚≠ê‚≠ê Intermedio |
| 4 | Pod-level Resources | [04-pod-level/pod-level-resources.yaml](./04-pod-level/pod-level-resources.yaml) | Feature beta K8s 1.34, resource sharing | ‚≠ê‚≠ê‚≠ê Avanzado |
| 5 | Extended Resources | [05-extended/extended-resources.yaml](./05-extended/extended-resources.yaml) | GPUs, custom resources | ‚≠ê‚≠ê Intermedio |
| 6 | OOMKilled Simulation | [06-troubleshooting/oomkilled-simulation.yaml](./06-troubleshooting/oomkilled-simulation.yaml) | Memory leak, OOMKilled, troubleshooting | ‚≠ê‚≠ê Intermedio |
| 7 | CPU Throttling | [07-troubleshooting/cpu-throttling.yaml](./07-troubleshooting/cpu-throttling.yaml) | CPU stress, throttling, HPA | ‚≠ê‚≠ê‚≠ê Avanzado |

---

## üéØ Learning Paths

### Path 1: Fundamentos (Para principiantes)
Aprende los conceptos b√°sicos de resource management:

```bash
# 1. Conceptos b√°sicos
kubectl apply -f 01-basico/requests-limits-basic.yaml
kubectl get pods -l example=basic-resources
kubectl top pod requests-limits-basic

# 2. Entender QoS Classes
kubectl apply -f 02-qos/qos-classes.yaml
kubectl get pods -l example=qos-demo -o custom-columns=\
NAME:.metadata.name,\
QoS:.status.qosClass

# 3. Ver comportamiento
kubectl describe pod qos-guaranteed
kubectl describe pod qos-burstable-flexible
kubectl describe pod qos-besteffort
```

**Tiempo estimado**: 30 minutos  
**Requisitos**: Cluster Kubernetes b√°sico

### Path 2: Troubleshooting (Para administradores)
Aprende a diagnosticar y resolver problemas comunes:

```bash
# 1. Simular OOMKilled
kubectl apply -f 06-troubleshooting/oomkilled-simulation.yaml
kubectl get pod oomkilled-demo --watch

# Esperar ~30 segundos y observar
kubectl describe pod oomkilled-demo | grep -A 10 "Last State"

# 2. Detectar CPU Throttling
kubectl apply -f 07-troubleshooting/cpu-throttling.yaml
kubectl top pod cpu-throttling-demo --watch

# 3. Verificar ephemeral storage
kubectl apply -f 03-ephemeral/ephemeral-storage.yaml
kubectl logs -f ephemeral-monitor -c monitor
```

**Tiempo estimado**: 45 minutos  
**Requisitos**: metrics-server instalado

### Path 3: Producci√≥n (Para arquitectos)
Configuraciones avanzadas para ambientes productivos:

```bash
# 1. Pod-level resources (K8s 1.34+)
kubectl apply -f 04-pod-level/pod-level-resources.yaml
kubectl describe pod pod-level-hybrid | grep -A 20 "Resources"

# 2. Extended resources (requiere device plugins)
kubectl describe node | grep -i "nvidia.com/gpu"
kubectl apply -f 05-extended/extended-resources.yaml

# 3. Deployment con best practices
kubectl apply -f 03-ephemeral/ephemeral-storage.yaml
kubectl get deployment web-app-with-storage -o yaml
```

**Tiempo estimado**: 60 minutos  
**Requisitos**: K8s 1.34+, device plugins (opcional)

---

## üìö Descripci√≥n Detallada de Ejemplos

### 1. Requests y Limits B√°sicos
**Archivo**: `01-basico/requests-limits-basic.yaml`

**Qu√© aprender√°s**:
- Diferencia entre requests y limits
- QoS Class: Burstable
- Pods con m√∫ltiples contenedores
- Init containers con recursos
- Solo requests (sin limits)
- Solo limits (sin requests)
- Ephemeral storage b√°sico

**Ejemplos incluidos**:
- ‚úÖ Pod b√°sico con requests/limits
- ‚úÖ Multi-container resource allocation
- ‚úÖ Init containers (regla del m√°ximo)
- ‚úÖ Request-only configuration
- ‚úÖ Limit-only configuration (auto-copy)
- ‚úÖ Ephemeral storage demo

**Comandos clave**:
```bash
kubectl apply -f 01-basico/requests-limits-basic.yaml
kubectl get pods -l example
kubectl describe pod requests-limits-basic
kubectl get pod requests-limits-basic -o jsonpath='{.status.qosClass}'
kubectl top pod requests-limits-basic
```

---

### 2. Quality of Service (QoS) Classes
**Archivo**: `02-qos/qos-classes.yaml`

**Qu√© aprender√°s**:
- QoS Class: Guaranteed
- QoS Class: Burstable (3 variantes)
- QoS Class: BestEffort
- Orden de eviction bajo presi√≥n de recursos
- Comparaci√≥n directa de comportamiento

**Ejemplos incluidos**:
- ‚úÖ Guaranteed Pod (request == limit)
- ‚úÖ Burstable flexible (request < limit)
- ‚úÖ Burstable request-only (sin limits)
- ‚úÖ Burstable mixed (contenedores mixtos)
- ‚úÖ BestEffort (sin resources)
- ‚úÖ Deployment con comparaci√≥n

**Orden de Eviction**:
```
1. BestEffort  ‚óÑ‚îÄ‚îÄ Se eliminan PRIMERO
2. Burstable   ‚óÑ‚îÄ‚îÄ Prioridad media
3. Guaranteed  ‚óÑ‚îÄ‚îÄ Se eliminan √öLTIMO (m√°xima protecci√≥n)
```

**Comandos clave**:
```bash
kubectl apply -f 02-qos/qos-classes.yaml
kubectl get pods -l example=qos-demo -o custom-columns=\
NAME:.metadata.name,QoS:.status.qosClass
```

---

### 3. Ephemeral Storage
**Archivo**: `03-ephemeral/ephemeral-storage.yaml`

**Qu√© aprender√°s**:
- emptyDir con sizeLimit (‚úÖ best practice)
- emptyDir sin sizeLimit (‚ö†Ô∏è peligroso)
- tmpfs (memory-backed)
- M√∫ltiples emptyDir en un Pod
- Monitoreo de uso de storage
- Eviction por exceso de storage

**Ejemplos incluidos**:
- ‚úÖ emptyDir con sizeLimit seguro
- ‚ö†Ô∏è emptyDir sin l√≠mite (demo)
- ‚úÖ tmpfs (cuenta como memoria, no storage)
- ‚úÖ M√∫ltiples vol√∫menes con l√≠mites
- ‚úÖ Pod de monitoreo de storage
- üî• Demo de eviction intencional
- ‚úÖ Deployment con best practices

**‚ö†Ô∏è Importante**:
```yaml
# tmpfs NO cuenta como ephemeral-storage
emptyDir:
  medium: Memory  # ‚Üê Usa RAM, cuenta como memory usage

# emptyDir regular S√ç cuenta
emptyDir:
  sizeLimit: "1Gi"  # ‚Üê Cuenta como ephemeral-storage
```

**Comandos clave**:
```bash
kubectl apply -f 03-ephemeral/ephemeral-storage.yaml
kubectl logs -f ephemeral-monitor -c monitor
kubectl exec -it emptydir-with-sizelimit -- df -h /cache
kubectl get events --field-selector reason=Evicted
```

---

### 4. Pod-level Resources (Beta K8s 1.34+)
**Archivo**: `04-pod-level/pod-level-resources.yaml`

**Qu√© aprender√°s**:
- Feature gate `PodLevelResources`
- Especificar presupuesto total del Pod
- Resource sharing entre contenedores
- Combinaci√≥n Pod-level + Container-level

**Ejemplos incluidos**:
- ‚úÖ Solo Pod-level (contenedores comparten)
- ‚úÖ H√≠brido (app con l√≠mite + sidecars sin l√≠mite)
- ‚úÖ Deployment multi-sidecar

**‚ö†Ô∏è Requisitos**:
- Kubernetes 1.34+
- Feature gate `PodLevelResources=true` (default en 1.34)

**Ventajas**:
- ‚úÖ Simplifica configuraci√≥n con muchos sidecars
- ‚úÖ Mejor utilizaci√≥n de recursos idle
- ‚úÖ Reduce over-provisioning

**Comandos clave**:
```bash
kubectl apply -f 04-pod-level/pod-level-resources.yaml
kubectl describe pod pod-level-basic | grep -A 10 "Resources"
kubectl top pod pod-level-hybrid --containers
```

---

### 5. Extended Resources
**Archivo**: `05-extended/extended-resources.yaml`

**Qu√© aprender√°s**:
- Solicitar GPUs NVIDIA
- Solicitar GPUs AMD
- Custom extended resources

**Ejemplos incluidos**:
- ‚úÖ NVIDIA GPU request
- ‚úÖ AMD GPU request
- ‚úÖ Custom resources (FPGA, dongles)

**‚ö†Ô∏è Requisitos**:
- Device plugin instalado en el nodo
- Nodo debe anunciar el recurso

**Instalaci√≥n NVIDIA GPU Device Plugin**:
```bash
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/nvidia-device-plugin.yml
```

**Verificar recursos disponibles**:
```bash
kubectl describe node | grep -i "nvidia.com/gpu"
```

**Comandos clave**:
```bash
kubectl apply -f 05-extended/extended-resources.yaml
kubectl describe pod gpu-pod-nvidia
```

---

### 6. OOMKilled Simulation
**Archivo**: `06-troubleshooting/oomkilled-simulation.yaml`

**Qu√© aprender√°s**:
- Simular memory leak
- Observar comportamiento de OOMKilled
- Detectar Exit Code 137
- Analizar restart count
- CrashLoopBackOff

**Ejemplos incluidos**:
- üî• Memory leak intencional (stress)
- üî• Memory leak gradual (script)

**Comportamiento esperado**:
```
1. Container intenta usar m√°s memoria que el l√≠mite
2. Kernel OOM Killer detecta exceso
3. Proceso terminado con SIGKILL
4. Exit Code: 137
5. Pod reinicia (restartPolicy: Always)
6. Si falla repetidamente ‚Üí CrashLoopBackOff
```

**‚ö†Ô∏è SOLO PARA TESTING** - No usar en producci√≥n

**Comandos clave**:
```bash
kubectl apply -f 06-troubleshooting/oomkilled-simulation.yaml
kubectl get pod oomkilled-demo --watch

# Esperar ~30 segundos
kubectl describe pod oomkilled-demo | grep -A 10 "Last State"
# Reason: OOMKilled
# Exit Code: 137

kubectl get pod oomkilled-demo -o jsonpath='{.status.containerStatuses[0].restartCount}'
kubectl logs oomkilled-demo --previous
```

---

### 7. CPU Throttling
**Archivo**: `07-troubleshooting/cpu-throttling.yaml`

**Qu√© aprender√°s**:
- Simular carga de CPU
- Detectar throttling
- Comparar con y sin throttling
- Alternativa: Horizontal Pod Autoscaler

**Ejemplos incluidos**:
- üî• CPU stress con l√≠mite bajo (throttled)
- ‚úÖ Comparaci√≥n throttled vs not-throttled
- ‚úÖ Deployment con HPA

**Comportamiento de Throttling**:
```
- Intenta usar 2 CPUs
- L√≠mite: 0.5 CPU
- Kernel throttles el proceso
- CPU usage stuck en ~500m
- Aplicaci√≥n se vuelve lenta
- NO se termina (diferente a OOMKill)
```

**Detectar Throttling**:
```bash
# Ver CPU usage (stuck en el l√≠mite)
kubectl top pod cpu-throttling-demo

# Ver stats de throttling (dentro del contenedor)
kubectl exec -it cpu-throttling-demo -- cat /sys/fs/cgroup/cpu/cpu.stat
# nr_throttled: 800  # ‚Üê 80% del tiempo throttled!

# Con Prometheus
rate(container_cpu_cfs_throttled_seconds_total{pod="cpu-throttling-demo"}[5m])
```

**‚ö†Ô∏è SOLO PARA TESTING**

**Comandos clave**:
```bash
kubectl apply -f 07-troubleshooting/cpu-throttling.yaml
kubectl top pod cpu-throttling-demo --watch
kubectl top pod cpu-comparison --containers
```

---

## üõ†Ô∏è Casos de Uso Pr√°cticos

### Caso 1: Aplicaci√≥n Web (Burstable)
**Escenario**: API REST con tr√°fico variable

```yaml
# Usar: 01-basico/requests-limits-basic.yaml
resources:
  requests:
    cpu: "250m"
    memory: "128Mi"
  limits:
    cpu: "1"
    memory: "512Mi"
```

**Por qu√©**:
- Request bajo ‚Üí scheduler puede colocar m√°s Pods
- Limit alto ‚Üí puede manejar picos de tr√°fico
- QoS: Burstable (balance costo/flexibilidad)

### Caso 2: Base de Datos (Guaranteed)
**Escenario**: PostgreSQL en producci√≥n

```yaml
# Usar: 02-qos/qos-classes.yaml (qos-guaranteed)
resources:
  requests:
    cpu: "2"
    memory: "4Gi"
  limits:
    cpu: "2"
    memory: "4Gi"
```

**Por qu√©**:
- Request == Limit ‚Üí QoS Guaranteed
- M√°xima protecci√≥n contra eviction
- Rendimiento predecible

### Caso 3: Batch Jobs (BestEffort)
**Escenario**: Procesamiento batch no cr√≠tico

```yaml
# Usar: 02-qos/qos-classes.yaml (qos-besteffort)
# Sin resources definidos
```

**Por qu√©**:
- No reserva recursos ‚Üí m√°s Pods en el cl√∫ster
- Puede usar recursos idle
- Se evicted primero (aceptable para batch jobs)

### Caso 4: Multi-Sidecar App (Pod-level)
**Escenario**: App con 4+ sidecars (service mesh, logging, etc.)

```yaml
# Usar: 04-pod-level/pod-level-resources.yaml
spec:
  resources:
    limits:
      cpu: "3"
      memory: "3Gi"
  # Todos los contenedores comparten
```

**Por qu√©**:
- Dif√≠cil calcular recursos para cada sidecar
- Sidecars comparten recursos idle
- Menos over-provisioning

---

## üìä Comandos √ötiles

### Monitoreo

```bash
# Ver uso de recursos de todos los Pods
kubectl top pods --all-namespaces

# Ver uso de recursos de un Pod con contenedores
kubectl top pod <pod-name> --containers

# Ver uso de recursos de nodos
kubectl top nodes

# Ver recursos asignados en un nodo
kubectl describe node <node-name> | grep -A 10 "Allocated resources"
```

### Troubleshooting

```bash
# Ver QoS Class de un Pod
kubectl get pod <pod-name> -o jsonpath='{.status.qosClass}'

# Ver eventos de un Pod
kubectl get events --field-selector involvedObject.name=<pod-name>

# Ver logs del contenedor anterior (tras crash)
kubectl logs <pod-name> --previous

# Ver restart count
kubectl get pod <pod-name> -o jsonpath='{.status.containerStatuses[0].restartCount}'

# Ver Pods evicted
kubectl get pods --field-selector=status.phase=Failed

# Ver eventos de eviction
kubectl get events --all-namespaces | grep -i evict

# Ver eventos de OOMKilled
kubectl get events --all-namespaces --field-selector reason=OOMKilled
```

### An√°lisis

```bash
# Ver recursos de todos los Pods en formato customizado
kubectl get pods -o custom-columns=\
NAME:.metadata.name,\
CPU_REQ:.spec.containers[0].resources.requests.cpu,\
CPU_LIM:.spec.containers[0].resources.limits.cpu,\
MEM_REQ:.spec.containers[0].resources.requests.memory,\
MEM_LIM:.spec.containers[0].resources.limits.memory,\
QoS:.status.qosClass

# Contar Pods por QoS class
kubectl get pods --all-namespaces -o json | \
  jq -r '.items[].status.qosClass' | sort | uniq -c

# Ver Pods con restart count alto
kubectl get pods --all-namespaces -o json | \
  jq -r '.items[] | select(.status.containerStatuses[].restartCount > 5) | 
  "\(.metadata.namespace)/\(.metadata.name): \(.status.containerStatuses[].restartCount) restarts"'
```

---

## üßπ Limpieza

```bash
# Limpiar ejemplos individuales
kubectl delete -f 01-basico/requests-limits-basic.yaml
kubectl delete -f 02-qos/qos-classes.yaml
kubectl delete -f 03-ephemeral/ephemeral-storage.yaml
kubectl delete -f 04-pod-level/pod-level-resources.yaml
kubectl delete -f 05-extended/extended-resources.yaml
kubectl delete -f 06-troubleshooting/oomkilled-simulation.yaml
kubectl delete -f 07-troubleshooting/cpu-throttling.yaml

# Limpiar TODOS los ejemplos
kubectl delete pods,deployments -l example
```

---

## üìñ Referencias

- **[README Principal](../README.md)**: Documentaci√≥n completa del m√≥dulo
- **[Laboratorios](../laboratorios/)**: Ejercicios pr√°cticos guiados
- **[Kubernetes Docs](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)**: Documentaci√≥n oficial

---

**√öltima actualizaci√≥n**: Noviembre 2025  
**Versi√≥n**: Kubernetes 1.28+
