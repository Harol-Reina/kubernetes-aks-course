# =============================================================================
# Ejemplo 05: Extended Resources (GPUs, Custom Hardware)
# =============================================================================

---
# Ejemplo 1: NVIDIA GPU Request

apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod-nvidia
  labels:
    example: extended-resources
    type: gpu
spec:
  containers:
  - name: cuda-app
    image: nvidia/cuda:11.8.0-base-ubuntu22.04
    command: ["nvidia-smi"]
    resources:
      limits:
        nvidia.com/gpu: 2  # Solicita 2 GPUs NVIDIA
        # Extended resources deben ser n√∫meros enteros

---
# Ejemplo 2: AMD GPU

apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod-amd
  labels:
    example: extended-resources
    type: gpu-amd
spec:
  containers:
  - name: rocm-app
    image: rocm/rocm-terminal:latest
    resources:
      limits:
        amd.com/gpu: 1

---
# Ejemplo 3: Custom Extended Resource

apiVersion: v1
kind: Pod
metadata:
  name: custom-resource-pod
  labels:
    example: extended-resources
    type: custom
spec:
  containers:
  - name: app
    image: nginx:1.25-alpine
    resources:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "1"
        memory: "512Mi"
        example.com/fpga: 1  # Custom resource
        example.com/dongle: 2

# Para usar extended resources, el nodo debe anunciarlos:
# kubectl patch node <node> --patch '
# status:
#   capacity:
#     example.com/fpga: "4"
#     example.com/dongle: "10"
# '
