# MÃ³dulo 11: Resource Limits en Pods

## Ãndice

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Conceptos Fundamentales](#conceptos-fundamentales)
3. [Requests vs Limits](#requests-vs-limits)
4. [Tipos de Recursos](#tipos-de-recursos)
5. [Unidades de Recursos](#unidades-de-recursos)
6. [Quality of Service (QoS) Classes](#quality-of-service-qos-classes)
7. [ConfiguraciÃ³n de Recursos](#configuraciÃ³n-de-recursos)
8. [Pod-level Resources (Beta K8s 1.34)](#pod-level-resources-beta-k8s-134)
9. [Ephemeral Storage](#ephemeral-storage)
10. [Extended Resources](#extended-resources)
11. [Comportamiento del Scheduler](#comportamiento-del-scheduler)
12. [Enforcement de LÃ­mites](#enforcement-de-lÃ­mites)
13. [Monitoreo de Recursos](#monitoreo-de-recursos)
14. [Best Practices](#best-practices)
15. [Troubleshooting](#troubleshooting)
16. [Ejemplos PrÃ¡cticos](#ejemplos-prÃ¡cticos)
17. [Laboratorios](#laboratorios)
18. [Referencias](#referencias)

---

## IntroducciÃ³n

La gestiÃ³n de recursos es **crÃ­tica** para la estabilidad y eficiencia de aplicaciones en Kubernetes. Este mÃ³dulo cubre en profundidad cÃ³mo especificar y gestionar recursos (CPU, memoria, almacenamiento) para contenedores y Pods.

### Â¿Por quÃ© es importante?

- **Estabilidad del clÃºster**: Prevenir que un Pod consuma todos los recursos del nodo
- **Scheduling eficiente**: El scheduler necesita saber cuÃ¡ntos recursos requiere cada Pod
- **Calidad de Servicio**: Garantizar recursos mÃ­nimos para aplicaciones crÃ­ticas
- **OptimizaciÃ³n de costos**: Evitar sobre-aprovisionamiento de recursos
- **PrevenciÃ³n de OOMKilled**: Controlar el uso de memoria para evitar terminaciones inesperadas

### ActualizaciÃ³n Noviembre 2025

Este documento estÃ¡ actualizado para **Kubernetes 1.28+** e incluye:
- âœ… Pod-level resources (feature beta en K8s 1.34)
- âœ… Memory QoS considerations (feature stalled)
- âœ… Ephemeral storage management mejorado
- âœ… Extended resources con DRA (Dynamic Resource Allocation)
- âœ… Best practices actualizadas para producciÃ³n

---

## Conceptos Fundamentales

### Â¿QuÃ© son los Resource Requests y Limits?

Los **requests** y **limits** son dos mecanismos para controlar el uso de recursos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NODO (8 CPU, 16 GB)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pod A                                            â”‚   â”‚
â”‚  â”‚  Request: 1 CPU, 2 GB  â—„â”€â”€ Scheduler garantiza   â”‚   â”‚
â”‚  â”‚  Limit:   2 CPU, 4 GB  â—„â”€â”€ Kubelet enforza       â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  Uso real: 1.5 CPU, 3 GB âœ“ (dentro del lÃ­mite)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pod B                                            â”‚   â”‚
â”‚  â”‚  Request: 0.5 CPU, 1 GB                          â”‚   â”‚
â”‚  â”‚  Limit:   1 CPU, 2 GB                            â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  Uso real: 0.8 CPU, 1.5 GB âœ“                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  Total Requests:  1.5 CPU, 3 GB   (scheduler check)     â”‚
â”‚  Total Limits:    3 CPU, 6 GB     (puede overcommit)    â”‚
â”‚  Capacidad nodo:  8 CPU, 16 GB                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Diferencias clave

| Aspecto | Request | Limit |
|---------|---------|-------|
| **PropÃ³sito** | Reservar recursos mÃ­nimos | Restringir uso mÃ¡ximo |
| **Scheduler** | âœ… Usa para decidir nodo | âŒ No considera |
| **Enforcement** | âŒ No enforza lÃ­mite | âœ… Kubelet enforza |
| **Overcommit** | âŒ No puede exceder capacidad total | âœ… Puede sumar mÃ¡s que capacidad nodo |
| **QoS Class** | âœ… Influye en clasificaciÃ³n | âœ… Influye en clasificaciÃ³n |

---

## Requests vs Limits

### Requests (Peticiones)

**DefiniciÃ³n**: Cantidad **mÃ­nima garantizada** de recursos que un contenedor necesita.

#### CaracterÃ­sticas:

1. **Scheduler lo usa para placement**: 
   - El scheduler suma todos los requests de Pods ya programados en un nodo
   - Solo programa un nuevo Pod si: `sum(requests) + new_pod_request <= node.allocatable`
   - **No considera el uso real** de recursos en el nodo

2. **No es un lÃ­mite**:
   - El contenedor puede usar MÃS recursos que su request
   - Solo estÃ¡ garantizado que tendrÃ¡ AL MENOS esa cantidad disponible

3. **CPU Shares (Linux cgroups)**:
   - Para CPU, el request se traduce a `cpu.shares` en cgroups
   - Si hay contenciÃ³n de CPU, los Pods con mayor request reciben mÃ¡s tiempo de CPU

#### Ejemplo prÃ¡ctico:

```yaml
resources:
  requests:
    cpu: "500m"      # Garantiza 0.5 CPU cores
    memory: "256Mi"  # Garantiza 256 MiB de RAM
```

**Comportamiento**:
- âœ… El scheduler busca un nodo con al menos 500m CPU y 256Mi memoria disponibles
- âœ… Si el nodo tiene recursos libres, el contenedor puede usar 2 CPU y 2 GB si lo necesita
- âœ… En contenciÃ³n de CPU, este contenedor recibe al menos su share proporcional

### Limits (LÃ­mites)

**DefiniciÃ³n**: Cantidad **mÃ¡xima** de recursos que un contenedor puede usar.

#### CaracterÃ­sticas:

1. **Hard limit enforced por kernel**:
   - **CPU**: Throttling (restricciÃ³n de acceso)
   - **Memory**: OOM Kill (terminaciÃ³n del proceso)

2. **Diferencia entre CPU y Memory**:

   **CPU Limit (soft enforcement)**:
   ```
   - El kernel usa cgroups para throttling
   - Si el contenedor intenta usar mÃ¡s CPU, simplemente se frena
   - El Pod NO se termina por exceso de CPU
   - Puede causar latencia/lentitud en la aplicaciÃ³n
   ```

   **Memory Limit (hard enforcement)**:
   ```
   - El kernel detecta exceso de memoria
   - Activa el OOM (Out of Memory) killer
   - Termina el proceso que excediÃ³ el lÃ­mite
   - El Pod puede reiniciarse (si restartPolicy lo permite)
   - Reason: "OOMKilled", Exit Code: 137
   ```

3. **Overcommit permitido**:
   - La suma de limits de todos los Pods puede exceder la capacidad del nodo
   - Esto se llama "overcommit" y es normal en Kubernetes
   - Si todos los Pods intentan usar sus lÃ­mites simultÃ¡neamente â†’ eviction

#### Ejemplo prÃ¡ctico:

```yaml
resources:
  limits:
    cpu: "1"         # MÃ¡ximo 1 CPU core
    memory: "512Mi"  # MÃ¡ximo 512 MiB de RAM
```

**Comportamiento**:
- âœ… CPU: Si intenta usar mÃ¡s de 1 core â†’ **throttling** (se frena)
- âŒ Memory: Si intenta usar mÃ¡s de 512Mi â†’ **OOMKilled** (se termina)

### Combinaciones Request + Limit

#### 1. Solo Request (sin limit)

```yaml
resources:
  requests:
    cpu: "500m"
    memory: "256Mi"
  # No limits definidos
```

**Comportamiento**:
- âœ… Garantiza 500m CPU y 256Mi memoria
- âš ï¸ Puede usar TODA la CPU/memoria disponible del nodo (peligroso)
- âš ï¸ QoS Class: **BestEffort** o **Burstable**

#### 2. Solo Limit (sin request)

```yaml
resources:
  limits:
    cpu: "1"
    memory: "512Mi"
  # No requests definidos
```

**Comportamiento Kubernetes**:
- ğŸ”„ Kubernetes **copia automÃ¡ticamente** el limit al request
- Equivale a: `requests.cpu = "1"`, `requests.memory = "512Mi"`
- âš ï¸ Puede resultar en over-provisioning (reserva mÃ¡s de lo necesario)

#### 3. Request = Limit (recomendado para producciÃ³n crÃ­tica)

```yaml
resources:
  requests:
    cpu: "1"
    memory: "512Mi"
  limits:
    cpu: "1"
    memory: "512Mi"
```

**Comportamiento**:
- âœ… Recursos garantizados y lÃ­mite conocido
- âœ… QoS Class: **Guaranteed** (mÃ¡xima prioridad)
- âœ… Ãšltima en ser evicted en caso de presiÃ³n de recursos
- âœ… Ideal para bases de datos, aplicaciones crÃ­ticas

#### 4. Request < Limit (comÃºn en desarrollo/staging)

```yaml
resources:
  requests:
    cpu: "500m"
    memory: "256Mi"
  limits:
    cpu: "2"
    memory: "1Gi"
```

**Comportamiento**:
- âœ… Reserva mÃ­nimo (500m, 256Mi) pero puede crecer hasta (2, 1Gi)
- âœ… QoS Class: **Burstable**
- âœ… Flexible para picos de carga
- âš ï¸ Puede sufrir throttling/OOMKill si excede lÃ­mites

---

## Tipos de Recursos

Kubernetes soporta varios tipos de recursos que se pueden gestionar:

### 1. Recursos de ComputaciÃ³n (Compute Resources)

#### CPU

- **Unidad base**: Kubernetes CPU (equivalente a 1 vCPU/core o 1 hyperthread)
- **MediciÃ³n**: Unidades absolutas (no relativas)
- **Ejemplos**: `1`, `0.5`, `500m` (500 millicpu)
- **PrecisiÃ³n mÃ­nima**: `1m` (0.001 CPU)

#### Memory

- **Unidad base**: Bytes
- **Sufijos soportados**:
  - Decimal: `E`, `P`, `T`, `G`, `M`, `k`
  - Binario (potencia de 2): `Ei`, `Pi`, `Ti`, `Gi`, `Mi`, `Ki`
- **Ejemplos**: `128974848`, `129M`, `123Mi`

### 2. Ephemeral Storage (Almacenamiento EfÃ­mero)

- **Desde**: Kubernetes 1.8+ (stable desde 1.25)
- **Recurso**: `ephemeral-storage`
- **Incluye**:
  - VolÃºmenes `emptyDir` (excepto `tmpfs`)
  - Logs de contenedor a nivel de nodo
  - Writable container layers (imÃ¡genes de contenedor)

#### Ejemplo:

```yaml
resources:
  requests:
    ephemeral-storage: "2Gi"
  limits:
    ephemeral-storage: "4Gi"
```

**âš ï¸ Consideraciones**:

1. **tmpfs emptyDir NO cuenta como ephemeral-storage**:
   - Se cuenta como **uso de memoria del contenedor**
   - Afecta al lÃ­mite de memoria, no de storage

2. **Enforcement**:
   - Si excede el lÃ­mite â†’ **Pod eviction**
   - Kubelet monitorea con escaneo periÃ³dico o project quotas (XFS)

3. **ConfiguraciÃ³n del nodo**:
   - Single filesystem: Todo en un filesystem (tÃ­pico `/var/lib/kubelet`)
   - Two filesystems: Separar kubelet data y container runtime

### 3. Huge Pages (PÃ¡ginas Grandes)

- **Linux-specific feature**
- **Recurso**: `hugepages-<size>` (ej: `hugepages-2Mi`, `hugepages-1Gi`)
- **Uso**: OptimizaciÃ³n de rendimiento para aplicaciones que usan mucha memoria
- **âš ï¸ No se puede overcommit** (diferencia con CPU/memory)

#### Ejemplo:

```yaml
resources:
  requests:
    hugepages-2Mi: "80Mi"  # 40 pÃ¡ginas de 2Mi cada una
  limits:
    hugepages-2Mi: "80Mi"
```

### 4. Extended Resources (Recursos Extendidos)

Recursos personalizados fuera del dominio `kubernetes.io`:

#### Tipos:

1. **Node-level** (gestionados por device plugins):
   - GPUs: `nvidia.com/gpu`, `amd.com/gpu`
   - FPGAs: `vendor.com/fpga`
   - High-performance NICs: `vendor.com/nic`

2. **Cluster-level** (gestionados por scheduler extenders):
   - Licencias de software
   - Recursos compartidos

#### Ejemplo GPU:

```yaml
resources:
  limits:
    nvidia.com/gpu: 2  # Solicita 2 GPUs NVIDIA
```

**âš ï¸ CaracterÃ­sticas**:
- âœ… Deben ser **cantidades enteras** (no fraccionarias)
- âœ… **No se puede overcommit**
- âœ… Request y Limit deben ser **iguales**

---

## Unidades de Recursos

### CPU

#### RepresentaciÃ³n

- **1 Kubernetes CPU** = 1 vCPU/core fÃ­sico o 1 vCore (VM)
- **Fraccionario**: Se permiten fracciones con precisiÃ³n hasta `1m` (milliCPU)

#### Formatos equivalentes:

```yaml
cpu: "1"      # 1 CPU completo
cpu: "0.5"    # Mitad de un CPU
cpu: "500m"   # 500 millicpu = 0.5 CPU
cpu: "100m"   # 100 millicpu = 0.1 CPU
```

#### âš ï¸ Valores invÃ¡lidos:

```yaml
cpu: "0.5m"   # âŒ InvÃ¡lido (< 1m)
cpu: "0.0005" # âŒ InvÃ¡lido (= 0.5m)
cpu: "1500m"  # âœ… VÃ¡lido (= 1.5 CPU)
```

#### ğŸ’¡ Best Practice:

**Usa millicpu (`m`) para valores < 1 CPU**:
- âœ… `100m` es mÃ¡s legible que `0.1`
- âœ… Evita errores con decimales invÃ¡lidos

### Memory

#### Sufijos soportados

| Sufijo | Tipo | Base | Ejemplo | Bytes |
|--------|------|------|---------|-------|
| `k` | Decimal | 10Â³ | `1000k` | 1,000,000 |
| `M` | Decimal | 10â¶ | `500M` | 500,000,000 |
| `G` | Decimal | 10â¹ | `2G` | 2,000,000,000 |
| `Ki` | Binario | 2Â¹â° | `1000Ki` | 1,024,000 |
| `Mi` | Binario | 2Â²â° | `500Mi` | 524,288,000 |
| `Gi` | Binario | 2Â³â° | `2Gi` | 2,147,483,648 |

#### Valores equivalentes:

```yaml
memory: "128974848"    # Bytes exactos
memory: "129e6"        # NotaciÃ³n cientÃ­fica
memory: "129M"         # 129 megabytes (decimal)
memory: "123Mi"        # 123 mebibytes (binario)
```

#### âš ï¸ Cuidado con los sufijos:

```yaml
# âŒ COMÃšN ERROR: confundir "m" (milli) con "M" (mega)
memory: "400m"   # âŒ 0.4 bytes (casi nada!)
memory: "400M"   # âœ… 400 megabytes
memory: "400Mi"  # âœ… 400 mebibytes (recomendado)
```

#### ğŸ’¡ Best Practice:

**Usa sufijos binarios (`Mi`, `Gi`) para memoria**:
- âœ… MÃ¡s preciso (memoria se asigna en potencias de 2)
- âœ… Evita confusiÃ³n con millibytes (`m`)

### Ephemeral Storage

Usa las mismas unidades que memoria:

```yaml
ephemeral-storage: "2Gi"   # 2 gibibytes
ephemeral-storage: "500Mi" # 500 mebibytes
```

---

## Quality of Service (QoS) Classes

Kubernetes asigna automÃ¡ticamente una **QoS Class** a cada Pod basÃ¡ndose en sus recursos configurados. Esta clase determina la **prioridad de eviction** cuando el nodo estÃ¡ bajo presiÃ³n de recursos.

### ClasificaciÃ³n AutomÃ¡tica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESIÃ“N DE RECURSOS                      â”‚
â”‚                                                             â”‚
â”‚  Orden de Eviction (primero â†’ Ãºltimo)                       â”‚
â”‚                                                             â”‚
â”‚  1. BestEffort  â—„â”€â”€â”€ Sin requests/limits                    â”‚
â”‚     â””â”€ Se eliminan PRIMERO                                  â”‚
â”‚                                                             â”‚
â”‚  2. Burstable   â—„â”€â”€â”€ Request < Limit                        â”‚
â”‚     â””â”€ Se eliminan segÃºn uso vs request                     â”‚
â”‚                                                             â”‚
â”‚  3. Guaranteed  â—„â”€â”€â”€ Request = Limit (todos los recursos)   â”‚
â”‚     â””â”€ Se eliminan ÃšLTIMO (mÃ¡xima protecciÃ³n)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. Guaranteed (Garantizado)

**Condiciones** (TODAS deben cumplirse):

1. âœ… **Todos** los contenedores tienen `requests` Y `limits` para CPU y Memory
2. âœ… Para **cada** contenedor: `requests.cpu == limits.cpu`
3. âœ… Para **cada** contenedor: `requests.memory == limits.memory`

#### Ejemplo Guaranteed:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-guaranteed
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "500m"
        memory: "256Mi"
      limits:
        cpu: "500m"      # âœ… Igual a request
        memory: "256Mi"  # âœ… Igual a request
```

**CaracterÃ­sticas**:
- ğŸ›¡ï¸ **MÃ¡xima protecciÃ³n**: Ãšltima clase en ser evicted
- ğŸ¯ **Recursos predecibles**: Sabe exactamente cuÃ¡nto puede usar
- ğŸ’° **Costo**: Puede resultar en over-provisioning
- ğŸ¯ **Uso**: Bases de datos, aplicaciones crÃ­ticas, stateful sets

### 2. Burstable (Flexible)

**Condiciones**:

1. âœ… No califica para Guaranteed
2. âœ… **Al menos UN** contenedor tiene request o limit para CPU o Memory

#### Ejemplo Burstable (request < limit):

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-burstable
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "250m"
        memory: "128Mi"
      limits:
        cpu: "1"        # âœ… Mayor que request
        memory: "512Mi" # âœ… Mayor que request
```

#### Ejemplo Burstable (solo request):

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-burstable-request-only
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "250m"
        memory: "128Mi"
      # Sin limits â†’ puede usar todos los recursos disponibles
```

**CaracterÃ­sticas**:
- âš–ï¸ **Prioridad media**: Se evicted despuÃ©s de BestEffort, antes de Guaranteed
- ğŸ“ˆ **Flexible**: Puede usar mÃ¡s recursos si estÃ¡n disponibles
- âš ï¸ **Riesgo**: Puede sufrir throttling o OOMKill
- ğŸ¯ **Uso**: Aplicaciones web, servicios stateless, desarrollo/staging

**Orden de eviction dentro de Burstable**:
- Pods que exceden mÃ¡s su request se evicted primero
- CÃ¡lculo: `(current_usage - request) / request`

### 3. BestEffort (Mejor Esfuerzo)

**Condiciones**:

1. âŒ **NINGÃšN** contenedor tiene requests o limits para CPU o Memory

#### Ejemplo BestEffort:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: qos-besteffort
spec:
  containers:
  - name: app
    image: nginx
    # âŒ Sin resources definidos
```

**CaracterÃ­sticas**:
- âš ï¸ **Primera en ser evicted**: Menor prioridad
- ğŸ² **Sin garantÃ­as**: Puede usar recursos disponibles, pero sin protecciÃ³n
- ğŸ’¸ **Bajo costo**: No reserva recursos
- ğŸ¯ **Uso**: Batch jobs no crÃ­ticos, tareas de limpieza, desarrollo/testing

### Tabla Comparativa QoS

| QoS Class | Request | Limit | Eviction Priority | Uso TÃ­pico |
|-----------|---------|-------|-------------------|------------|
| **Guaranteed** | âœ… CPU + Memory | âœ… = Request | ğŸ›¡ï¸ 3 (Ãºltima) | Prod crÃ­tica, DBs |
| **Burstable** | âœ… Al menos 1 recurso | âš–ï¸ Opcional o > Request | âš ï¸ 2 (media) | Web apps, APIs |
| **BestEffort** | âŒ Ninguno | âŒ Ninguno | ğŸ”¥ 1 (primera) | Batch jobs, testing |

### Verificar QoS Class de un Pod

```bash
# Ver QoS class asignada
kubectl get pod <pod-name> -o jsonpath='{.status.qosClass}'

# Ejemplo completo con detalles
kubectl describe pod <pod-name> | grep QoS
```

### Ejemplo de Eviction por QoS

Supongamos un nodo con 4 GB de memoria que se queda sin memoria:

```yaml
# Pod A - Guaranteed (usando 1 GB, limit 1 GB)
qosClass: Guaranteed

# Pod B - Burstable (usando 1.5 GB, request 500 MB, limit 2 GB)
qosClass: Burstable

# Pod C - BestEffort (usando 500 MB, sin limits)
qosClass: BestEffort
```

**Orden de eviction**:
1. âŒ **Pod C** (BestEffort) â†’ evicted primero
2. Si aÃºn hay presiÃ³n â†’ âŒ **Pod B** (Burstable, excede request)
3. Solo en extremo â†’ âŒ **Pod A** (Guaranteed)

---

## ConfiguraciÃ³n de Recursos

### Sintaxis BÃ¡sica

#### Para contenedores individuales:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "250m"          # MÃ­nimo garantizado
        memory: "128Mi"
        ephemeral-storage: "1Gi"
      limits:
        cpu: "500m"          # MÃ¡ximo permitido
        memory: "256Mi"
        ephemeral-storage: "2Gi"
```

### Pod con MÃºltiples Contenedores

Los requests/limits del **Pod** son la **suma** de todos sus contenedores:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "250m"
        memory: "64Mi"
      limits:
        cpu: "500m"
        memory: "128Mi"
  
  - name: sidecar
    image: log-forwarder
    resources:
      requests:
        cpu: "250m"
        memory: "64Mi"
      limits:
        cpu: "500m"
        memory: "128Mi"

# Recursos totales del Pod:
# requests: cpu=500m, memory=128Mi
# limits:   cpu=1, memory=256Mi
```

### Init Containers

Los init containers **NO se suman** a los recursos del Pod. Se usa el **mÃ¡ximo**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-demo
spec:
  initContainers:
  - name: init-setup
    image: busybox
    resources:
      requests:
        cpu: "1"         # â† Init necesita 1 CPU
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "512Mi"
  
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        cpu: "250m"      # â† App necesita 250m CPU
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "256Mi"

# Recursos efectivos del Pod:
# requests: cpu=1 (mÃ¡ximo entre init y app), memory=512Mi
# limits:   cpu=1, memory=512Mi
```

**Regla de cÃ¡lculo**:
```
Pod Request = MAX(
  MAX(init_container_requests),
  SUM(container_requests)
)
```

### Recursos por Namespace (con LimitRange)

Puedes establecer valores por defecto con `LimitRange`:

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: default-resources
  namespace: development
spec:
  limits:
  - default:  # Limits por defecto si no se especifican
      cpu: "500m"
      memory: "256Mi"
    defaultRequest:  # Requests por defecto si no se especifican
      cpu: "250m"
      memory: "128Mi"
    max:  # MÃ¡ximo permitido
      cpu: "2"
      memory: "2Gi"
    min:  # MÃ­nimo requerido
      cpu: "100m"
      memory: "64Mi"
    type: Container
```

**Ver referencia completa**: [MÃ³dulo 12 - LimitRange](../modulo-12-limitrange/)

---

## Pod-level Resources (Beta K8s 1.34)

### IntroducciÃ³n

**Desde Kubernetes 1.34** (beta), puedes especificar recursos **a nivel de Pod** en lugar de solo por contenedor.

**âš ï¸ Requisito**: Feature gate `PodLevelResources` habilitado (default: true en 1.34+)

### Â¿Por quÃ© Pod-level resources?

**Problema actual**: DifÃ­cil calcular recursos exactos cuando tienes muchos contenedores

**Ejemplo**:
```yaml
# âŒ DifÃ­cil: Asignar recursos a 5 sidecars
containers:
- name: app
- name: sidecar1
- name: sidecar2
- name: sidecar3
- name: sidecar4
- name: sidecar5
# Â¿CuÃ¡nto CPU dar a cada uno? DifÃ­cil predecir
```

**SoluciÃ³n**: Especificar presupuesto total del Pod

```yaml
# âœ… FÃ¡cil: Presupuesto total del Pod
spec:
  resources:
    limits:
      cpu: "2"
      memory: "2Gi"
  # Los contenedores comparten estos recursos
```

### Sintaxis Pod-level

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-level-demo
spec:
  resources:  # â† A nivel de Pod
    requests:
      cpu: "1"
      memory: "1Gi"
    limits:
      cpu: "2"
      memory: "2Gi"
  
  containers:
  - name: app
    image: nginx
    resources:  # â† Opcional: lÃ­mite individual
      limits:
        cpu: "1"
        memory: "1Gi"
  
  - name: sidecar
    image: logger
    # Sin resources â†’ comparte del presupuesto del Pod
```

### Reglas de CombinaciÃ³n

#### 1. Solo Pod-level resources:

```yaml
spec:
  resources:
    limits:
      cpu: "2"
      memory: "2Gi"
  containers:
  - name: app
    # Sin resources
  - name: sidecar
    # Sin resources
# Los contenedores comparten 2 CPU y 2 Gi entre ellos
```

#### 2. Pod-level + Container-level:

```yaml
spec:
  resources:
    limits:
      cpu: "2"       # â† Presupuesto total
      memory: "2Gi"
  containers:
  - name: app
    resources:
      limits:
        cpu: "1"     # â† LÃ­mite individual (dentro del presupuesto)
        memory: "1Gi"
  - name: sidecar
    # Sin limits â†’ puede usar hasta (2-1)=1 CPU restante
```

**âš ï¸ ValidaciÃ³n**:
```
SUM(container.limits) <= pod.limits
```

Si la suma de lÃ­mites de contenedores excede el lÃ­mite del Pod â†’ âŒ Error de validaciÃ³n

### Ventajas

âœ… **Simplifica configuraciÃ³n** con muchos contenedores  
âœ… **Resource sharing** entre contenedores del mismo Pod  
âœ… **Reduce over-provisioning** (no necesitas calcular lÃ­mites exactos por contenedor)  
âœ… **Mejor utilizaciÃ³n** de recursos idle entre contenedores  

### Limitaciones

âš ï¸ **Solo CPU y Memory** (no ephemeral-storage, extended resources)  
âš ï¸ **Beta feature** (puede cambiar en futuras versiones)  
âš ï¸ Requiere K8s 1.34+ con feature gate habilitado

---

## Ephemeral Storage

### Â¿QuÃ© es Ephemeral Storage?

Almacenamiento **local temporal** en el nodo, sin garantÃ­a de durabilidad a largo plazo.

**Incluye**:
1. VolÃºmenes `emptyDir` (excepto tmpfs)
2. Logs de contenedor a nivel de nodo (`/var/log`)
3. Writable container layers (imÃ¡genes de contenedor)

### ConfiguraciÃ³n

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ephemeral-demo
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        ephemeral-storage: "2Gi"
      limits:
        ephemeral-storage: "4Gi"
    volumeMounts:
    - name: cache
      mountPath: /cache
  
  volumes:
  - name: cache
    emptyDir:
      sizeLimit: "1Gi"  # LÃ­mite del volumen especÃ­fico
```

### Enforcement

**Kubelet monitorea** el uso de ephemeral storage:

1. **Periodic scanning** (por defecto):
   - Escaneo programado de directorios
   - Mide uso de espacio en disco
   
2. **Filesystem project quotas** (XFS):
   - MÃ¡s eficiente
   - Enforcement en tiempo real

**Si se excede el lÃ­mite** â†’ Pod eviction

### âš ï¸ Consideraciones CrÃ­ticas

#### 1. tmpfs emptyDir NO es ephemeral-storage

```yaml
volumes:
- name: tmp
  emptyDir:
    medium: Memory  # â† Esto es tmpfs (en RAM)
```

**Comportamiento**:
- âŒ NO cuenta como `ephemeral-storage`
- âœ… Cuenta como **uso de memoria** del contenedor
- Afecta el lÃ­mite de `memory`, no de `ephemeral-storage`

#### 2. emptyDir sin sizeLimit puede consumir todo el lÃ­mite del Pod

```yaml
volumes:
- name: data
  emptyDir: {}  # âš ï¸ Sin sizeLimit
```

**Riesgo**:
- Puede consumir hasta el `limits.memory` del Pod
- Puede causar OOM si se llena
- Puede causar denial of service en el nodo

**ğŸ’¡ Best Practice**: Siempre especificar `sizeLimit`:

```yaml
volumes:
- name: data
  emptyDir:
    sizeLimit: "500Mi"  # âœ… LÃ­mite explÃ­cito
```

#### 3. MÃºltiples emptyDir pueden agotar memoria

```yaml
volumes:
- name: cache
  emptyDir: {}
- name: temp
  emptyDir: {}
- name: logs
  emptyDir: {}
# âš ï¸ Cada uno puede consumir hasta limits.memory
```

**SoluciÃ³n**: ResourceQuota + LimitRange en namespace

### Monitoreo

```bash
# Ver uso de ephemeral storage por Pod
kubectl describe node <node-name> | grep -A 10 "Allocated resources"

# Ver eventos de eviction por storage
kubectl get events --all-namespaces | grep -i evict
```

---

## Extended Resources

### DefiniciÃ³n

Recursos **fuera del dominio `kubernetes.io`** gestionados por:
1. Device plugins (node-level)
2. Scheduler extenders (cluster-level)
3. Dynamic Resource Allocation - DRA (K8s 1.26+)

### Tipos Comunes

#### 1. GPUs

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
  - name: cuda-app
    image: nvidia/cuda:11.0-base
    resources:
      limits:
        nvidia.com/gpu: 2  # Solicita 2 GPUs
```

#### 2. FPGAs

```yaml
resources:
  limits:
    xilinx.com/fpga: 1
```

#### 3. Custom Hardware

```yaml
resources:
  limits:
    example.com/nic: 1  # Network Interface Card especÃ­fica
```

### CaracterÃ­sticas

âš ï¸ **Restricciones**:
1. âœ… Solo **cantidades enteras** (no `0.5`, `1.5m`)
2. âœ… Request == Limit (deben ser iguales si ambos existen)
3. âœ… **No se puede overcommit**

### Anunciar Extended Resources (node-level)

```bash
# Ejemplo: AÃ±adir 5 recursos "example.com/foo" a un nodo
curl --header "Content-Type: application/json-patch+json" \
  --request PATCH \
  --data '[{"op": "add", "path": "/status/capacity/example.com~1foo", "value": "5"}]' \
  http://k8s-master:8080/api/v1/nodes/node-1/status
```

**Nota**: `~1` es la codificaciÃ³n del carÃ¡cter `/` en JSON-Patch

### Device Plugins

Los device plugins **anuncian automÃ¡ticamente** recursos:

**Ejemplos**:
- [NVIDIA GPU Device Plugin](https://github.com/NVIDIA/k8s-device-plugin)
- [Intel Device Plugins](https://github.com/intel/intel-device-plugins-for-kubernetes)
- [AMD GPU Device Plugin](https://github.com/RadeonOpenCompute/k8s-device-plugin)

**InstalaciÃ³n tÃ­pica** (NVIDIA GPU):

```bash
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/nvidia-device-plugin.yml
```

---

## Comportamiento del Scheduler

### Proceso de Scheduling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Pod creado con requests                                   â”‚
â”‚    requests: cpu=500m, memory=1Gi                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Scheduler evalÃºa CADA nodo                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ Nodo A                                               â”‚  â”‚
â”‚    â”‚  Capacity:    cpu=4, memory=8Gi                      â”‚  â”‚
â”‚    â”‚  Allocatable: cpu=3.8, memory=7.5Gi (despuÃ©s daemons)â”‚  â”‚
â”‚    â”‚  Allocated:   cpu=2.5, memory=5Gi (Pods existentes)  â”‚  â”‚
â”‚    â”‚  Available:   cpu=1.3, memory=2.5Gi                  â”‚  â”‚
â”‚    â”‚                                                      â”‚  â”‚
â”‚    â”‚  Check: 500m <= 1.3 âœ… AND 1Gi <= 2.5Gi âœ…           â”‚  â”‚
â”‚    â”‚  â†’ Nodo A es CANDIDATO                               â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ Nodo B                                               â”‚  â”‚
â”‚    â”‚  Available: cpu=300m, memory=3Gi                     â”‚  â”‚
â”‚    â”‚  Check: 500m <= 300m âŒ                              â”‚  â”‚
â”‚    â”‚  â†’ Nodo B RECHAZADO                                  â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. De los candidatos, aplica scoring                         â”‚
â”‚    (NodeResourcesBalancedAllocation, etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Selecciona nodo con mejor score                           â”‚
â”‚    Pod scheduled en Nodo A                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Puntos Clave

1. **Solo usa requests** (NO limits):
   ```
   sum(pod.requests) <= node.allocatable
   ```

2. **No considera uso real**:
   - Un nodo puede tener 90% de CPU idle
   - Pero si los requests suman 100% â†’ NO programa mÃ¡s Pods

3. **Node.Allocatable < Node.Capacity**:
   - Daemons del sistema reservan recursos
   - `kubelet`, `kube-proxy`, `system daemons`

### Ver Capacidad y Allocatable

```bash
# Ver recursos del nodo
kubectl describe node <node-name>

# Salida ejemplo:
# Capacity:
#   cpu:                4
#   memory:             8Gi
# Allocatable:
#   cpu:                3800m
#   memory:             7500Mi
# 
# Non-terminated Pods:
#   Namespace  Name        CPU Requests  Memory Requests
#   ---------  ----        ------------  ---------------
#   default    pod-a       500m (13%)    1Gi (13%)
#   default    pod-b       250m (6%)     512Mi (6%)
# 
# Allocated resources:
#   CPU Requests: 750m (19%)
#   Memory Requests: 1536Mi (20%)
```

### Fallo de Scheduling

Si no encuentra nodo â†’ Pod queda en **Pending**:

```bash
kubectl describe pod <pod-name>

# Events:
# Type     Reason            Message
# ----     ------            -------
# Warning  FailedScheduling  0/3 nodes available: insufficient cpu
```

---

## Enforcement de LÃ­mites

### CPU Throttling

#### Mecanismo (Linux cgroups)

**CPU limits se enforzan con throttling** (restricciÃ³n de tiempo de CPU):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PerÃ­odo de CPU: 100ms (cfs_period_us=100000)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚ Contenedor con limit cpu=1 â†’ quota=100ms por perÃ­odo       â”‚
â”‚                                                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 0ms                     50ms                 100ms   â”‚   â”‚
â”‚ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RUNNING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚   â”‚
â”‚ â”‚                                      â””â”€ Usa 50ms     â”‚   â”‚
â”‚ â”‚                                                      â”‚   â”‚
â”‚ â”‚  âœ… OK: Solo usÃ³ 50ms de 100ms permitidos            â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ 0ms                                            100ms â”‚   â”‚
â”‚ â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RUNNING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚   â”‚
â”‚ â”‚                                                â”‚     â”‚   â”‚
â”‚ â”‚  âš ï¸ THROTTLED: UsÃ³ 100ms completos             â”‚     â”‚   â”‚
â”‚ â”‚  Siguiente perÃ­odo: debe esperar hasta obtener cuota â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Consecuencias del Throttling

```yaml
resources:
  limits:
    cpu: "500m"  # 0.5 CPU
```

**Si el contenedor intenta usar mÃ¡s**:
- âš ï¸ **Kernel throttles** el proceso
- â±ï¸ **Latencia aumenta** (requests tardan mÃ¡s)
- ğŸ”¥ **CPU usage = 100%** del lÃ­mite (stuck)
- âŒ **NO se termina** el contenedor

**SÃ­ntomas**:
- AplicaciÃ³n lenta
- Timeouts en requests HTTP
- `kubectl top pod` muestra CPU en el lÃ­mite

#### Detectar Throttling

```bash
# Ver mÃ©tricas de throttling (requiere cAdvisor/metrics-server)
kubectl exec -it <pod-name> -- cat /sys/fs/cgroup/cpu/cpu.stat

# Salida:
# nr_periods 1000        # NÃºmero de perÃ­odos
# nr_throttled 500       # CuÃ¡ntos fueron throttled
# throttled_time 25000   # Tiempo total throttled (nanosegundos)
```

**ğŸ’¡ Si `nr_throttled` es alto** â†’ Aumenta el CPU limit

### Memory OOMKilled

#### Mecanismo (Linux OOM Killer)

**Memory limits se enforzan con terminaciÃ³n del proceso**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Contenedor con limit memory=512Mi                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ Uso de memoria crece gradualmente:                       â”‚
â”‚                                                          â”‚
â”‚  256Mi  âœ… OK                                            â”‚
â”‚  384Mi  âœ… OK                                            â”‚
â”‚  512Mi  âš ï¸ En el lÃ­mite                                  â”‚
â”‚  513Mi  âŒ EXCEDE LÃMITE                                 â”‚
â”‚         â”‚                                                â”‚
â”‚         â””â”€â”€â–º Kernel detecta exceso de memoria            â”‚
â”‚              â”‚                                           â”‚
â”‚              â””â”€â”€â–º OOM Killer selecciona proceso          â”‚
â”‚                   â”‚                                      â”‚
â”‚                   â””â”€â”€â–º SIGKILL al proceso                â”‚
â”‚                        (tÃ­picamente PID 1)               â”‚
â”‚                        â”‚                                 â”‚
â”‚                        â””â”€â”€â–º Exit Code: 137               â”‚
â”‚                             Reason: OOMKilled            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Consecuencias del OOMKilled

```yaml
resources:
  limits:
    memory: "512Mi"
```

**Si el contenedor excede el lÃ­mite**:
- âŒ **Kernel termina** el proceso (SIGKILL)
- ğŸ”„ **Pod puede reiniciarse** (si `restartPolicy: Always`)
- ğŸ“Š **Restart Count** aumenta
- âš ï¸ **CrashLoopBackOff** si ocurre repetidamente

#### Detectar OOMKilled

```bash
# Ver eventos del Pod
kubectl describe pod <pod-name>

# Buscar en eventos:
# Last State:     Terminated
#   Reason:       OOMKilled
#   Exit Code:    137

# Ver restart count
kubectl get pod <pod-name> -o jsonpath='{.status.containerStatuses[0].restartCount}'

# Ver Ãºltimo estado
kubectl get pod <pod-name> -o jsonpath='{.status.containerStatuses[0].lastState}'
```

#### Prevenir OOMKilled

1. **Aumentar memory limit** (si la app necesita mÃ¡s):
   ```yaml
   limits:
     memory: "1Gi"  # â† Aumentado
   ```

2. **Investigar memory leaks**:
   ```bash
   # Heap dump (Java)
   kubectl exec -it <pod> -- jmap -dump:file=/tmp/heap.bin 1
   
   # Ver uso detallado
   kubectl top pod <pod-name> --containers
   ```

3. **Usar memory profiling**:
   - Java: JVM heap analysis
   - Python: `memory_profiler`
   - Go: `pprof`

### Ephemeral Storage Eviction

```yaml
resources:
  limits:
    ephemeral-storage: "2Gi"
```

**Si excede el lÃ­mite**:
- âŒ **Pod eviction** (no OOMKill)
- ğŸ“ Reason: `Evicted`
- ğŸš« **No se reinicia automÃ¡ticamente**
- âš ï¸ Debes recrear el Pod

```bash
# Ver Pods evicted
kubectl get pods --field-selector=status.phase=Failed

# Ver razÃ³n
kubectl describe pod <evicted-pod>
# Reason: Evicted
# Message: Pod ephemeral local storage usage exceeds the total limit of containers 2Gi
```

---

## Monitoreo de Recursos

### Metrics Server

**InstalaciÃ³n** (si no estÃ¡ instalado):

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### kubectl top

#### Ver uso de Pods

```bash
# Todos los Pods del namespace
kubectl top pods

# Salida:
# NAME                CPU(cores)   MEMORY(bytes)
# nginx-deployment    10m          50Mi
# redis-pod           5m           100Mi

# Pod especÃ­fico con contenedores
kubectl top pod <pod-name> --containers

# Todos los namespaces
kubectl top pods --all-namespaces

# Ordenar por CPU
kubectl top pods --sort-by=cpu

# Ordenar por memoria
kubectl top pods --sort-by=memory
```

#### Ver uso de Nodos

```bash
# Todos los nodos
kubectl top nodes

# Salida:
# NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# node-1     500m         25%    2Gi             40%
# node-2     800m         40%    3Gi             60%
```

### Ver Recursos Asignados vs Disponibles

```bash
# Recursos asignados en un nodo
kubectl describe node <node-name>

# Extracto relevante:
# Allocated resources:
#   (Total limits may be over 100%, i.e., overcommitted)
#   Resource           Requests      Limits
#   --------           --------      ------
#   cpu                1500m (37%)   3000m (75%)
#   memory             3Gi (40%)     6Gi (80%)
#   ephemeral-storage  0 (0%)        0 (0%)
```

### Alertas y Monitoreo Avanzado

#### Prometheus + Grafana

**MÃ©tricas clave**:

```yaml
# CPU throttling
rate(container_cpu_cfs_throttled_seconds_total[5m])

# Memory usage vs limit
container_memory_usage_bytes / container_spec_memory_limit_bytes

# OOMKilled count
rate(container_oom_events_total[5m])

# Pods en estado Pending
kube_pod_status_phase{phase="Pending"}
```

#### Configurar alertas

```yaml
# Ejemplo alerta Prometheus
groups:
- name: resources
  rules:
  - alert: HighMemoryUsage
    expr: |
      container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
    for: 5m
    annotations:
      summary: "Container {{ $labels.container }} using >90% memory"
  
  - alert: CPUThrottling
    expr: |
      rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.1
    for: 10m
    annotations:
      summary: "Container {{ $labels.container }} is being throttled"
```

---

## Best Practices

### 1. Siempre Especifica Requests y Limits

âŒ **Evitar**:
```yaml
# Sin resources - QoS: BestEffort
containers:
- name: app
  image: nginx
```

âœ… **Recomendado**:
```yaml
# Con resources - QoS: Burstable o Guaranteed
containers:
- name: app
  image: nginx
  resources:
    requests:
      cpu: "250m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "256Mi"
```

### 2. Request = Limit para ProducciÃ³n CrÃ­tica

âœ… **Aplicaciones stateful, bases de datos**:
```yaml
# QoS: Guaranteed
resources:
  requests:
    cpu: "2"
    memory: "4Gi"
  limits:
    cpu: "2"
    memory: "4Gi"
```

**Ventajas**:
- ğŸ›¡ï¸ MÃ¡xima protecciÃ³n contra eviction
- ğŸ“Š Uso predecible de recursos
- ğŸ¯ No sufre throttling inesperado

### 3. Request < Limit para Aplicaciones Bursty

âœ… **APIs, web apps con picos de trÃ¡fico**:
```yaml
# QoS: Burstable
resources:
  requests:
    cpu: "500m"
    memory: "256Mi"
  limits:
    cpu: "2"
    memory: "1Gi"
```

**Ventajas**:
- ğŸ“ˆ Puede manejar picos de carga
- ğŸ’° Usa menos recursos en estado idle
- âš–ï¸ Balance entre costo y flexibilidad

### 4. Calcula Requests BasÃ¡ndote en Uso Real

**Proceso recomendado**:

1. **Empezar conservador**:
   ```yaml
   requests:
     cpu: "100m"
     memory: "128Mi"
   ```

2. **Monitorear en staging/desarrollo**:
   ```bash
   kubectl top pods --containers
   ```

3. **Ajustar basÃ¡ndote en percentil 95**:
   ```yaml
   # Si p95 de uso es: cpu=250m, memory=200Mi
   requests:
     cpu: "300m"      # +20% margen
     memory: "250Mi"
   ```

4. **Limits = 2x Requests** (regla general):
   ```yaml
   limits:
     cpu: "600m"
     memory: "500Mi"
   ```

### 5. Usa LimitRange para Defaults

âœ… **Establecer defaults en namespace**:
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: default-limits
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "256Mi"
    defaultRequest:
      cpu: "250m"
      memory: "128Mi"
    type: Container
```

**Beneficio**: Pods sin resources definidos obtienen valores seguros automÃ¡ticamente

### 6. Usa ResourceQuota para Limitar Namespace

âœ… **Prevenir que un namespace consuma todo el clÃºster**:
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: development
spec:
  hard:
    requests.cpu: "10"
    requests.memory: "20Gi"
    limits.cpu: "20"
    limits.memory: "40Gi"
    pods: "50"
```

**Ver referencia**: [MÃ³dulo 13 - ResourceQuota](../modulo-13-resourcequota/)

### 7. Monitorea Throttling y OOMKilled

```bash
# Script para detectar problemas
#!/bin/bash

# Pods con restart count alto (posible OOMKilled)
kubectl get pods --all-namespaces -o json | \
  jq -r '.items[] | select(.status.containerStatuses[].restartCount > 5) | 
  "\(.metadata.namespace)/\(.metadata.name): \(.status.containerStatuses[].restartCount) restarts"'

# Pods OOMKilled recientemente
kubectl get events --all-namespaces --field-selector reason=OOMKilled

# Pods en CrashLoopBackOff
kubectl get pods --all-namespaces --field-selector status.phase=Failed
```

### 8. Ephemeral Storage: Siempre Define sizeLimit

âŒ **Evitar**:
```yaml
volumes:
- name: cache
  emptyDir: {}  # Puede llenar el disco del nodo
```

âœ… **Recomendado**:
```yaml
volumes:
- name: cache
  emptyDir:
    sizeLimit: "1Gi"
```

### 9. Considera Vertical Pod Autoscaler (VPA)

**VPA ajusta automÃ¡ticamente** requests/limits basÃ¡ndose en uso histÃ³rico:

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: nginx-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: nginx
  updatePolicy:
    updateMode: "Auto"  # Actualiza automÃ¡ticamente
```

**Ventajas**:
- ğŸ¤– OptimizaciÃ³n automÃ¡tica
- ğŸ“Š Basado en datos reales
- ğŸ’° Reduce costos eliminando over-provisioning

**LimitaciÃ³n**: No compatible con HPA (Horizontal Pod Autoscaler) en la misma mÃ©trica

### 10. Testing de LÃ­mites

âœ… **Probar comportamiento bajo presiÃ³n**:

```bash
# Simular carga de CPU
kubectl run stress-cpu --image=polinux/stress --restart=Never -- stress --cpu 2 --timeout 60s

# Simular carga de memoria
kubectl run stress-mem --image=polinux/stress --restart=Never -- stress --vm 1 --vm-bytes 512M --timeout 60s

# Ver comportamiento
kubectl top pod stress-cpu
kubectl top pod stress-mem
```

---

## Troubleshooting

### Problema 1: Pod Pending - FailedScheduling

#### SÃ­ntoma

```bash
kubectl get pods
# NAME    READY   STATUS    RESTARTS   AGE
# my-pod  0/1     Pending   0          5m
```

#### DiagnÃ³stico

```bash
kubectl describe pod my-pod

# Events:
# Type     Reason            Message
# ----     ------            -------
# Warning  FailedScheduling  0/3 nodes available: insufficient cpu
```

#### Causas Comunes

1. **Requests demasiado altos**:
   ```yaml
   requests:
     cpu: "10"  # â† Si ningÃºn nodo tiene 10 CPUs disponibles
   ```

2. **Nodos saturados**:
   ```bash
   kubectl describe nodes
   # Allocated resources: cpu 95%, memory 90%
   ```

3. **Taints en nodos**:
   ```bash
   kubectl describe node <node> | grep Taints
   # Taints: dedicated=gpu:NoSchedule
   ```

#### Soluciones

**1. Reducir requests**:
```yaml
requests:
  cpu: "500m"  # â† MÃ¡s razonable
```

**2. Escalar el clÃºster** (aÃ±adir nodos):
```bash
# GKE
gcloud container clusters resize my-cluster --num-nodes=5

# EKS
eksctl scale nodegroup --cluster=my-cluster --name=ng-1 --nodes=5

# AKS
az aks scale --resource-group myRG --name myCluster --node-count 5
```

**3. Limpiar Pods innecesarios**:
```bash
kubectl delete deployment <unused-deployment>
```

**4. AÃ±adir tolerations** (si hay taints):
```yaml
tolerations:
- key: "dedicated"
  operator: "Equal"
  value: "gpu"
  effect: "NoSchedule"
```

### Problema 2: Container OOMKilled

#### SÃ­ntoma

```bash
kubectl get pods
# NAME    READY   STATUS             RESTARTS   AGE
# my-pod  0/1     CrashLoopBackOff   5          3m

kubectl describe pod my-pod
# Last State:     Terminated
#   Reason:       OOMKilled
#   Exit Code:    137
```

#### DiagnÃ³stico

```bash
# Ver restart count
kubectl get pod my-pod -o jsonpath='{.status.containerStatuses[0].restartCount}'
# Output: 5

# Ver eventos
kubectl get events --field-selector involvedObject.name=my-pod

# Ver logs antes del crash
kubectl logs my-pod --previous
```

#### Causas Comunes

1. **Memory limit demasiado bajo**:
   ```yaml
   limits:
     memory: "128Mi"  # â† App necesita mÃ¡s
   ```

2. **Memory leak** en la aplicaciÃ³n

3. **Pico inesperado** de memoria

#### Soluciones

**1. Aumentar memory limit**:
```yaml
limits:
  memory: "512Mi"  # â† Incrementado
```

**2. Investigar memory leak**:
```bash
# Java
kubectl exec -it my-pod -- jmap -histo:live 1 | head -20

# Python
kubectl exec -it my-pod -- python -m memory_profiler app.py

# Node.js
kubectl exec -it my-pod -- node --inspect app.js
```

**3. Configurar heap size** (Java):
```yaml
env:
- name: JAVA_OPTS
  value: "-Xmx400m -Xms400m"  # 80% del memory limit (500Mi)
```

**4. Usar memory profiling** en desarrollo

### Problema 3: CPU Throttling - Alta Latencia

#### SÃ­ntoma

```bash
# AplicaciÃ³n lenta, timeouts
kubectl top pod my-pod
# NAME     CPU(cores)   MEMORY(bytes)
# my-pod   500m         200Mi

# CPU stuck en el lÃ­mite
```

#### DiagnÃ³stico

```bash
# Ver throttling stats (requiere acceso al nodo)
kubectl exec -it my-pod -- cat /sys/fs/cgroup/cpu/cpu.stat
# nr_periods 1000
# nr_throttled 800  # â† 80% del tiempo throttled!
# throttled_time 400000000000

# Ver mÃ©tricas Prometheus
rate(container_cpu_cfs_throttled_seconds_total{pod="my-pod"}[5m])
```

#### Causas Comunes

1. **CPU limit demasiado bajo**:
   ```yaml
   limits:
     cpu: "250m"  # â† App necesita mÃ¡s
   ```

2. **Picos de carga**

3. **Ineficiencia en el cÃ³digo**

#### Soluciones

**1. Aumentar CPU limit**:
```yaml
limits:
  cpu: "1"  # â† Incrementado
```

**2. Optimizar cÃ³digo**:
- Profiling de CPU
- Reducir operaciones costosas
- Usar caching

**3. Horizontal scaling** en lugar de vertical:
```yaml
# Deployment con HPA
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### Problema 4: Ephemeral Storage - Pod Evicted

#### SÃ­ntoma

```bash
kubectl get pods
# NAME    READY   STATUS    RESTARTS   AGE
# my-pod  0/1     Evicted   0          1h

kubectl describe pod my-pod
# Status:  Failed
# Reason:  Evicted
# Message: Pod ephemeral local storage usage exceeds the total limit
```

#### DiagnÃ³stico

```bash
# Ver uso de storage (si el Pod aÃºn existe)
kubectl exec -it my-pod -- df -h

# Ver eventos
kubectl get events | grep -i evict
```

#### Causas Comunes

1. **emptyDir sin sizeLimit**:
   ```yaml
   volumes:
   - name: cache
     emptyDir: {}  # â† Puede crecer sin lÃ­mite
   ```

2. **Logs excesivos**

3. **Cache no limpiado**

#### Soluciones

**1. Definir sizeLimit**:
```yaml
volumes:
- name: cache
  emptyDir:
    sizeLimit: "1Gi"
```

**2. Aumentar ephemeral-storage limit**:
```yaml
limits:
  ephemeral-storage: "5Gi"
```

**3. Log rotation**:
```yaml
# Configurar en la app o usar logrotate
env:
- name: LOG_MAX_SIZE
  value: "100MB"
- name: LOG_MAX_FILES
  value: "3"
```

**4. Cleanup periÃ³dico**:
```yaml
# Cronjob para limpiar cache
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cache-cleanup
spec:
  schedule: "0 */6 * * *"  # Cada 6 horas
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: cleanup
            image: busybox
            command: ["/bin/sh", "-c", "rm -rf /cache/*"]
            volumeMounts:
            - name: cache
              mountPath: /cache
```

### Problema 5: ResourceQuota - No Puedo Crear Pods

#### SÃ­ntoma

```bash
kubectl create -f my-pod.yaml
# Error from server (Forbidden): pods "my-pod" is forbidden: 
# exceeded quota: compute-quota, requested: requests.cpu=1, 
# used: requests.cpu=9, limited: requests.cpu=10
```

#### DiagnÃ³stico

```bash
# Ver quotas del namespace
kubectl describe resourcequota -n my-namespace

# Output:
# Name:            compute-quota
# Namespace:       my-namespace
# Resource         Used   Hard
# --------         ----   ----
# requests.cpu     9      10     # â† Solo 1 CPU disponible
# requests.memory  18Gi   20Gi
```

#### Soluciones

**1. Reducir requests del nuevo Pod**:
```yaml
requests:
  cpu: "500m"  # â† De 1 a 0.5
```

**2. Eliminar Pods innecesarios**:
```bash
kubectl delete deployment <unused-app>
```

**3. Aumentar quota** (si tienes permisos):
```bash
kubectl patch resourcequota compute-quota -n my-namespace --patch '
spec:
  hard:
    requests.cpu: "20"
    requests.memory: "40Gi"
'
```

### Tabla Resumen de Troubleshooting

| SÃ­ntoma | Exit Code | Reason | SoluciÃ³n Principal |
|---------|-----------|--------|-------------------|
| Pending | - | FailedScheduling | Reducir requests o aÃ±adir nodos |
| CrashLoopBackOff | 137 | OOMKilled | Aumentar memory limit |
| Lentitud | - | CPU Throttling | Aumentar CPU limit o HPA |
| Evicted | - | Ephemeral storage | Definir sizeLimit, aumentar limite |
| Forbidden | - | ResourceQuota | Reducir requests o aumentar quota |

---

## Ejemplos PrÃ¡cticos

Ver la carpeta [`ejemplos/`](./ejemplos/) para ejemplos completos:

1. **[BÃ¡sico - Requests y Limits](./ejemplos/01-basico/requests-limits-basic.yaml)**
   - ConfiguraciÃ³n simple de resources
   - MÃºltiples contenedores
   - Init containers

2. **[QoS Classes](./ejemplos/02-qos/qos-classes.yaml)**
   - Guaranteed
   - Burstable
   - BestEffort
   - ComparaciÃ³n de comportamiento

3. **[Ephemeral Storage](./ejemplos/03-ephemeral/ephemeral-storage.yaml)**
   - emptyDir con sizeLimit
   - Limits de ephemeral-storage
   - Monitoreo de uso

4. **[Pod-level Resources](./ejemplos/04-pod-level/pod-level-resources.yaml)**
   - Feature beta K8s 1.34
   - Presupuesto total del Pod
   - Sharing entre contenedores

5. **[Extended Resources](./ejemplos/05-extended/extended-resources.yaml)**
   - GPU requests
   - Custom resources
   - Device plugins

6. **[SimulaciÃ³n OOMKilled](./ejemplos/06-troubleshooting/oomkilled-simulation.yaml)**
   - Memory leak intencional
   - Observar restart count
   - Ajustar lÃ­mites

7. **[CPU Throttling](./ejemplos/07-troubleshooting/cpu-throttling.yaml)**
   - Stress test de CPU
   - Detectar throttling
   - Optimizar lÃ­mites

---

## Laboratorios

### Lab 01: Fundamentos de Resource Limits (35-40 min)

**Objetivos**:
- Configurar requests y limits
- Observar comportamiento de QoS classes
- Usar kubectl top para monitoreo

**[Ver laboratorio completo](./laboratorios/lab-01-fundamentos.md)**

### Lab 02: Troubleshooting Avanzado (45-50 min)

**Objetivos**:
- Simular y resolver OOMKilled
- Detectar CPU throttling
- GestiÃ³n de ephemeral storage
- AnÃ¡lisis de mÃ©tricas

**[Ver laboratorio completo](./laboratorios/lab-02-troubleshooting.md)**

### Lab 03: OptimizaciÃ³n para ProducciÃ³n (50-60 min)

**Objetivos**:
- Pod-level resources (K8s 1.34)
- Vertical Pod Autoscaler (VPA)
- Best practices de sizing
- Monitoreo con Prometheus

**[Ver laboratorio completo](./laboratorios/lab-03-produccion.md)**

---

## Referencias

### DocumentaciÃ³n Oficial

- **Kubernetes Docs**: [Resource Management for Pods and Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- **API Reference**: [Container Resources](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#Container)
- **Quality of Service**: [Configure Quality of Service for Pods](https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/)
- **Ephemeral Storage**: [Ephemeral Volumes](https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/)

### MÃ³dulos Relacionados

- **[MÃ³dulo 10 - Namespaces y OrganizaciÃ³n](../modulo-10-namespaces-organizacion/)**: OrganizaciÃ³n de recursos
- **[MÃ³dulo 12 - LimitRange](../modulo-12-limitrange/)**: Defaults y restricciones por namespace
- **[MÃ³dulo 13 - ResourceQuota](../modulo-13-resourcequota/)**: LÃ­mites agregados por namespace
- **[MÃ³dulo 19 - Monitoring](../modulo-19-monitoring/)**: Monitoreo avanzado con Prometheus

### Herramientas

- **[Metrics Server](https://github.com/kubernetes-sigs/metrics-server)**: MÃ©tricas de recursos
- **[Vertical Pod Autoscaler](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)**: Ajuste automÃ¡tico de resources
- **[Goldilocks](https://github.com/FairwindsOps/goldilocks)**: Recomendaciones de resources
- **[kubectl-resource-view](https://github.com/appvia/kubectl-resource_view)**: Vista de recursos

### ArtÃ­culos y GuÃ­as

- **CNCF**: [Resource Requests and Limits Best Practices](https://www.cncf.io/blog/2023/01/13/kubernetes-resource-requests-and-limits/)
- **Google Cloud**: [Best practices for managing Kubernetes resources](https://cloud.google.com/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke)
- **AWS**: [Amazon EKS Best Practices - Resource Management](https://aws.github.io/aws-eks-best-practices/reliability/docs/dataplane/#configure-and-size-resource-requests-and-limits-for-all-workloads)

### Videos

- **Kubernetes Resource Management Explained** - KubeCon 2024
- **Right-sizing Kubernetes Applications** - Google Cloud Next

---

## Resumen

### Puntos Clave

1. **Requests** = MÃ­nimo garantizado (scheduler lo usa)
2. **Limits** = MÃ¡ximo permitido (kubelet lo enforza)
3. **QoS Classes**:
   - Guaranteed (request = limit) â†’ MÃ¡xima protecciÃ³n
   - Burstable (request < limit) â†’ Flexible
   - BestEffort (sin resources) â†’ Primera en eviction
4. **CPU**: Throttling (no termina)
5. **Memory**: OOMKilled (termina con Exit Code 137)
6. **Ephemeral Storage**: Eviction (no reinicia)

### Comandos Esenciales

```bash
# Monitoreo
kubectl top pods
kubectl top nodes
kubectl describe node <node>

# Troubleshooting
kubectl describe pod <pod>
kubectl logs <pod> --previous
kubectl get events --field-selector involvedObject.name=<pod>

# Recursos del cluster
kubectl describe resourcequota
kubectl describe limitrange
```

### Checklist para ProducciÃ³n

- [ ] Todos los Pods tienen requests y limits definidos
- [ ] Apps crÃ­ticas usan QoS Guaranteed (request = limit)
- [ ] emptyDir volumes tienen sizeLimit
- [ ] ResourceQuota configurado por namespace
- [ ] LimitRange con defaults sensatos
- [ ] Monitoreo de throttling y OOMKilled
- [ ] Alertas configuradas (Prometheus/Grafana)
- [ ] VPA considerado para optimizaciÃ³n automÃ¡tica
- [ ] Requests basados en uso real (no guess)
- [ ] Testing de lÃ­mites en staging

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025  
**VersiÃ³n de Kubernetes**: 1.28+  
**Autor**: Curso de Kubernetes - Arquitectura

