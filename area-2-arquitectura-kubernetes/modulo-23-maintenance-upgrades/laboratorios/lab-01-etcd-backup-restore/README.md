# Lab 01: etcd Backup y Restore

**Duraci√≥n estimada:** 30-45 minutos  
**Dificultad:** ‚≠ê‚≠ê‚≠ê Avanzado  
**Relevancia CKA:** üî¥ CR√çTICO (Troubleshooting 30%)

---

## üéØ Objetivos de Aprendizaje

Al completar este laboratorio, ser√°s capaz de:

- ‚úÖ Realizar backup completo de etcd usando `etcdctl`
- ‚úÖ Restaurar un cluster desde un snapshot de etcd
- ‚úÖ Verificar la integridad de backups de etcd
- ‚úÖ Automatizar procedimientos de backup/restore
- ‚úÖ Entender el almacenamiento de estado en Kubernetes
- ‚úÖ Diagnosticar problemas de p√©rdida de datos

---

## üìã Prerequisitos

Antes de comenzar, aseg√∫rate de:

1. ‚úÖ Tener un cluster Kubernetes funcional (kubeadm o similar)
2. ‚úÖ Acceso SSH al nodo control plane
3. ‚úÖ Permisos de root o sudo en el control plane
4. ‚úÖ Familiaridad con l√≠nea de comandos Linux
5. ‚úÖ Conocimiento b√°sico de etcd y su rol en K8s

**Verifica prerequisitos:**
```bash
# Verificar acceso a etcd
kubectl get pods -n kube-system | grep etcd

# Verificar versi√≥n de etcdctl
ETCDCTL_API=3 etcdctl version

# Verificar espacio en disco (necesitas ~500MB)
df -h /var/lib/etcd
```

üìñ **Ver detalles completos**: [SETUP.md](./SETUP.md)

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CONTROL PLANE NODE                        ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  API Server    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  etcd (Primary)  ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ  (6443)        ‚îÇ  Estado ‚îÇ  (2379)          ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                     ‚îÇ                        ‚îÇ
‚îÇ                                     ‚îÇ Snapshot               ‚îÇ
‚îÇ                                     ‚ñº                        ‚îÇ
‚îÇ                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ                             ‚îÇ  Backup File     ‚îÇ            ‚îÇ
‚îÇ                             ‚îÇ  /backup/        ‚îÇ            ‚îÇ
‚îÇ                             ‚îÇ  snapshot.db     ‚îÇ            ‚îÇ
‚îÇ                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                                     ‚îÇ                        ‚îÇ
‚îÇ                                     ‚îÇ Restore                ‚îÇ
‚îÇ                                     ‚ñº                        ‚îÇ
‚îÇ                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ                             ‚îÇ  etcd (Restored) ‚îÇ            ‚îÇ
‚îÇ                             ‚îÇ  /var/lib/etcd-  ‚îÇ            ‚îÇ
‚îÇ                             ‚îÇ  restored/       ‚îÇ            ‚îÇ
‚îÇ                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

FLUJO DE BACKUP:
1. etcdctl snapshot save ‚Üí /backup/snapshot-YYYYMMDD.db
2. etcdctl snapshot status ‚Üí Verificar integridad
3. Copiar a almacenamiento externo (opcional)

FLUJO DE RESTORE:
1. Detener API server temporalmente
2. etcdctl snapshot restore ‚Üí /var/lib/etcd-restored
3. Actualizar manifest de etcd
4. Reiniciar etcd con datos restaurados
```

---

## üìö Conceptos Clave

### ¬øQu√© es etcd?

**etcd** es una base de datos clave-valor distribuida que almacena **TODO el estado del cluster Kubernetes**:

- üóÇÔ∏è **Configuraci√≥n de recursos**: Pods, Services, ConfigMaps, Secrets
- üë• **RBAC**: Roles, RoleBindings, ServiceAccounts
- üîß **Estado del cluster**: Nodes, Events, Leases
- üì¶ **Custom Resources**: CRDs y sus instancias

**Sin etcd funcional = Cluster completamente no operacional** ‚ö†Ô∏è

### ¬øPor qu√© hacer backups de etcd?

**Escenarios de recuperaci√≥n cr√≠ticos**:

1. **P√©rdida de datos**: Corrupci√≥n de disco, eliminaci√≥n accidental
2. **Disaster recovery**: Fallo completo del datacenter
3. **Rollback de configuraci√≥n**: Revertir cambios masivos err√≥neos
4. **Migraci√≥n de cluster**: Mover estado a nuevo cluster
5. **Auditor√≠a**: Investigar estado hist√≥rico del cluster

**Frecuencia recomendada**:
- ‚úÖ **Producci√≥n**: Cada 4-6 horas + antes de cambios mayores
- ‚úÖ **Staging**: Diario
- ‚úÖ **Desarrollo**: Semanal

---

## üõ†Ô∏è Procedimiento del Laboratorio

### Parte 1: Preparar el Entorno

#### Paso 1.1: Crear datos de prueba

```bash
# Crear namespace de prueba
kubectl create namespace backup-test

# Crear varios recursos para validar el backup
kubectl create deployment nginx-backup --image=nginx:alpine \
  --replicas=3 -n backup-test

# Crear ConfigMap con datos
kubectl create configmap backup-config \
  --from-literal=database=production \
  --from-literal=version=1.0.0 \
  -n backup-test

# Crear Secret
kubectl create secret generic backup-secret \
  --from-literal=password=super-secret-123 \
  -n backup-test

# Verificar recursos creados
kubectl get all,cm,secret -n backup-test
```

**‚úÖ Verificaci√≥n esperada:**
```
NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          10s
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          10s
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          10s

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-backup   3/3     3            3           10s

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-backup-xxxxxxxxx   3         3         3       10s

NAME                      DATA   AGE
configmap/backup-config   2      5s

NAME                    TYPE     DATA   AGE
secret/backup-secret    Opaque   1      3s
```

#### Paso 1.2: Obtener informaci√≥n de etcd

```bash
# SSH al nodo control plane (si est√°s usando cluster remoto)
# ssh user@control-plane-node

# Identificar el pod de etcd
sudo kubectl get pods -n kube-system -l component=etcd -o wide

# Obtener configuraci√≥n de etcd desde el manifest
sudo cat /etc/kubernetes/manifests/etcd.yaml | grep -E "cert|key|server"
```

**Variables importantes** (guarda para uso posterior):

```bash
# Exportar variables de etcd (ajusta seg√∫n tu cluster)
export ETCDCTL_API=3
export ETCD_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCD_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCD_KEY=/etc/kubernetes/pki/etcd/server.key
export ETCD_ENDPOINTS=https://127.0.0.1:2379

# Verificar conectividad a etcd
sudo ETCDCTL_API=3 etcdctl \
  --cacert=$ETCD_CACERT \
  --cert=$ETCD_CERT \
  --key=$ETCD_KEY \
  --endpoints=$ETCD_ENDPOINTS \
  endpoint health
```

**‚úÖ Output esperado:**
```
https://127.0.0.1:2379 is healthy: successfully committed proposal: took = 2.345ms
```

---

### Parte 2: Realizar Backup de etcd

#### Paso 2.1: Crear directorio de backups

```bash
# Crear directorio con permisos apropiados
sudo mkdir -p /var/lib/etcd-backup
sudo chmod 700 /var/lib/etcd-backup

# Verificar espacio disponible
df -h /var/lib/etcd-backup
```

#### Paso 2.2: Ejecutar snapshot manual

```bash
# Crear snapshot con timestamp
BACKUP_FILE="/var/lib/etcd-backup/snapshot-$(date +%Y%m%d-%H%M%S).db"

sudo ETCDCTL_API=3 etcdctl snapshot save $BACKUP_FILE \
  --cacert=$ETCD_CACERT \
  --cert=$ETCD_CERT \
  --key=$ETCD_KEY \
  --endpoints=$ETCD_ENDPOINTS

echo "Backup creado en: $BACKUP_FILE"
```

**‚úÖ Output esperado:**
```
{"level":"info","ts":"2025-11-13T10:30:00Z","caller":"snapshot/v3_snapshot.go:65","msg":"created temporary db file","path":"/var/lib/etcd-backup/snapshot-20251113-103000.db.part"}
{"level":"info","ts":"2025-11-13T10:30:01Z","logger":"client","caller":"v3/maintenance.go:211","msg":"opened snapshot stream; downloading"}
{"level":"info","ts":"2025-11-13T10:30:01Z","caller":"snapshot/v3_snapshot.go:73","msg":"fetching snapshot","endpoint":"https://127.0.0.1:2379"}
{"level":"info","ts":"2025-11-13T10:30:02Z","logger":"client","caller":"v3/maintenance.go:219","msg":"completed snapshot read; closing"}
Snapshot saved at /var/lib/etcd-backup/snapshot-20251113-103000.db
```

#### Paso 2.3: Verificar integridad del backup

```bash
# Verificar status del snapshot
sudo ETCDCTL_API=3 etcdctl snapshot status $BACKUP_FILE --write-out=table

# Obtener tama√±o del archivo
ls -lh $BACKUP_FILE
```

**‚úÖ Output esperado:**
```
+---------+----------+------------+------------+
|  HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |
+---------+----------+------------+------------+
| 1a2b3c4d|    12345 |       1234 |     15 MB  |
+---------+----------+------------+------------+

-rw------- 1 root root 15M Nov 13 10:30 /var/lib/etcd-backup/snapshot-20251113-103000.db
```

#### Paso 2.4: Usar script de automatizaci√≥n

```bash
# Copiar script de backup automatizado
sudo cp backup-etcd.sh /usr/local/bin/
sudo chmod +x /usr/local/bin/backup-etcd.sh

# Ejecutar script
sudo /usr/local/bin/backup-etcd.sh

# Ver logs
sudo tail -f /var/log/etcd-backup.log
```

---

### Parte 3: Simular P√©rdida de Datos

#### Paso 3.1: Eliminar recursos de prueba

```bash
# Eliminar el deployment (simula p√©rdida de datos)
kubectl delete deployment nginx-backup -n backup-test

# Eliminar el ConfigMap
kubectl delete configmap backup-config -n backup-test

# Verificar que ya no existen
kubectl get all,cm,secret -n backup-test
```

**‚úÖ Verificaci√≥n:**
```
NAME                    TYPE     DATA   AGE
secret/backup-secret    Opaque   1      5m
# El deployment y ConfigMap deben haber desaparecido
```

#### Paso 3.2: Intentar recuperar (sin restore)

```bash
# Verificar que no hay forma de recuperar los recursos eliminados
kubectl get deploy -n backup-test
# No resources found in backup-test namespace.

# Ahora procederemos a restaurar desde el backup
```

---

### Parte 4: Restaurar desde Backup

#### Paso 4.1: Detener componentes del control plane

‚ö†Ô∏è **ADVERTENCIA**: Este paso causa downtime del cluster (API no disponible)

```bash
# Mover manifests fuera del directorio de kubelet
sudo mv /etc/kubernetes/manifests/kube-apiserver.yaml /tmp/
sudo mv /etc/kubernetes/manifests/kube-controller-manager.yaml /tmp/
sudo mv /etc/kubernetes/manifests/kube-scheduler.yaml /tmp/

# Esperar a que los pods se detengan
sleep 10

# Verificar que API server est√° detenido
kubectl get nodes 2>&1 | grep "connection refused"
```

#### Paso 4.2: Restaurar snapshot de etcd

```bash
# Definir directorio de restore
RESTORE_DIR="/var/lib/etcd-restored"

# Ejecutar restore (usa el archivo de backup m√°s reciente)
LATEST_BACKUP=$(ls -t /var/lib/etcd-backup/snapshot-*.db | head -1)

sudo ETCDCTL_API=3 etcdctl snapshot restore $LATEST_BACKUP \
  --data-dir=$RESTORE_DIR \
  --name=default \
  --initial-cluster=default=https://127.0.0.1:2380 \
  --initial-advertise-peer-urls=https://127.0.0.1:2380 \
  --initial-cluster-token=etcd-cluster-1

echo "Restore completado en: $RESTORE_DIR"
```

**‚úÖ Output esperado:**
```
{"level":"info","ts":"2025-11-13T10:35:00Z","caller":"snapshot/v3_snapshot.go:251","msg":"restoring snapshot","path":"/var/lib/etcd-backup/snapshot-20251113-103000.db","wal-dir":"/var/lib/etcd-restored/member/wal","data-dir":"/var/lib/etcd-restored","snap-dir":"/var/lib/etcd-restored/member/snap"}
{"level":"info","ts":"2025-11-13T10:35:01Z","caller":"mvcc/kvstore.go:415","msg":"restored last compact revision","meta-bucket-name":"meta","meta-bucket-name-key":"finishedCompactRev","restored-compact-revision":12000}
{"level":"info","ts":"2025-11-13T10:35:01Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"abcd1234","local-member-id":"0","added-peer-id":"efgh5678","added-peer-peer-urls":["https://127.0.0.1:2380"]}
```

#### Paso 4.3: Actualizar configuraci√≥n de etcd

```bash
# Backup del manifest original
sudo cp /etc/kubernetes/manifests/etcd.yaml /tmp/etcd.yaml.bak

# Editar manifest para apuntar al nuevo data-dir
sudo sed -i 's|/var/lib/etcd|/var/lib/etcd-restored|g' \
  /tmp/etcd.yaml

# NOTA: Tambi√©n debes actualizar --initial-cluster-token si es necesario
```

**Edici√≥n manual alternativa:**

```bash
sudo nano /tmp/etcd.yaml
```

Buscar y modificar:
```yaml
# ANTES:
- --data-dir=/var/lib/etcd

# DESPU√âS:
- --data-dir=/var/lib/etcd-restored
```

#### Paso 4.4: Reiniciar control plane

```bash
# Mover manifest de etcd modificado
sudo mv /tmp/etcd.yaml /etc/kubernetes/manifests/

# Esperar a que etcd inicie (30-60 segundos)
sleep 60

# Restaurar otros componentes
sudo mv /tmp/kube-apiserver.yaml /etc/kubernetes/manifests/
sudo mv /tmp/kube-controller-manager.yaml /etc/kubernetes/manifests/
sudo mv /tmp/kube-scheduler.yaml /etc/kubernetes/manifests/

# Esperar a que todos los componentes inicien
sleep 30
```

#### Paso 4.5: Verificar que el cluster est√° operacional

```bash
# Verificar nodos
kubectl get nodes

# Verificar componentes del control plane
kubectl get pods -n kube-system

# CR√çTICO: Verificar que los recursos eliminados est√°n restaurados
kubectl get all,cm,secret -n backup-test
```

**‚úÖ Verificaci√≥n esperada - RECURSOS RESTAURADOS:**
```
NAME                                READY   STATUS    RESTARTS   AGE
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          15m
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          15m
pod/nginx-backup-xxxxxxxxx-xxxxx    1/1     Running   0          15m

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-backup   3/3     3            3           15m

NAME                      DATA   AGE
configmap/backup-config   2      15m

NAME                    TYPE     DATA   AGE
secret/backup-secret    Opaque   1      15m
```

üéâ **¬°√âXITO!** Los recursos eliminados han sido restaurados desde el backup.

#### Paso 4.6: Validar datos restaurados

```bash
# Verificar contenido del ConfigMap
kubectl get configmap backup-config -n backup-test -o yaml

# Verificar que el Secret existe (no mostrar contenido sensible)
kubectl get secret backup-secret -n backup-test

# Verificar logs de un pod restaurado
POD_NAME=$(kubectl get pods -n backup-test -l app=nginx-backup -o jsonpath='{.items[0].metadata.name}')
kubectl logs $POD_NAME -n backup-test --tail=10
```

---

### Parte 5: Automatizaci√≥n de Backups

#### Paso 5.1: Configurar cron job para backups autom√°ticos

```bash
# Editar crontab de root
sudo crontab -e

# Agregar backup cada 6 horas (a las 00:00, 06:00, 12:00, 18:00)
0 */6 * * * /usr/local/bin/backup-etcd.sh >> /var/log/etcd-backup.log 2>&1

# Agregar limpieza de backups antiguos (mantener √∫ltimos 7 d√≠as)
0 2 * * * find /var/lib/etcd-backup -name "snapshot-*.db" -mtime +7 -delete
```

#### Paso 5.2: Verificar script de backup automatizado

Ver el contenido del script: [backup-etcd.sh](./backup-etcd.sh)

```bash
# Testear el script manualmente
sudo /usr/local/bin/backup-etcd.sh

# Verificar que se cre√≥ el backup
ls -lth /var/lib/etcd-backup/ | head -5
```

#### Paso 5.3: Script de restore automatizado

Ver el contenido del script: [restore-etcd.sh](./restore-etcd.sh)

```bash
# Hacer ejecutable
sudo chmod +x restore-etcd.sh

# NO ejecutar en producci√≥n sin revisi√≥n previa
# El script incluye validaciones de seguridad
```

---

## üß™ Validaci√≥n del Laboratorio

### Checklist de Completitud

- [ ] **Backup creado exitosamente** con `etcdctl snapshot save`
- [ ] **Integridad verificada** con `etcdctl snapshot status`
- [ ] **Recursos de prueba** creados (deployment, configmap, secret)
- [ ] **Simulaci√≥n de p√©rdida** de datos realizada
- [ ] **Restore ejecutado** desde snapshot
- [ ] **Cluster operacional** despu√©s del restore
- [ ] **Recursos restaurados** verificados en namespace backup-test
- [ ] **Scripts de automatizaci√≥n** configurados
- [ ] **Cron job** programado para backups peri√≥dicos
- [ ] **Cleanup ejecutado** (recursos de prueba eliminados)

### Comandos de Verificaci√≥n Final

```bash
# 1. Verificar salud de etcd
sudo ETCDCTL_API=3 etcdctl endpoint health \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379

# 2. Listar backups disponibles
ls -lh /var/lib/etcd-backup/

# 3. Verificar cron jobs configurados
sudo crontab -l | grep etcd

# 4. Verificar cluster funcional
kubectl get nodes
kubectl get pods -A | grep -E "Running|Pending"

# 5. Contar recursos totales en etcd
sudo ETCDCTL_API=3 etcdctl get / --prefix --keys-only \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379 | wc -l
```

---

## üîç Troubleshooting

### Problema 1: "connection refused" al ejecutar etcdctl

**S√≠ntomas:**
```
Error: context deadline exceeded
```

**Soluci√≥n:**
```bash
# Verificar que etcd est√° corriendo
sudo crictl ps | grep etcd

# Verificar logs de etcd
sudo crictl logs <etcd-container-id>

# Verificar que los certificados son correctos
ls -l /etc/kubernetes/pki/etcd/

# Asegurarte de usar ETCDCTL_API=3
export ETCDCTL_API=3
```

---

### Problema 2: Snapshot save falla con "permission denied"

**S√≠ntomas:**
```bash
Error: open /var/lib/etcd-backup/snapshot.db: permission denied
```

**Soluci√≥n:**
```bash
# Verificar permisos del directorio
sudo ls -ld /var/lib/etcd-backup

# Crear con permisos correctos si no existe
sudo mkdir -p /var/lib/etcd-backup
sudo chmod 700 /var/lib/etcd-backup
sudo chown root:root /var/lib/etcd-backup

# Ejecutar etcdctl con sudo
sudo ETCDCTL_API=3 etcdctl snapshot save ...
```

---

### Problema 3: Cluster no inicia despu√©s del restore

**S√≠ntomas:**
```bash
kubectl get nodes
# The connection to the server was refused
```

**Diagn√≥stico:**
```bash
# 1. Verificar logs de kubelet
sudo journalctl -u kubelet -f

# 2. Verificar manifest de etcd
sudo cat /etc/kubernetes/manifests/etcd.yaml | grep data-dir

# 3. Verificar permisos del directorio restored
sudo ls -ld /var/lib/etcd-restored
sudo chown -R root:root /var/lib/etcd-restored

# 4. Verificar logs de contenedor etcd
sudo crictl logs <etcd-container-id> 2>&1 | tail -50
```

**Soluci√≥n - Rollback si es necesario:**
```bash
# 1. Detener componentes
sudo mv /etc/kubernetes/manifests/*.yaml /tmp/

# 2. Restaurar manifest original de etcd
sudo cp /tmp/etcd.yaml.bak /etc/kubernetes/manifests/etcd.yaml

# 3. Eliminar directorio restored problem√°tico
sudo rm -rf /var/lib/etcd-restored

# 4. Reiniciar componentes
sudo mv /tmp/kube-*.yaml /etc/kubernetes/manifests/

# 5. Esperar a que el cluster se recupere
sleep 60
kubectl get nodes
```

---

### Problema 4: Error "cluster ID mismatch"

**S√≠ntomas:**
```
error: "cluster ID mismatch"
```

**Soluci√≥n:**
```bash
# Durante restore, aseg√∫rate de usar --initial-cluster-token √∫nico
sudo ETCDCTL_API=3 etcdctl snapshot restore $BACKUP_FILE \
  --data-dir=/var/lib/etcd-restored \
  --initial-cluster-token=etcd-cluster-restored-$(date +%s)
  
# Actualizar manifest con el nuevo token
sudo nano /etc/kubernetes/manifests/etcd.yaml
# Agregar: --initial-cluster-token=etcd-cluster-restored-XXXXXXXXXX
```

---

### Problema 5: Backup muy grande (>1GB)

**Causa:** El cluster tiene muchos recursos o historial largo de eventos.

**Soluci√≥n:**
```bash
# 1. Limpiar eventos antiguos antes del backup
kubectl delete events --all-namespaces --field-selector=involvedObject.kind=Pod

# 2. Compactar historial de etcd
sudo ETCDCTL_API=3 etcdctl compact \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379 \
  $(sudo ETCDCTL_API=3 etcdctl endpoint status --write-out="json" \
    --cacert=/etc/kubernetes/pki/etcd/ca.crt \
    --cert=/etc/kubernetes/pki/etcd/server.crt \
    --key=/etc/kubernetes/pki/etcd/server.key \
    --endpoints=https://127.0.0.1:2379 \
    | jq -r '.[0].Status.header.revision')

# 3. Defragmentar etcd
sudo ETCDCTL_API=3 etcdctl defrag \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379

# 4. Ahora crear backup (ser√° m√°s peque√±o)
```

---

## üìö Recursos Adicionales

### Documentaci√≥n Oficial

- [Kubernetes - Operating etcd clusters](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)
- [etcd - Disaster recovery](https://etcd.io/docs/v3.5/op-guide/recovery/)
- [etcdctl snapshot commands](https://etcd.io/docs/v3.5/op-guide/maintenance/)

### Comandos √ötiles de etcd

```bash
# Verificar miembros del cluster etcd
sudo ETCDCTL_API=3 etcdctl member list \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379

# Ver m√©tricas de etcd
curl -k --cert /etc/kubernetes/pki/etcd/server.crt \
  --key /etc/kubernetes/pki/etcd/server.key \
  --cacert /etc/kubernetes/pki/etcd/ca.crt \
  https://127.0.0.1:2379/metrics | grep -E "etcd_server_has_leader|etcd_mvcc_db_total_size"

# Obtener revisi√≥n actual
sudo ETCDCTL_API=3 etcdctl endpoint status --write-out=table \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379
```

### Best Practices

**Backups:**
- ‚úÖ Automatizar con cron jobs
- ‚úÖ Mantener m√∫ltiples versiones (7-30 d√≠as)
- ‚úÖ Almacenar en ubicaci√≥n externa al cluster
- ‚úÖ Cifrar backups en reposo
- ‚úÖ Probar procedimiento de restore regularmente

**Seguridad:**
- ‚úÖ Proteger certificados de etcd (chmod 600)
- ‚úÖ Restringir acceso SSH al control plane
- ‚úÖ Auditar accesos a etcd
- ‚úÖ Usar TLS para todas las comunicaciones

**Monitoreo:**
- ‚úÖ Alertar si backup falla
- ‚úÖ Monitorear tama√±o de etcd
- ‚úÖ Verificar latencia de etcd
- ‚úÖ Tracking de revisiones

---

## üéì Conceptos para el Examen CKA

### Puntos Cr√≠ticos para CKA

1. **Comando de backup** (MEMORIZAR):
   ```bash
   ETCDCTL_API=3 etcdctl snapshot save /backup/snapshot.db \
     --cacert=<ca-cert> --cert=<cert> --key=<key> --endpoints=<endpoint>
   ```

2. **Comando de restore** (MEMORIZAR):
   ```bash
   ETCDCTL_API=3 etcdctl snapshot restore /backup/snapshot.db \
     --data-dir=/var/lib/etcd-restored
   ```

3. **Ubicaci√≥n de certificados** (CONOCER):
   - CA cert: `/etc/kubernetes/pki/etcd/ca.crt`
   - Server cert: `/etc/kubernetes/pki/etcd/server.crt`
   - Server key: `/etc/kubernetes/pki/etcd/server.key`

4. **Verificaci√≥n de integridad**:
   ```bash
   ETCDCTL_API=3 etcdctl snapshot status snapshot.db --write-out=table
   ```

5. **Manifest de etcd**: `/etc/kubernetes/manifests/etcd.yaml`

### Escenarios de Examen

**Tarea t√≠pica CKA**:
> "Realiza un backup de etcd y gu√°rdalo en /opt/etcd-backup/snapshot.db"

**Soluci√≥n en 3 pasos**:
```bash
# 1. Exportar variables
export ETCDCTL_API=3

# 2. Obtener cert paths del manifest
grep -E "cert|key|server" /etc/kubernetes/manifests/etcd.yaml

# 3. Ejecutar backup
sudo etcdctl snapshot save /opt/etcd-backup/snapshot.db \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  --endpoints=https://127.0.0.1:2379
```

**Tiempo en examen**: 3-5 minutos (backup) | 8-12 minutos (restore completo)

---

## üßπ Limpieza del Laboratorio

**IMPORTANTE**: Ejecuta el script de cleanup para restaurar el estado original.

```bash
# Ejecutar script de limpieza
./cleanup.sh
```

El script realizar√°:
- ‚úÖ Eliminar namespace `backup-test` y todos sus recursos
- ‚úÖ Eliminar backups de prueba en `/var/lib/etcd-backup`
- ‚úÖ Restaurar manifest original de etcd (si fue modificado)
- ‚úÖ Eliminar cron jobs de backup (opcional)
- ‚úÖ Restaurar etcd al data-dir original `/var/lib/etcd`

**Verificaci√≥n post-cleanup:**
```bash
# Verificar que el namespace fue eliminado
kubectl get ns backup-test
# Error from server (NotFound): namespaces "backup-test" not found ‚úÖ

# Verificar que etcd usa el data-dir original
sudo cat /etc/kubernetes/manifests/etcd.yaml | grep data-dir
# --data-dir=/var/lib/etcd ‚úÖ

# Verificar cluster funcional
kubectl get nodes
# All nodes should be Ready ‚úÖ
```

---

## üìä Resumen del Laboratorio

### Lo que Aprendiste

- ‚úÖ Realizar backups de etcd con `etcdctl snapshot save`
- ‚úÖ Verificar integridad de snapshots con `snapshot status`
- ‚úÖ Restaurar cluster desde backup con `snapshot restore`
- ‚úÖ Automatizar backups con scripts y cron
- ‚úÖ Troubleshooting de problemas de restore
- ‚úÖ Entender arquitectura de almacenamiento de K8s

### Comandos Clave

| Operaci√≥n | Comando |
|-----------|---------|
| **Backup** | `etcdctl snapshot save snapshot.db` |
| **Verificar** | `etcdctl snapshot status snapshot.db` |
| **Restore** | `etcdctl snapshot restore snapshot.db --data-dir=/new/path` |
| **Health** | `etcdctl endpoint health` |
| **Status** | `etcdctl endpoint status --write-out=table` |

### Tiempo Total

- ‚è±Ô∏è **Setup**: 5-10 minutos
- ‚è±Ô∏è **Backup**: 10-15 minutos
- ‚è±Ô∏è **Restore**: 15-20 minutos
- ‚è±Ô∏è **Troubleshooting**: 5-10 minutos
- ‚è±Ô∏è **Cleanup**: 3-5 minutos
- **TOTAL**: ~40-60 minutos

---

## üéØ Siguiente Paso

Contin√∫a con: **[Lab 02: Cluster Upgrade](../lab-02-cluster-upgrade-minor/README.md)**

Aprender√°s a:
- Actualizar cluster de Kubernetes 1.27 ‚Üí 1.28
- Upgrade de control plane con kubeadm
- Upgrade de worker nodes sin downtime
- Rollback en caso de problemas

---

**üéì ¬°Excelente trabajo!** Has completado uno de los laboratorios m√°s cr√≠ticos para CKA.

**Nivel de complejidad**: ‚≠ê‚≠ê‚≠ê Avanzado  
**Relevancia CKA**: üî¥ CR√çTICO (30% del examen - Troubleshooting)  
**Habilidades adquiridas**: Disaster Recovery, etcd operations, Cluster backup/restore

---

*Laboratorio creado para el curso Kubernetes CKA/CKAD - M√≥dulo 23: Maintenance & Upgrades*  
*Versi√≥n: 1.0 | Fecha: 2025-11-13*
