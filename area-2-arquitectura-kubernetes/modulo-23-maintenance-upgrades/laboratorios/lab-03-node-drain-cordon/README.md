# Lab 03: Node Drain, Cordon & Maintenance

**DuraciÃ³n estimada:** 30-45 minutos  
**Dificultad:** â­â­ Intermedio  
**Relevancia CKA:** ğŸ”´ CRÃTICO (Node Maintenance 15%)

---

## ğŸ¯ Objetivos de Aprendizaje

Al completar este laboratorio, serÃ¡s capaz de:

- âœ… Realizar mantenimiento de nodos sin causar downtime de aplicaciones
- âœ… Usar `kubectl drain` para evacuar pods de forma segura
- âœ… Entender la diferencia entre `drain`, `cordon` y `uncordon`
- âœ… Manejar PodDisruptionBudgets (PDBs) durante mantenimiento
- âœ… Trabajar con node taints y tolerations
- âœ… Implementar graceful shutdown de aplicaciones

---

## ğŸ“‹ Prerequisitos

Antes de comenzar, asegÃºrate de:

1. âœ… Tener un cluster Kubernetes con **al menos 2 worker nodes**
2. âœ… Deployments con mÃºltiples rÃ©plicas corriendo
3. âœ… Permisos para drenar nodos (`kubectl drain`)
4. âœ… Acceso SSH a los nodos (para simular mantenimiento)

**Verifica prerequisitos:**
```bash
# Verificar nÃºmero de nodos
kubectl get nodes

# Debe mostrar al menos 2 workers
# NAME                STATUS   ROLES           AGE   VERSION
# k8s-control-plane   Ready    control-plane   30d   v1.28.0
# k8s-worker-01       Ready    <none>          30d   v1.28.0
# k8s-worker-02       Ready    <none>          30d   v1.28.0

# Verificar que hay deployments corriendo
kubectl get deployments -A
```

ğŸ“– **Ver detalles completos**: [SETUP.md](./SETUP.md)

---

## ğŸ—ï¸ Arquitectura del Mantenimiento de Nodos

```
ESTADO INICIAL - Cluster con 2 Workers
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTROL PLANE                            â”‚
â”‚                  kube-apiserver                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKER-01       â”‚       â”‚   WORKER-02      â”‚
    â”‚   Status: Ready   â”‚       â”‚   Status: Ready  â”‚
    â”‚                   â”‚       â”‚                  â”‚
    â”‚   Pod A (rep 1/3) â”‚       â”‚   Pod A (rep 2/3)â”‚
    â”‚   Pod B (rep 1/2) â”‚       â”‚   Pod A (rep 3/3)â”‚
    â”‚   Pod C           â”‚       â”‚   Pod B (rep 2/2)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FASE 1: CORDON - Marcar nodo para mantenimiento
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl cordon worker-01                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKER-01         â”‚       â”‚   WORKER-02      â”‚
    â”‚ âš ï¸ SchedulingDisabledâ”‚       â”‚   Status: Ready  â”‚
    â”‚                     â”‚       â”‚                  â”‚
    â”‚   Pod A (rep 1/3)   â”‚       â”‚   Pod A (rep 2/3)â”‚
    â”‚   Pod B (rep 1/2)   â”‚       â”‚   Pod A (rep 3/3)â”‚
    â”‚   Pod C             â”‚       â”‚   Pod B (rep 2/2)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Nuevos pods NO se      â†       Nuevos pods VAN aquÃ­
    crearÃ¡n aquÃ­

FASE 2: DRAIN - Evacuar pods existentes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl drain worker-01 --ignore-daemonsets                 â”‚
â”‚ --delete-emptydir-data                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKER-01         â”‚       â”‚   WORKER-02      â”‚
    â”‚ âš ï¸ SchedulingDisabledâ”‚       â”‚   Status: Ready  â”‚
    â”‚                     â”‚       â”‚                  â”‚
    â”‚   (vacÃ­o)           â”‚  â”€â”€â”€â†’ â”‚   Pod A (rep 1/3)â”‚
    â”‚   Solo DaemonSets   â”‚  â”€â”€â”€â†’ â”‚   Pod A (rep 2/3)â”‚
    â”‚                     â”‚  â”€â”€â”€â†’ â”‚   Pod A (rep 3/3)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   Pod B (rep 1/2)â”‚
    Listo para                    â”‚   Pod B (rep 2/2)â”‚
    mantenimiento                 â”‚   Pod C          â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FASE 3: MANTENIMIENTO - Realizar cambios en el nodo
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ # SSH al nodo                                               â”‚
â”‚ ssh worker-01                                               â”‚
â”‚                                                             â”‚
â”‚ # Actualizar paquetes, reiniciar, etc.                     â”‚
â”‚ sudo apt-get update && sudo apt-get upgrade                â”‚
â”‚ sudo reboot                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FASE 4: UNCORDON - Habilitar scheduling nuevamente
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kubectl uncordon worker-01                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKER-01         â”‚       â”‚   WORKER-02      â”‚
    â”‚   Status: Ready âœ“   â”‚       â”‚   Status: Ready  â”‚
    â”‚                     â”‚       â”‚                  â”‚
    â”‚   (vacÃ­o)           â”‚       â”‚   Pod A (rep 1/3)â”‚
    â”‚   Listo para recibirâ”‚       â”‚   Pod A (rep 2/3)â”‚
    â”‚   nuevos pods       â”‚       â”‚   Pod A (rep 3/3)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   Pod B (rep 1/2)â”‚
                                  â”‚   Pod B (rep 2/2)â”‚
                                  â”‚   Pod C          â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RESULTADO FINAL - Balance natural
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Los nuevos pods se distribuirÃ¡n entre ambos nodos          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   WORKER-01         â”‚       â”‚   WORKER-02      â”‚
    â”‚   Status: Ready     â”‚       â”‚   Status: Ready  â”‚
    â”‚                     â”‚       â”‚                  â”‚
    â”‚   Pod X (nuevo)     â”‚       â”‚   Pod A (rep 1/3)â”‚
    â”‚   Pod Y (nuevo)     â”‚       â”‚   Pod A (rep 2/3)â”‚
    â”‚                     â”‚       â”‚   Pod A (rep 3/3)â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Conceptos Clave

### Comandos de Mantenimiento de Nodos

| Comando | Efecto en Pods Existentes | Nuevos Pods | Uso |
|---------|---------------------------|-------------|-----|
| **`kubectl cordon <node>`** | âŒ NO los afecta | ğŸš« NO se programan | Prevenir scheduling |
| **`kubectl drain <node>`** | âœ… Los evacua (delete) | ğŸš« NO se programan | Mantenimiento completo |
| **`kubectl uncordon <node>`** | âŒ NO los afecta | âœ… Vuelven a programarse | Restaurar scheduling |

### Drain vs Cordon

**`kubectl cordon`**:
- Marca el nodo como `SchedulingDisabled`
- Los pods existentes **NO se mueven**
- Solo previene nuevos pods
- Ãštil para: Preparar mantenimiento gradual

**`kubectl drain`**:
- Hace `cordon` automÃ¡ticamente
- **Evacua** todos los pods (excepto DaemonSets)
- Respeta `PodDisruptionBudgets`
- Espera graceful termination
- Ãštil para: Mantenimiento inmediato, upgrades

### PodDisruptionBudgets (PDB)

Un **PodDisruptionBudget** limita cuÃ¡ntos pods pueden estar down simultÃ¡neamente:

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-app-pdb
spec:
  minAvailable: 2  # MÃ­nimo 2 pods siempre disponibles
  selector:
    matchLabels:
      app: my-app
```

**Comportamiento durante drain**:
- `kubectl drain` **espera** hasta que el PDB lo permita
- Si `minAvailable` no se puede cumplir, drain se bloquea
- Flags para override: `--disable-eviction` o `--force`

---

## ğŸ› ï¸ Procedimiento del Laboratorio

### Parte 1: Setup - Crear Aplicaciones de Prueba

#### Paso 1.1: Deployment con mÃºltiples rÃ©plicas

```bash
# Crear namespace de prueba
kubectl create namespace drain-test

# Deployment con 6 rÃ©plicas (distribuidas entre workers)
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-demo
  namespace: drain-test
spec:
  replicas: 6
  selector:
    matchLabels:
      app: nginx-demo
  template:
    metadata:
      labels:
        app: nginx-demo
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
EOF
```

**Verificar distribuciÃ³n:**
```bash
kubectl get pods -n drain-test -o wide

# DeberÃ­as ver pods distribuidos entre worker-01 y worker-02
```

#### Paso 1.2: Deployment con PodDisruptionBudget

```bash
# Deployment crÃ­tico con PDB
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: critical-app
  namespace: drain-test
spec:
  replicas: 4
  selector:
    matchLabels:
      app: critical-app
  template:
    metadata:
      labels:
        app: critical-app
    spec:
      containers:
      - name: app
        image: busybox:1.28
        command: ['sh', '-c', 'while true; do echo "Running..."; sleep 30; done']
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: critical-app-pdb
  namespace: drain-test
spec:
  minAvailable: 2  # Siempre mantener al menos 2 pods
  selector:
    matchLabels:
      app: critical-app
EOF
```

**Verificar PDB:**
```bash
kubectl get pdb -n drain-test

# Output esperado:
# NAME               MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
# critical-app-pdb   2               N/A               2                     10s
```

#### Paso 1.3: DaemonSet (no se evacua con drain)

```bash
# DaemonSet de ejemplo (simula node monitoring)
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-monitor
  namespace: drain-test
spec:
  selector:
    matchLabels:
      app: node-monitor
  template:
    metadata:
      labels:
        app: node-monitor
    spec:
      containers:
      - name: monitor
        image: busybox:1.28
        command: ['sh', '-c', 'while true; do echo "Monitoring $(hostname)..."; sleep 60; done']
EOF
```

**Verificar que hay 1 pod por nodo:**
```bash
kubectl get pods -n drain-test -l app=node-monitor -o wide
```

---

### Parte 2: Cordon - Prevenir Nuevos Pods

#### Paso 2.1: Identificar nodo para mantenimiento

```bash
# Listar nodos y su carga
kubectl get nodes -o wide

# Ver pods en cada nodo
kubectl get pods -A -o wide --field-selector spec.nodeName=k8s-worker-01
```

Elige el nodo con **menos pods crÃ­ticos** para este ejercicio.

#### Paso 2.2: Cordon del nodo

```bash
# Marcar worker-01 para mantenimiento
kubectl cordon k8s-worker-01

# Verificar estado
kubectl get nodes

# Output esperado:
# NAME                STATUS                     ROLES           AGE   VERSION
# k8s-control-plane   Ready                      control-plane   30d   v1.28.0
# k8s-worker-01       Ready,SchedulingDisabled   <none>          30d   v1.28.0  â† Cordoned
# k8s-worker-02       Ready                      <none>          30d   v1.28.0
```

#### Paso 2.3: Verificar comportamiento de nuevos pods

```bash
# Escalar deployment para crear nuevos pods
kubectl scale deployment nginx-demo -n drain-test --replicas=10

# Ver dÃ³nde se programan los nuevos pods
kubectl get pods -n drain-test -o wide

# Los nuevos 4 pods SOLO irÃ¡n a worker-02 (no a worker-01 cordoned)
```

**âœ… VerificaciÃ³n:**
- Los pods existentes en `worker-01` **siguen corriendo**
- Los nuevos pods **solo van a `worker-02`**

---

### Parte 3: Drain - Evacuar Pods

#### Paso 3.1: Intentar drain bÃ¡sico

```bash
# Primer intento de drain (fallarÃ¡ por DaemonSets)
kubectl drain k8s-worker-01

# Error esperado:
# error: cannot delete DaemonSet-managed Pods (use --ignore-daemonsets to ignore)
# ...
```

#### Paso 3.2: Drain correcto con flags

```bash
# Drain ignorando DaemonSets
kubectl drain k8s-worker-01 --ignore-daemonsets --delete-emptydir-data

# Output esperado:
# node/k8s-worker-01 already cordoned
# WARNING: ignoring DaemonSet-managed Pods: drain-test/node-monitor-xxxxx
# evicting pod drain-test/nginx-demo-xxxxx
# evicting pod drain-test/critical-app-xxxxx
# ...
# pod/nginx-demo-xxxxx evicted
# pod/critical-app-xxxxx evicted
# node/k8s-worker-01 drained
```

**Proceso durante drain:**
1. Pods reciben `SIGTERM` (graceful shutdown)
2. Esperan `terminationGracePeriodSeconds` (default 30s)
3. Deployment controller crea rÃ©plicas en otros nodos
4. Pods originales terminan

#### Paso 3.3: Verificar evacuaciÃ³n

```bash
# Ver pods en worker-01 (solo DaemonSets deben quedar)
kubectl get pods -A -o wide --field-selector spec.nodeName=k8s-worker-01

# Output esperado: Solo DaemonSets
# NAMESPACE    NAME                  READY   STATUS    RESTARTS   AGE
# drain-test   node-monitor-xxxxx    1/1     Running   0          5m
# kube-system  kube-proxy-xxxxx      1/1     Running   0          30d

# Ver que los pods migraron a worker-02
kubectl get pods -n drain-test -o wide | grep -v monitor
```

---

### Parte 4: Mantenimiento del Nodo

Ahora que el nodo estÃ¡ drenado, puedes realizar mantenimiento:

#### Paso 4.1: Simular mantenimiento

```bash
# OpciÃ³n 1: ActualizaciÃ³n de paquetes (sin reiniciar)
ssh k8s-worker-01 "sudo apt-get update && sudo apt-get upgrade -y"

# OpciÃ³n 2: Reinicio completo
ssh k8s-worker-01 "sudo reboot"

# Esperar a que el nodo vuelva
kubectl get nodes -w
```

#### Paso 4.2: Verificar que el nodo volviÃ³

```bash
# DespuÃ©s del reinicio
kubectl get nodes

# El nodo estarÃ¡ Ready, pero SIGUE CORDONED:
# k8s-worker-01   Ready,SchedulingDisabled   <none>   30d   v1.28.0
```

âš ï¸ **IMPORTANTE**: `drain` deja el nodo en estado `SchedulingDisabled`. Debes hacer `uncordon` manualmente.

---

### Parte 5: Uncordon - Restaurar Scheduling

#### Paso 5.1: Habilitar scheduling

```bash
# Uncordon del nodo
kubectl uncordon k8s-worker-01

# Verificar estado
kubectl get nodes

# Output esperado:
# NAME                STATUS   ROLES           AGE   VERSION
# k8s-control-plane   Ready    control-plane   30d   v1.28.0
# k8s-worker-01       Ready    <none>          30d   v1.28.0  â† Ya no tiene SchedulingDisabled
# k8s-worker-02       Ready    <none>          30d   v1.28.0
```

#### Paso 5.2: Verificar rebalanceo gradual

```bash
# Los pods NO se mueven automÃ¡ticamente despuÃ©s de uncordon
kubectl get pods -n drain-test -o wide

# Siguen en worker-02

# Pero los NUEVOS pods se distribuirÃ¡n
kubectl scale deployment nginx-demo -n drain-test --replicas=12

# Ver distribuciÃ³n de los nuevos pods
kubectl get pods -n drain-test -o wide

# Ahora verÃ¡s pods en ambos workers
```

---

### Parte 6: Forzar Rebalanceo (Opcional)

Si quieres forzar redistribuciÃ³n de pods existentes:

#### OpciÃ³n 1: Restart del Deployment

```bash
kubectl rollout restart deployment nginx-demo -n drain-test

# Esperar a que termine
kubectl rollout status deployment nginx-demo -n drain-test

# Ver distribuciÃ³n balanceada
kubectl get pods -n drain-test -o wide
```

#### OpciÃ³n 2: Drenar el otro nodo (rolling)

```bash
# Ahora drena worker-02
kubectl drain k8s-worker-02 --ignore-daemonsets --delete-emptydir-data

# Los pods migrarÃ¡n a worker-01 (ya uncordoned)

# Luego uncordon worker-02
kubectl uncordon k8s-worker-02
```

---

## ğŸ§ª ValidaciÃ³n del Laboratorio

### Checklist de Completitud

- [ ] **Cordon ejecutado** correctamente en un nodo
- [ ] **Nuevos pods** NO se programan en nodo cordoned
- [ ] **Drain ejecutado** con flags apropiados
- [ ] **DaemonSets** permanecen en el nodo drenado
- [ ] **Pods evacuados** correctamente a otros nodos
- [ ] **PodDisruptionBudget** respetado durante drain
- [ ] **Mantenimiento** simulado (actualizaciÃ³n o reinicio)
- [ ] **Uncordon ejecutado** despuÃ©s de mantenimiento
- [ ] **Nuevos pods** se pueden programar en nodo uncordoned
- [ ] **Cleanup** completado

### Script de VerificaciÃ³n

```bash
./verify-drain.sh
```

El script verificarÃ¡:
- âœ… Estados de nodos (Ready vs SchedulingDisabled)
- âœ… DistribuciÃ³n de pods entre nodos
- âœ… PodDisruptionBudgets activos
- âœ… DaemonSets en todos los nodos

---

## ğŸ” Troubleshooting

### Problema 1: Drain se bloquea indefinidamente

**SÃ­ntomas:**
```bash
kubectl drain worker-01 --ignore-daemonsets
evicting pod default/my-pod
error when evicting pod "my-pod": Cannot evict pod as it would violate the pod's disruption budget.
```

**Causa**: PodDisruptionBudget impide la evacuaciÃ³n

**Soluciones:**

**OpciÃ³n 1: Esperar** (recomendado)
```bash
# El drain eventualmente procederÃ¡ cuando el PDB lo permita
# Esto puede tomar tiempo si otros pods tambiÃ©n estÃ¡n down
```

**OpciÃ³n 2: Verificar PDB**
```bash
kubectl get pdb -A

# Ver detalles del PDB problemÃ¡tico
kubectl describe pdb <pdb-name> -n <namespace>

# Ver cuÃ¡ntos pods estÃ¡n disponibles
# ALLOWED DISRUPTIONS debe ser > 0 para que drain funcione
```

**OpciÃ³n 3: Temporalmente modificar PDB** (CUIDADO)
```bash
# Reducir minAvailable
kubectl edit pdb <pdb-name> -n <namespace>

# Cambiar:
# minAvailable: 3
# a:
# minAvailable: 1

# DespuÃ©s del drain, restaurar el valor original
```

**OpciÃ³n 4: Forzar drain** (ÃšLTIMO RECURSO)
```bash
# Ignora PDBs - PUEDE CAUSAR DOWNTIME
kubectl drain worker-01 --ignore-daemonsets --delete-emptydir-data --force --disable-eviction

# âš ï¸ Usa solo en emergencias
```

---

### Problema 2: Pods con emptyDir no se evacuan

**SÃ­ntomas:**
```bash
error: cannot delete Pods with local storage (use --delete-emptydir-data to override)
```

**Causa**: Pods usando volÃºmenes `emptyDir`

**SoluciÃ³n:**
```bash
# Agregar flag --delete-emptydir-data
kubectl drain worker-01 --ignore-daemonsets --delete-emptydir-data

# âš ï¸ Esto ELIMINARÃ los datos en emptyDir (temporal por diseÃ±o)
```

**PrevenciÃ³n**:
- Usa `PersistentVolumes` para datos importantes
- `emptyDir` es para datos temporales/cache

---

### Problema 3: Pods "standalone" no se pueden drenar

**SÃ­ntomas:**
```bash
error: cannot delete Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet
```

**Causa**: Pod creado directamente (no por controller)

**Identificar:**
```bash
kubectl get pods -A -o json | jq '.items[] | select(.metadata.ownerReferences == null) | .metadata.name'
```

**SoluciÃ³n:**
```bash
# OpciÃ³n 1: Eliminar el pod manualmente primero
kubectl delete pod <pod-name> -n <namespace>

# Luego drain
kubectl drain worker-01 --ignore-daemonsets

# OpciÃ³n 2: Forzar con --force
kubectl drain worker-01 --ignore-daemonsets --force

# âš ï¸ El pod se eliminarÃ¡ y NO se recrearÃ¡ (no hay controller)
```

---

### Problema 4: Drain tarda demasiado

**SÃ­ntomas:**
```bash
# Drain se queda en "evicting pod..." por minutos
```

**Causas posibles:**
1. `terminationGracePeriodSeconds` muy alto
2. Pod con finalizers
3. Pod con hooks de pre-stop lentos

**DiagnÃ³stico:**
```bash
# Ver grace period del pod
kubectl get pod <pod-name> -o yaml | grep terminationGracePeriodSeconds

# Ver events
kubectl get events --sort-by='.lastTimestamp' | grep <pod-name>
```

**SoluciÃ³n:**
```bash
# Reducir grace period temporalmente
kubectl drain worker-01 --ignore-daemonsets --grace-period=30

# Si sigue bloqueado, forzar:
kubectl drain worker-01 --ignore-daemonsets --grace-period=0 --force
```

---

### Problema 5: Nodo no vuelve a Ready despuÃ©s de reinicio

**SÃ­ntomas:**
```bash
kubectl get nodes
NAME          STATUS      ROLES    AGE   VERSION
worker-01     NotReady    <none>   30d   v1.28.0
```

**DiagnÃ³stico:**
```bash
# SSH al nodo
ssh worker-01

# Verificar kubelet
sudo systemctl status kubelet

# Ver logs
sudo journalctl -xeu kubelet | tail -50
```

**Soluciones comunes:**
```bash
# 1. Reiniciar kubelet
sudo systemctl restart kubelet

# 2. Verificar container runtime
sudo systemctl status containerd
sudo systemctl restart containerd
sudo systemctl restart kubelet

# 3. Verificar CNI
ls /etc/cni/net.d/
```

---

## ğŸ“š Comandos de Referencia RÃ¡pida

### Comandos Esenciales CKA

```bash
# CORDON - Prevenir scheduling
kubectl cordon <node>

# UNCORDON - Habilitar scheduling
kubectl uncordon <node>

# DRAIN - Evacuar pods (flags mÃ¡s comunes)
kubectl drain <node> \
  --ignore-daemonsets \
  --delete-emptydir-data \
  --grace-period=30

# DRAIN FORZADO (emergencias)
kubectl drain <node> \
  --ignore-daemonsets \
  --delete-emptydir-data \
  --force \
  --grace-period=0

# Ver estado de nodos
kubectl get nodes

# Ver pods en un nodo especÃ­fico
kubectl get pods -A -o wide --field-selector spec.nodeName=<node>

# Ver PodDisruptionBudgets
kubectl get pdb -A

# Ver detalles de PDB
kubectl describe pdb <pdb-name> -n <namespace>
```

### Workflow Completo de Mantenimiento

```bash
# 1. PreparaciÃ³n
kubectl get nodes                           # Ver nodos disponibles
kubectl get pods -A -o wide                 # Ver distribuciÃ³n de pods

# 2. Cordon
kubectl cordon worker-01                    # Prevenir nuevos pods

# 3. Verificar
kubectl get nodes                           # Confirmar SchedulingDisabled

# 4. Drain
kubectl drain worker-01 --ignore-daemonsets --delete-emptydir-data

# 5. Mantenimiento
ssh worker-01 "sudo apt-get upgrade -y"    # O cualquier mantenimiento
ssh worker-01 "sudo reboot"                 # Si es necesario

# 6. Verificar nodo volviÃ³
kubectl get nodes -w                        # Esperar Ready

# 7. Uncordon
kubectl uncordon worker-01                  # Restaurar scheduling

# 8. Verificar
kubectl get nodes                           # Confirmar Ready (sin SchedulingDisabled)
```

---

## ğŸ“ Conceptos para el Examen CKA

### Puntos CrÃ­ticos para Memorizar

1. **Drain vs Cordon**:
   - `cordon`: Solo previene nuevos pods
   - `drain`: Cordon + evacua pods existentes

2. **Flags comunes de drain**:
   ```bash
   --ignore-daemonsets      # Siempre necesario (DaemonSets no se evacuan)
   --delete-emptydir-data   # Para pods con emptyDir
   --force                  # Para pods standalone (sin controller)
   --grace-period=<seconds> # Tiempo de shutdown graceful
   ```

3. **DaemonSets**:
   - NUNCA se evacuan con drain
   - Permanecen en el nodo (por diseÃ±o)
   - Usa `--ignore-daemonsets` siempre

4. **PodDisruptionBudgets**:
   - Drain **respeta** PDBs por defecto
   - Puede bloquear drain si `minAvailable` no se cumple
   - Override con `--disable-eviction` (CUIDADO)

5. **Uncordon NO es automÃ¡tico**:
   - DespuÃ©s de drain/reinicio, nodo sigue `SchedulingDisabled`
   - Debes hacer `uncordon` manualmente

### Escenario TÃ­pico de Examen

**Tarea:**
> "Perform maintenance on worker-01. Drain all pods safely, then uncordon the node."

**SoluciÃ³n (5 minutos):**

```bash
# 1. Verificar estado inicial
kubectl get nodes

# 2. Cordon opcional (drain lo hace automÃ¡ticamente)
kubectl cordon worker-01

# 3. Drain
kubectl drain worker-01 --ignore-daemonsets --delete-emptydir-data

# 4. Verificar evacuaciÃ³n
kubectl get pods -A -o wide | grep worker-01
# (Solo DaemonSets deben aparecer)

# 5. Simular mantenimiento (si se pide)
# ssh worker-01 "sudo reboot"

# 6. Uncordon
kubectl uncordon worker-01

# 7. Verificar
kubectl get nodes
# worker-01 debe estar Ready (sin SchedulingDisabled)
```

**Tiempo estimado en examen**: 3-5 minutos

---

## ğŸ§¹ Limpieza del Laboratorio

```bash
# Ejecutar script de limpieza
./cleanup.sh
```

El script realizarÃ¡:
- âœ… Uncordon de todos los nodos
- âœ… EliminaciÃ³n del namespace `drain-test`
- âœ… VerificaciÃ³n de que no quedan nodos cordoned
- âœ… Reporte final de estado del cluster

**Limpieza manual:**
```bash
# Uncordon todos los nodos
kubectl get nodes -o name | xargs -I {} kubectl uncordon {}

# Eliminar namespace de prueba
kubectl delete namespace drain-test

# Verificar
kubectl get nodes
kubectl get namespaces
```

---

## ğŸ“Š Resumen del Laboratorio

### Lo que Aprendiste

- âœ… Diferencia entre `cordon`, `drain` y `uncordon`
- âœ… Evacuar pods de forma segura sin downtime
- âœ… Manejar DaemonSets durante mantenimiento
- âœ… Trabajar con PodDisruptionBudgets
- âœ… Realizar mantenimiento de nodos en producciÃ³n
- âœ… Troubleshooting de problemas comunes de drain

### Tiempo por Fase

| Fase | Tiempo |
|------|--------|
| **Setup de apps** | 5-8 min |
| **Cordon + verificaciÃ³n** | 3-5 min |
| **Drain + evacuaciÃ³n** | 5-10 min |
| **Mantenimiento (simulado)** | 5-10 min |
| **Uncordon + verificaciÃ³n** | 3-5 min |
| **TOTAL** | ~30-45 min |

### Comandos Clave para CKA

| Comando | Uso en Examen | Criticidad |
|---------|---------------|------------|
| `kubectl cordon <node>` | Prevenir scheduling | â­â­â­ |
| `kubectl drain <node> --ignore-daemonsets` | Mantenimiento de nodos | â­â­â­â­â­ |
| `kubectl uncordon <node>` | Restaurar nodo | â­â­â­â­ |
| `kubectl get pdb` | Verificar PDBs | â­â­â­ |

---

## ğŸ¯ Siguiente Paso

ContinÃºa con: **[Lab 04: Certificate Management](../lab-04-certificate-management/README.md)**

AprenderÃ¡s a:
- Gestionar certificados TLS de Kubernetes
- Verificar expiraciÃ³n de certificados
- Renovar certificados con kubeadm
- Troubleshooting de problemas de certificados

---

**ğŸ“ Â¡Excelente trabajo!** Has completado el laboratorio de mantenimiento de nodos.

**Nivel de complejidad**: â­â­ Intermedio  
**Relevancia CKA**: ğŸ”´ CRÃTICO (15% del examen - Node Maintenance)  
**Habilidades adquiridas**: Node maintenance, graceful eviction, PDB handling

---

*Laboratorio creado para el curso Kubernetes CKA/CKAD - MÃ³dulo 23: Maintenance & Upgrades*  
*VersiÃ³n: 1.0 | Fecha: 2025-11-13*
