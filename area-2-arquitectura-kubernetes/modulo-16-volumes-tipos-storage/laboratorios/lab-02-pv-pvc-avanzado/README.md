# Laboratorio 02: PersistentVolume y PersistentVolumeClaim Avanzado

## ğŸ“‹ InformaciÃ³n del Laboratorio

**DuraciÃ³n estimada**: 45-55 minutos  
**Nivel**: Intermedio  
**Prerequisitos**:
- Haber completado [Laboratorio 01](../lab-01-volumenes-basicos/)
- Cluster AKS activo con mÃºltiples nodos (recomendado)
- kubectl y Azure CLI configurados
- ComprensiÃ³n bÃ¡sica de PVC

## ğŸ¯ Objetivos de Aprendizaje

Al completar este laboratorio, serÃ¡s capaz de:

1. âœ… Crear PersistentVolumes (PV) manualmente y vincularlos con PVC
2. âœ… Usar Access Modes correctamente (RWO, ROX, RWX)
3. âœ… Implementar y probar Reclaim Policies (Retain, Delete)
4. âœ… Trabajar con Azure Files para almacenamiento compartido
5. âœ… Diagnosticar y resolver problemas comunes de volÃºmenes
6. âœ… Recuperar datos despuÃ©s de eliminar un PVC (con Retain)

## ğŸ“š Conceptos Clave

Este laboratorio profundiza en conceptos avanzados de almacenamiento persistente:

| Concepto | DescripciÃ³n | Impacto |
|----------|-------------|---------|
| **Access Mode RWO** | ReadWriteOnce - Un nodo | Azure Disk |
| **Access Mode RWX** | ReadWriteMany - MÃºltiples nodos | Azure Files |
| **Reclaim Policy Retain** | PV NO se elimina | ProtecciÃ³n de datos |
| **Reclaim Policy Delete** | PV se elimina automÃ¡ticamente | Limpieza automÃ¡tica |
| **StorageClass** | Template para provisioning | AutomatizaciÃ³n |

---

## ğŸ§ª Ejercicio 1: Access Modes - ReadWriteOnce vs ReadWriteMany (15 min)

### Objetivo
Entender las diferencias entre RWO (Azure Disk) y RWX (Azure Files) con ejemplos prÃ¡cticos.

### Parte A: ReadWriteOnce con Azure Disk

#### Paso 1.1: Crear PVC con RWO

Crea el archivo `pvc-rwo.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-rwo-disk
  labels:
    lab: pv-pvc-avanzado
    access-mode: rwo
spec:
  accessModes:
    - ReadWriteOnce  # Solo un nodo puede montar
  storageClassName: managed-csi  # Azure Disk
  resources:
    requests:
      storage: 5Gi
```

```bash
# Aplicar
kubectl apply -f pvc-rwo.yaml

# Verificar
kubectl get pvc pvc-rwo-disk
kubectl wait --for=jsonpath='{.status.phase}'=Bound pvc/pvc-rwo-disk --timeout=60s
```

#### Paso 1.2: Crear Deployment con 3 rÃ©plicas usando RWO

Crea el archivo `deployment-rwo.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-rwo
  labels:
    lab: pv-pvc-avanzado
spec:
  replicas: 3  # Intentar 3 rÃ©plicas
  selector:
    matchLabels:
      app: app-rwo
  template:
    metadata:
      labels:
        app: app-rwo
    spec:
      containers:
      - name: app
        image: busybox
        command:
        - sh
        - -c
        - |
          echo "Pod: $(hostname)"
          echo "Nodo: $NODE_NAME"
          echo "Escribiendo en volumen RWO..."
          echo "$(date): Pod $(hostname) en nodo $NODE_NAME" >> /data/log.txt
          tail -f /data/log.txt
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: storage
          mountPath: /data
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: pvc-rwo-disk
```

```bash
# Aplicar
kubectl apply -f deployment-rwo.yaml

# Esperar un poco
sleep 10

# Ver estado de los Pods
kubectl get pods -l app=app-rwo -o wide
```

**ObservaciÃ³n esperada**:
- Si todos los Pods estÃ¡n en el **mismo nodo**: âœ… Los 3 estarÃ¡n Running
- Si los Pods estÃ¡n en **diferentes nodos**: âš ï¸ Solo 1-2 estarÃ¡n Running, otros Pending

```bash
# Ver eventos de Pods pending
kubectl get events --sort-by='.lastTimestamp' | grep -i "multi-attach\|failedattach"

# Si ves "Multi-Attach error":
# âœ… Es el comportamiento esperado con ReadWriteOnce
```

#### Paso 1.3: Verificar en quÃ© nodos estÃ¡n los Pods

```bash
# Ver distribuciÃ³n de Pods por nodo
kubectl get pods -l app=app-rwo -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName

# âš ï¸ ReadWriteOnce = Solo un nodo puede montar el volumen
```

### Parte B: ReadWriteMany con Azure Files

#### Paso 1.4: Crear PVC con RWX

Crea el archivo `pvc-rwx.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-rwx-files
  labels:
    lab: pv-pvc-avanzado
    access-mode: rwx
spec:
  accessModes:
    - ReadWriteMany  # MÃºltiples nodos pueden montar
  storageClassName: azurefile-csi  # Azure Files (no Disk!)
  resources:
    requests:
      storage: 10Gi
```

```bash
# Aplicar
kubectl apply -f pvc-rwx.yaml

# Verificar (puede tardar mÃ¡s que Disk)
kubectl get pvc pvc-rwx-files
kubectl wait --for=jsonpath='{.status.phase}'=Bound pvc/pvc-rwx-files --timeout=120s
```

#### Paso 1.5: Crear Deployment con 5 rÃ©plicas usando RWX

Crea el archivo `deployment-rwx.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-rwx
  labels:
    lab: pv-pvc-avanzado
spec:
  replicas: 5  # MÃºltiples rÃ©plicas, sin problemas
  selector:
    matchLabels:
      app: app-rwx
  template:
    metadata:
      labels:
        app: app-rwx
    spec:
      containers:
      - name: app
        image: busybox
        command:
        - sh
        - -c
        - |
          echo "Pod: $(hostname)"
          echo "Nodo: $NODE_NAME"
          
          # Crear directorio por Pod
          mkdir -p /shared/pods/$(hostname)
          
          # Escribir datos
          while true; do
            echo "$(date): Pod $(hostname) en nodo $NODE_NAME" >> /shared/pods/$(hostname)/log.txt
            echo "$(date): Global desde $(hostname)" >> /shared/global.log
            echo "EscribÃ­ en /shared/pods/$(hostname)/log.txt"
            echo "Total de Pods activos: $(ls -1 /shared/pods/ | wc -l)"
            sleep 10
          done
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: shared-storage
          mountPath: /shared
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "200m"
      volumes:
      - name: shared-storage
        persistentVolumeClaim:
          claimName: pvc-rwx-files
```

```bash
# Aplicar
kubectl apply -f deployment-rwx.yaml

# Esperar
sleep 15

# Ver estado de los Pods
kubectl get pods -l app=app-rwx -o wide

# âœ… TODOS los Pods deben estar Running
# âœ… Pueden estar en diferentes nodos
```

#### Paso 1.6: Verificar comparticiÃ³n de datos

```bash
# Ver logs de varios Pods
kubectl logs -l app=app-rwx --tail=5 --prefix | head -30

# Acceder a un Pod y ver datos de TODOS los Pods
POD=$(kubectl get pod -l app=app-rwx -o jsonpath='{.items[0].metadata.name}')
kubectl exec $POD -- ls -l /shared/pods/
# DeberÃ­as ver directorios de los 5 Pods âœ…

# Ver log global (escrito por todos)
kubectl exec $POD -- tail -20 /shared/global.log
# VerÃ¡s entradas de mÃºltiples Pods âœ…
```

### ğŸ” AnÃ¡lisis del Ejercicio 1

**ComparaciÃ³n**:

| Aspecto | ReadWriteOnce (Disk) | ReadWriteMany (Files) |
|---------|----------------------|----------------------|
| **StorageClass** | managed-csi | azurefile-csi |
| **TecnologÃ­a** | Azure Managed Disk | Azure Files (SMB) |
| **Nodos simultÃ¡neos** | 1 | MÃºltiples âœ… |
| **Rendimiento** | Alto (SSD) | Moderado |
| **Costo** | Bajo-Medio | Medio-Alto |
| **Caso de uso** | DB single-instance | Apps distribuidas |

**CuÃ¡ndo usar cada uno**:
- **RWO**: PostgreSQL, MySQL, MongoDB (1 rÃ©plica)
- **RWX**: WordPress, CMS, procesamiento distribuido

---

## ğŸ§ª Ejercicio 2: Reclaim Policies - Retain vs Delete (20 min)

### Objetivo
Entender y practicar las polÃ­ticas de recuperaciÃ³n de volÃºmenes.

### Parte A: PolÃ­tica Delete (por defecto)

#### Paso 2.1: Crear PVC con StorageClass Delete

```bash
# Usar PVC existente (pvc-rwo-disk tiene Delete por defecto)
kubectl get pvc pvc-rwo-disk

# Ver el PV asociado
PV_DELETE=$(kubectl get pvc pvc-rwo-disk -o jsonpath='{.spec.volumeName}')
echo "PV: $PV_DELETE"

# Verificar Reclaim Policy
kubectl get pv $PV_DELETE -o custom-columns=NAME:.metadata.name,RECLAIM:.spec.persistentVolumeReclaimPolicy
# Debe mostrar: Delete
```

#### Paso 2.2: Escribir datos y luego eliminar PVC

```bash
# Escribir datos
kubectl exec -it $(kubectl get pod -l app=app-rwo -o jsonpath='{.items[0].metadata.name}') -- \
  sh -c 'echo "Datos importantes con Delete policy" > /data/important.txt'

# Verificar datos
kubectl exec $(kubectl get pod -l app=app-rwo -o jsonpath='{.items[0].metadata.name}') -- \
  cat /data/important.txt

# Obtener URI del disco Azure
DISK_URI=$(kubectl get pv $PV_DELETE -o jsonpath='{.spec.csi.volumeHandle}')
echo "Disco Azure: $DISK_URI"

# Eliminar Deployment y PVC
kubectl delete deployment app-rwo
kubectl delete pvc pvc-rwo-disk

# Esperar un momento
sleep 5

# Verificar que PV se eliminÃ³
kubectl get pv $PV_DELETE
# Error: not found âœ…

# âš ï¸ El disco Azure tambiÃ©n se eliminÃ³
# Los datos se perdieron permanentemente
```

### Parte B: PolÃ­tica Retain

#### Paso 2.3: Crear StorageClass con Retain

Crea el archivo `storageclass-retain.yaml`:

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: disk-retain
  labels:
    lab: pv-pvc-avanzado
provisioner: disk.csi.azure.com
parameters:
  skuname: StandardSSD_LRS
  kind: Managed
reclaimPolicy: Retain  # â† Proteger datos
volumeBindingMode: WaitForFirstConsumer
allowVolumeExpansion: true
```

```bash
# Aplicar
kubectl apply -f storageclass-retain.yaml

# Verificar
kubectl get storageclass disk-retain
```

#### Paso 2.4: Crear PVC con Retain policy

Crea el archivo `pvc-retain.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-retain-test
  labels:
    lab: pv-pvc-avanzado
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: disk-retain  # â† Usa StorageClass con Retain
  resources:
    requests:
      storage: 3Gi
```

```bash
# Aplicar
kubectl apply -f pvc-retain.yaml
kubectl wait --for=jsonpath='{.status.phase}'=Bound pvc/pvc-retain-test --timeout=60s
```

#### Paso 2.5: Escribir datos "crÃ­ticos"

Crea el archivo `pod-retain-test.yaml`:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: data-saver
  labels:
    lab: pv-pvc-avanzado
spec:
  containers:
  - name: app
    image: busybox
    command:
    - sh
    - -c
    - |
      echo "=== Guardando datos crÃ­ticos ==="
      echo "Estos datos deben protegerse con Retain policy"
      
      # Crear datos "importantes"
      cat > /data/critical-data.json <<EOF
      {
        "database": "production",
        "backup_date": "$(date)",
        "records": 1000000,
        "status": "critical"
      }
      EOF
      
      echo "Datos guardados:"
      cat /data/critical-data.json
      
      sleep 3600
    volumeMounts:
    - name: critical-storage
      mountPath: /data
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
  volumes:
  - name: critical-storage
    persistentVolumeClaim:
      claimName: pvc-retain-test
```

```bash
# Aplicar
kubectl apply -f pod-retain-test.yaml
kubectl wait --for=condition=ready pod/data-saver --timeout=60s

# Ver logs
kubectl logs data-saver

# Verificar datos
kubectl exec data-saver -- cat /data/critical-data.json
```

#### Paso 2.6: Simular "eliminaciÃ³n accidental" del PVC

```bash
# Obtener nombre del PV
PV_RETAIN=$(kubectl get pvc pvc-retain-test -o jsonpath='{.spec.volumeName}')
echo "PV con Retain: $PV_RETAIN"

# Obtener URI del disco
DISK_URI_RETAIN=$(kubectl get pv $PV_RETAIN -o jsonpath='{.spec.csi.volumeHandle}')
echo "Disco protegido: $DISK_URI_RETAIN"

# âš ï¸ Simular eliminaciÃ³n accidental
kubectl delete pod data-saver
kubectl delete pvc pvc-retain-test

# Verificar estado del PV
kubectl get pv $PV_RETAIN
# STATUS: Released âœ… (NO eliminado)
```

#### Paso 2.7: Recuperar datos del PV

```bash
# Ver detalles del PV
kubectl describe pv $PV_RETAIN
# Observar: ClaimRef apunta al PVC eliminado

# Limpiar claimRef para poder reutilizar el PV
kubectl patch pv $PV_RETAIN -p '{"spec":{"claimRef":null}}'

# Verificar nuevo estado
kubectl get pv $PV_RETAIN
# STATUS: Available âœ…
```

#### Paso 2.8: Crear nuevo PVC para recuperar datos

Crea el archivo `pvc-recover.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-recovered-data
  labels:
    lab: pv-pvc-avanzado
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: disk-retain
  resources:
    requests:
      storage: 3Gi
```

```bash
# Aplicar
kubectl apply -f pvc-recover.yaml

# Verificar que se vinculÃ³ al PV existente
kubectl get pvc pvc-recovered-data
# Debe estar Bound al mismo PV

# Verificar datos recuperados
kubectl run data-recovery --image=busybox --rm -it --restart=Never \
  --overrides='
{
  "spec": {
    "containers": [{
      "name": "recovery",
      "image": "busybox",
      "command": ["cat", "/data/critical-data.json"],
      "volumeMounts": [{
        "name": "recovered",
        "mountPath": "/data"
      }]
    }],
    "volumes": [{
      "name": "recovered",
      "persistentVolumeClaim": {
        "claimName": "pvc-recovered-data"
      }
    }]
  }
}'

# âœ… Debe mostrar los datos originales
```

### ğŸ” AnÃ¡lisis del Ejercicio 2

**Flujo con Delete**:
1. PVC eliminado â†’ PV eliminado â†’ Disco eliminado
2. âŒ Datos perdidos permanentemente
3. âœ… Limpieza automÃ¡tica

**Flujo con Retain**:
1. PVC eliminado â†’ PV pasa a "Released"
2. âœ… Disco intacto, datos protegidos
3. Manual: Limpiar claimRef â†’ Crear nuevo PVC
4. âœ… Datos recuperados

**DecisiÃ³n**:
- **ProducciÃ³n/Datos crÃ­ticos**: Retain
- **Desarrollo/Datos temporales**: Delete

---

## ğŸ§ª Ejercicio 3: Troubleshooting de VolÃºmenes (10 min)

### Objetivo
Diagnosticar y resolver problemas comunes de almacenamiento.

### Escenario 1: PVC Stuck en Pending

#### Paso 3.1: Crear PVC que fallarÃ¡

Crea el archivo `pvc-problema.yaml`:

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-problema
  labels:
    lab: pv-pvc-avanzado
spec:
  accessModes:
    - ReadWriteMany  # â† Problema: managed-csi NO soporta RWX
  storageClassName: managed-csi  # â† Azure Disk
  resources:
    requests:
      storage: 5Gi
```

```bash
# Aplicar
kubectl apply -f pvc-problema.yaml

# Ver estado
kubectl get pvc pvc-problema
# STATUS: Pending âš ï¸

# Diagnosticar
kubectl describe pvc pvc-problema
```

**Buscar en Events**:
```
Warning  ProvisioningFailed  ... storageclass "managed-csi" not found or does not support ReadWriteMany
```

**SoluciÃ³n**:
```bash
# Eliminar PVC problemÃ¡tico
kubectl delete pvc pvc-problema

# Usar StorageClass correcto (azurefile-csi para RWX)
```

### Escenario 2: Multi-Attach Error

#### Paso 3.2: Recrear escenario de multi-attach

```bash
# Usar deployment-rwo.yaml del Ejercicio 1
# Si no existe, recrearlo
kubectl apply -f pvc-rwo.yaml
kubectl apply -f deployment-rwo.yaml

# Escalar para forzar distribuciÃ³n multi-nodo
kubectl scale deployment app-rwo --replicas=10

# Ver Pods pending
kubectl get pods -l app=app-rwo | grep Pending

# Diagnosticar
kubectl describe pod <pod-pending-name>
```

**Buscar en Events**:
```
Warning  FailedAttachVolume  ... Multi-Attach error for volume "pvc-..." 
         Volume is already used by pod(s) ...
```

**SoluciÃ³n**:
```bash
# OpciÃ³n 1: Reducir rÃ©plicas a 1
kubectl scale deployment app-rwo --replicas=1

# OpciÃ³n 2: Usar StatefulSet con volumeClaimTemplates
# (cada Pod obtiene su propio PVC)

# OpciÃ³n 3: Cambiar a Azure Files (RWX)
```

### Escenario 3: PV Released y no disponible

**Ya lo practicamos en Ejercicio 2** âœ…

**SoluciÃ³n recordatorio**:
```bash
kubectl patch pv <pv-name> -p '{"spec":{"claimRef":null}}'
```

### ğŸ” AnÃ¡lisis del Ejercicio 3

**Checklist de troubleshooting**:

1. **PVC Pending**:
   - âœ… Ver `kubectl describe pvc <nombre>`
   - âœ… Verificar Events
   - âœ… Verificar que StorageClass existe
   - âœ… Verificar compatibilidad Access Mode

2. **Multi-Attach Error**:
   - âœ… Verificar Access Mode (RWO = solo 1 nodo)
   - âœ… Ver `kubectl get pods -o wide` (distribuciÃ³n de nodos)
   - âœ… Considerar RWX o StatefulSet

3. **PV Released**:
   - âœ… Ver `kubectl get pv`
   - âœ… Limpiar claimRef con patch
   - âœ… Crear nuevo PVC

4. **Performance bajo**:
   - âœ… Considerar Premium SSD
   - âœ… Aumentar tamaÃ±o del disco (mÃ¡s IOPS)
   - âœ… Verificar que no hay throttling

---

## ğŸ§¹ Limpieza del Laboratorio

### Paso 1: Eliminar Deployments y Pods

```bash
# Deployments
kubectl delete deployment app-rwo app-rwx 2>/dev/null || true

# Pods individuales
kubectl delete pod data-saver 2>/dev/null || true
```

### Paso 2: Eliminar PVCs

```bash
# PVCs del lab
kubectl delete pvc pvc-rwx-files pvc-recovered-data 2>/dev/null || true

# Esperar a que se eliminen
kubectl wait --for=delete pvc/pvc-rwx-files --timeout=60s 2>/dev/null || true
```

### Paso 3: Limpiar PVs con Retain

```bash
# Ver PVs en estado Released
kubectl get pv | grep Released

# Eliminar manualmente los PVs Released
kubectl delete pv $PV_RETAIN 2>/dev/null || true
```

### Paso 4: Eliminar StorageClass custom

```bash
kubectl delete storageclass disk-retain
```

### Paso 5: Verificar limpieza

```bash
# No debe haber recursos del lab
kubectl get all,pvc,pv,storageclass -l lab=pv-pvc-avanzado

# Verificar PVs huÃ©rfanos
kubectl get pv
# Si hay PVs en Released, eliminarlos
```

---

## âœ… VerificaciÃ³n de Conocimientos

### Pregunta 1
**Â¿CuÃ¡l es la diferencia principal entre Azure Disk y Azure Files en tÃ©rminos de Access Mode?**

<details>
<summary>Ver respuesta</summary>

- **Azure Disk (managed-csi)**: Solo soporta **ReadWriteOnce (RWO)** - un solo nodo puede montar
- **Azure Files (azurefile-csi)**: Soporta **ReadWriteMany (RWX)** - mÃºltiples nodos pueden montar simultÃ¡neamente

Azure Disk es block storage (como un USB), mientras que Azure Files es file storage (como una carpeta compartida en red).

</details>

### Pregunta 2
**Â¿QuÃ© pasa con un PersistentVolume cuando eliminas su PVC si la Reclaim Policy es "Retain"?**

<details>
<summary>Ver respuesta</summary>

El PV pasa a estado **"Released"** pero NO se elimina:
1. El disco Azure permanece intacto con todos los datos
2. El PV sigue existiendo pero no estÃ¡ disponible para nuevos PVCs
3. Para reutilizarlo: `kubectl patch pv <name> -p '{"spec":{"claimRef":null}}'`
4. Luego crear nuevo PVC que se vincule al PV

Esto permite **recuperaciÃ³n de datos** en caso de eliminaciÃ³n accidental.

</details>

### Pregunta 3
**Â¿Por quÃ© un Deployment con 3 rÃ©plicas usando un PVC con ReadWriteOnce podrÃ­a tener solo 1 Pod Running?**

<details>
<summary>Ver respuesta</summary>

Porque **ReadWriteOnce** permite que solo un **nodo** monte el volumen:

- Si los 3 Pods van al mismo nodo: âœ… Los 3 funcionan
- Si los Pods se distribuyen entre nodos: âŒ Solo el primero funciona
- Los otros quedan Pending con "Multi-Attach error"

**SoluciÃ³n**:
- Usar ReadWriteMany (Azure Files) si necesitas mÃºltiples rÃ©plicas
- O usar StatefulSet con volumeClaimTemplates (cada Pod su propio PVC)

</details>

### Pregunta 4
**Â¿CuÃ¡ndo usarÃ­as Reclaim Policy "Retain" en lugar de "Delete"?**

<details>
<summary>Ver respuesta</summary>

**Usar Retain cuando**:
- Datos de producciÃ³n crÃ­ticos
- Bases de datos importantes
- Entornos regulados (compliance, auditorÃ­a)
- MigraciÃ³n entre clusters
- Necesitas backup manual antes de eliminar

**Usar Delete cuando**:
- Entornos de desarrollo/testing
- Datos temporales o fÃ¡cilmente reconstruibles
- CI/CD pipelines
- Quieres limpieza automÃ¡tica
- Datos respaldados externamente

**Regla**: En caso de duda para producciÃ³n â†’ **Retain** (mÃ¡s seguro)

</details>

---

## ğŸ“ Resumen del Laboratorio

**Lo que aprendiste**:

### 1. Access Modes en Azure

| Access Mode | StorageClass | Pods simultÃ¡neos | Caso de Uso |
|-------------|--------------|------------------|-------------|
| **ReadWriteOnce** | managed-csi | 1 nodo | PostgreSQL, MySQL |
| **ReadWriteMany** | azurefile-csi | MÃºltiples nodos | WordPress, CMS |

### 2. Reclaim Policies

| Policy | Al eliminar PVC | Caso de Uso |
|--------|-----------------|-------------|
| **Delete** | PV + disco eliminados | Dev/test, datos temporales |
| **Retain** | PV Released, disco intacto | ProducciÃ³n, datos crÃ­ticos |

### 3. Troubleshooting

| Problema | Causa | SoluciÃ³n |
|----------|-------|----------|
| PVC Pending | StorageClass incompatible | Verificar Access Mode compatible |
| Multi-Attach error | RWO con mÃºltiples nodos | Usar RWX o StatefulSet |
| PV Released | Retain policy, PVC eliminado | Patch claimRef, crear nuevo PVC |

### 4. Mejores PrÃ¡cticas

âœ… **Hacer**:
- Usar Retain para datos de producciÃ³n
- Verificar Access Mode segÃºn necesidad
- Monitorear PVs Released
- Etiquetar recursos claramente
- Hacer backups externos

âŒ **Evitar**:
- RWO con Deployments multi-rÃ©plica (usar StatefulSet)
- Delete para datos crÃ­ticos sin backup
- Ignorar PVs Released (generan costos)
- Cambiar Reclaim Policy despuÃ©s de crear PV

---

## ğŸ“Š Matriz de DecisiÃ³n de Almacenamiento

```
Â¿Necesitas almacenamiento persistente?
â”‚
â”œâ”€NOâ”€â†’ emptyDir (Lab 01)
â”‚
â””â”€SÃâ”€â†’ Â¿MÃºltiples Pods necesitan acceso simultÃ¡neo?
       â”‚
       â”œâ”€NOâ”€â†’ Â¿Es producciÃ³n?
       â”‚      â”‚
       â”‚      â”œâ”€SÃâ”€â†’ managed-csi (RWO) + Retain
       â”‚      â”‚      + Backups externos
       â”‚      â”‚
       â”‚      â””â”€NOâ”€â†’ managed-csi (RWO) + Delete
       â”‚
       â””â”€SÃâ”€â†’ azurefile-csi (RWX)
              â”‚
              â”œâ”€ProducciÃ³nâ”€â†’ Retain
              â””â”€Dev/Testâ”€â”€â”€â†’ Delete
```

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n Principal](../../README.md)
- [Ejemplos Completos](../../ejemplos/)
- [Laboratorio 01 - VolÃºmenes BÃ¡sicos](../lab-01-volumenes-basicos/)
- [Azure Disk Documentation](https://docs.microsoft.com/azure/aks/azure-disk-csi)
- [Azure Files Documentation](https://docs.microsoft.com/azure/aks/azure-files-csi)

---

## ğŸ”œ PrÃ³ximos Pasos

### Temas Avanzados (MÃ³dulo 16)

- **StatefulSets** con volumeClaimTemplates
- **Volume Snapshots** y backups
- **ExpansiÃ³n de volÃºmenes** (resize online)
- **CSI Drivers** avanzados
- **Performance tuning** de almacenamiento

### PrÃ¡ctica Adicional

1. Implementar PostgreSQL con StatefulSet
2. Configurar backup automatizado de PVs
3. Migrar aplicaciÃ³n de VM a AKS con datos
4. Implementar WordPress multi-rÃ©plica con Azure Files

---

**Â¡Excelente trabajo completando el Laboratorio 02!** ğŸ‰

Has dominado conceptos avanzados de almacenamiento persistente en Kubernetes. Ahora estÃ¡s preparado para diseÃ±ar soluciones de almacenamiento robustas y resilientes en Azure AKS.
