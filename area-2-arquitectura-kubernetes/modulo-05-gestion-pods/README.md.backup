# ğŸ¯ MÃ³dulo 05: GestiÃ³n Avanzada de Pods

> **De la TeorÃ­a a la PrÃ¡ctica: Gestionando Pods en ProducciÃ³n**

---

## ğŸ“‹ InformaciÃ³n del MÃ³dulo

| Aspecto | Detalle |
|---------|---------|
| **DuraciÃ³n estimada** | 4-5 horas (teorÃ­a + labs) |
| **Nivel** | Intermedio |
| **Prerequisito** | [MÃ³dulo 04: Pods vs Contenedores](../modulo-04-pods-vs-contenedores/) |
| **Modalidad** | PrÃ¡ctico-Intensivo |
| **VersiÃ³n K8s** | 1.28+ (Noviembre 2025) |
| **Entorno** | Minikube + Docker driver |

---

## ğŸ¯ Objetivos de Aprendizaje

Al finalizar este mÃ³dulo, serÃ¡s capaz de:

### ğŸ“ Manifiestos y ConfiguraciÃ³n
- âœ… Escribir manifiestos YAML completos y production-ready
- âœ… Configurar resource requests y limits correctamente
- âœ… Aplicar security contexts y polÃ­ticas de seguridad

### ğŸ”„ GestiÃ³n Operacional
- âœ… Gestionar el ciclo de vida completo de Pods
- âœ… Implementar health checks (liveness, readiness, startup)
- âœ… Organizar recursos con labels, selectors y annotations

### ğŸ” Debugging y Troubleshooting
- âœ… Diagnosticar problemas comunes de Pods
- âœ… Usar herramientas avanzadas de debugging
- âœ… Interpretar eventos y logs efectivamente

### ğŸ¨ Casos de Uso Avanzados
- âœ… Optimizar recursos segÃºn QoS classes
- âœ… Aplicar best practices de producciÃ³n
- âœ… Integrar patterns de observabilidad

---

## ğŸ“š Prerequisitos

### Conocimientos Previos
- âœ… Completado [MÃ³dulo 04: Pods vs Contenedores](../modulo-04-pods-vs-contenedores/)
- âœ… ComprensiÃ³n de quÃ© es un Pod y sus namespaces
- âœ… Familiaridad con patrones multi-contenedor (Sidecar, Init, Ambassador)
- âœ… Conocimientos bÃ¡sicos de YAML
- âœ… Experiencia bÃ¡sica con lÃ­nea de comandos

### Entorno TÃ©cnico
```bash
# Verificar Minikube
minikube version  # â‰¥ v1.32.0

# Verificar Docker
docker --version  # â‰¥ 24.0.0

# Verificar kubectl
kubectl version --client  # â‰¥ v1.28.0

# Cluster debe estar corriendo
minikube status
# Expected: Running
```

### âš ï¸ Importante: SeparaciÃ³n con MÃ³dulo 04

| Aspecto | MÃ³dulo 04 (Prerequisito) | **MÃ³dulo 05 (Este)** |
|---------|--------------------------|----------------------|
| **Enfoque** | Â¿QuÃ© es un Pod? | Â¿CÃ³mo gestionarlo? |
| **Nivel** | Conceptual/ArquitectÃ³nico | Operacional/PrÃ¡ctico |
| **Contenido** | Namespaces, Patrones bÃ¡sicos | Manifiestos, Resources, Probes |
| **Objetivo** | Entender arquitectura interna | Dominar configuraciÃ³n y operaciÃ³n |

Si no has completado el MÃ³dulo 04, **hazlo primero** para comprender los fundamentos arquitectÃ³nicos de los Pods.

---

## ğŸ—ºï¸ Estructura del MÃ³dulo

Este mÃ³dulo sigue la progresiÃ³n **TeorÃ­a â†’ Ejemplo â†’ Laboratorio**:

| SecciÃ³n | Tema | Contenido |
|---------|------|-----------|
| **1** | [Manifiestos YAML](#-1-manifiestos-yaml-production-ready) | Estructura completa, campos obligatorios, mejores prÃ¡cticas |
| **2** | [GestiÃ³n del Ciclo de Vida](#-2-gestiÃ³n-del-ciclo-de-vida) | Estados, transiciones, comandos de gestiÃ³n |
| **3** | [Labels y Selectors](#-3-labels-selectors-y-annotations) | OrganizaciÃ³n, filtrado, casos de uso |
| **4** | [Resource Management](#-4-resource-management) | Requests, Limits, QoS classes |
| **5** | [Health Checks](#-5-health-checks-y-probes) | Liveness, Readiness, Startup probes |
| **6** | [Security Contexts](#-6-security-contexts) | runAsUser, capabilities, polÃ­ticas |
| **7** | [Debugging Avanzado](#-7-debugging-y-troubleshooting) | Herramientas, patterns, eventos |
| **8** | [Best Practices](#-8-best-practices-de-producciÃ³n) | Patrones, antipatrones, optimizaciÃ³n |

---

## ğŸ“ Recursos de Aprendizaje

### Ejemplos PrÃ¡cticos
ğŸ“ **Carpeta**: [`ejemplos/`](./ejemplos/)
- 50+ archivos YAML production-ready
- Organizado por tema y complejidad
- Cada ejemplo incluye comentarios explicativos

### Laboratorios Guiados
ğŸ“ **Carpeta**: [`laboratorios/`](./laboratorios/)
- Laboratorios hands-on con verificaciones
- DuraciÃ³n total: ~3-4 horas de prÃ¡ctica
- Incluyen troubleshooting y cleanup

### DocumentaciÃ³n de Referencia
- ğŸ“– [`ejemplos/README.md`](./ejemplos/README.md) - Ãndice completo de ejemplos
- ğŸ“– [`laboratorios/README.md`](./laboratorios/README.md) - GuÃ­a de laboratorios
- ğŸ“˜ **[`RESUMEN-MODULO.md`](./RESUMEN-MODULO.md)** - **GuÃ­a de estudio estructurada** (RECOMENDADO)

---

## ğŸ“ GuÃ­a de Estudio Recomendada

Para maximizar tu aprendizaje, sigue esta ruta estructurada:

```
Fase 1: Manifiestos YAML (60-90 min)
â”œâ”€ Estructura bÃ¡sica
â”œâ”€ Campos obligatorios y opcionales
â”œâ”€ Mejores prÃ¡cticas de escritura
â””â”€ Lab 01: Crear manifiestos

Fase 2: Resources y Health Checks (90-120 min)
â”œâ”€ Resource requests y limits
â”œâ”€ QoS classes
â”œâ”€ Probes (liveness, readiness, startup)
â””â”€ Lab 02: OptimizaciÃ³n de recursos

Fase 3: Seguridad y Labels (60-90 min)
â”œâ”€ Security contexts
â”œâ”€ Labels y selectors avanzados
â”œâ”€ Annotations y metadata
â””â”€ Lab 03: Hardening de Pods

Fase 4: Debugging y Production (60-90 min)
â”œâ”€ Herramientas de debugging
â”œâ”€ Troubleshooting patterns
â”œâ”€ Best practices
â””â”€ Lab 04: ResoluciÃ³n de problemas
```

ğŸ‘‰ **[ABRIR GUÃA DE ESTUDIO](./RESUMEN-MODULO.md)**

---

---

## ï¿½ 1. Manifiestos YAML Production-Ready

> **Objetivo**: Dominar la escritura de manifiestos Pod completos y optimizados para producciÃ³n

### 1.1. AnatomÃ­a de un Manifiesto Pod

#### **Estructura de 4 Niveles**

Todo manifiesto Pod en Kubernetes tiene 4 secciones raÃ­z obligatorias:

```yaml
apiVersion: v1      # 1. VersiÃ³n de la API K8s
kind: Pod           # 2. Tipo de recurso
metadata:           # 3. InformaciÃ³n identificativa
  name: mi-pod
  labels:
    app: frontend
spec:               # 4. EspecificaciÃ³n deseada
  containers:
  - name: nginx
    image: nginx:alpine
```

**ğŸ“– ExplicaciÃ³n de cada nivel:**

| Campo | DescripciÃ³n | Valores tÃ­picos |
|-------|-------------|-----------------|
| `apiVersion` | API version del recurso | `v1` para Pods |
| `kind` | Tipo de objeto K8s | `Pod`, `Deployment`, `Service` |
| `metadata` | InformaciÃ³n del objeto | name, labels, annotations |
| `spec` | Estado deseado | containers, volumes, etc |

---

#### **1.1.1. Metadata: IdentificaciÃ³n y OrganizaciÃ³n**

**Campos principales**:

```yaml
metadata:
  name: frontend-web               # Obligatorio: nombre Ãºnico
  namespace: production            # Opcional: default si se omite
  labels:                          # Opcional pero ALTAMENTE recomendado
    app: frontend
    version: v1.2.0
    tier: web
    environment: production
  annotations:                     # Opcional: metadata no identificativa
    description: "Frontend web server"
    maintainer: "devops@company.com"
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
```

**Diferencias clave: Labels vs Annotations**

| Aspecto | Labels | Annotations |
|---------|--------|-------------|
| **PropÃ³sito** | IdentificaciÃ³n y selecciÃ³n | Metadata adicional |
| **Usado por** | Selectors, Services, ReplicaSets | Herramientas, usuarios |
| **Filtrado** | âœ… SÃ­ (`-l app=frontend`) | âŒ No |
| **LÃ­mite** | 63 caracteres | Sin lÃ­mite prÃ¡ctico |
| **Ejemplos** | app, tier, env, version | URLs, descriptions, configs |

ğŸ’¡ **Ejemplo inline**:

```yaml
metadata:
  name: web-app
  labels:
    app: web              # Usado para selectors
    tier: frontend        # AgrupaciÃ³n lÃ³gica
  annotations:
    git-commit: "abc123"  # Info de deployment
```

```bash
# Filtrar por labels
kubectl get pods -l app=web
kubectl get pods -l tier=frontend
kubectl get pods -l 'environment in (production,staging)'
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/basicos/01-pod-con-labels.yaml`](./ejemplos/basicos/01-pod-con-labels.yaml)

---

#### **1.1.2. Spec: ConfiguraciÃ³n de Contenedores**

**Campos esenciales**:

```yaml
spec:
  containers:                    # Lista de contenedores (mÃ­nimo 1)
  - name: nginx                  # Nombre Ãºnico en el Pod
    image: nginx:1.25-alpine     # Imagen (preferir tags especÃ­ficos)
    imagePullPolicy: IfNotPresent  # Always, Never, IfNotPresent
    
    ports:                       # Puertos a exponer
    - containerPort: 80
      name: http                 # Nombre opcional para referencia
      protocol: TCP              # TCP, UDP, SCTP
    
    env:                         # Variables de entorno
    - name: ENVIRONMENT
      value: "production"
    - name: LOG_LEVEL
      value: "info"
    
    command: ["nginx"]           # Sobrescribe ENTRYPOINT
    args: ["-g", "daemon off;"]  # Sobrescribe CMD
```

**ğŸ”‘ Mejores prÃ¡cticas**:

1. âœ… **Tags especÃ­ficos** en producciÃ³n (evitar `latest`)
2. âœ… **Nombrar puertos** para facilitar referencias
3. âœ… **imagePullPolicy: IfNotPresent** para optimizar
4. âœ… **Un contenedor principal** por Pod (salvo patterns)

ğŸ’¡ **Ejemplo inline - Pod bÃ¡sico**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-basic
  labels:
    app: nginx
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    ports:
    - containerPort: 80
      name: http
```

```bash
# Aplicar
kubectl apply -f ejemplos/basicos/02-pod-simple.yaml

# Verificar
kubectl get pods
kubectl describe pod nginx-basic
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/basicos/02-pod-simple.yaml`](./ejemplos/basicos/02-pod-simple.yaml)

---

### 1.2. Variables de Entorno y ConfigMaps

#### **1.2.1. Variables directas**

```yaml
spec:
  containers:
  - name: app
    image: myapp
    env:
    - name: DATABASE_URL
      value: "postgres://db:5432/mydb"
    - name: API_KEY
      value: "hardcoded-key"          # âŒ NO recomendado para producciÃ³n
```

#### **1.2.2. Variables desde ConfigMap**

```yaml
env:
- name: DATABASE_URL
  valueFrom:
    configMapKeyRef:
      name: app-config
      key: database-url
```

ğŸ’¡ **Ejemplo inline completo**:

```yaml
# ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  environment: "production"
  log-level: "info"
  database-url: "postgres://db:5432"

---
# Pod usando ConfigMap
apiVersion: v1
kind: Pod
metadata:
  name: app-with-config
spec:
  containers:
  - name: app
    image: myapp
    envFrom:
    - configMapRef:
        name: app-config     # Carga TODAS las keys como env vars
```

```bash
# Aplicar
kubectl apply -f ejemplos/basicos/03-pod-con-configmap.yaml

# Ver env vars del Pod
kubectl exec app-with-config -- env | grep -E "environment|log-level"
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/basicos/03-pod-con-configmap.yaml`](./ejemplos/basicos/03-pod-con-configmap.yaml)

---

### 1.3. Volumes: Compartir Datos Entre Contenedores

#### **1.3.1. EmptyDir - Volume temporal**

```yaml
spec:
  volumes:
  - name: shared-data
    emptyDir: {}              # Se crea al iniciar Pod, se borra al eliminarlo
  
  containers:
  - name: writer
    image: busybox
    command: ["sh", "-c", "echo 'Hello' > /data/message.txt && sleep 3600"]
    volumeMounts:
    - name: shared-data
      mountPath: /data
  
  - name: reader
    image: busybox
    command: ["sh", "-c", "cat /data/message.txt && sleep 3600"]
    volumeMounts:
    - name: shared-data
      mountPath: /data
```

ğŸ’¡ **Ejemplo inline - Multi-contenedor con volume compartido**:

```bash
# Aplicar
kubectl apply -f ejemplos/multi-contenedor/01-shared-volume.yaml

# Verificar que ambos contenedores comparten datos
kubectl exec shared-volume -c reader -- cat /data/message.txt
# Output: Hello
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/multi-contenedor/01-shared-volume.yaml`](./ejemplos/multi-contenedor/01-shared-volume.yaml)

---

### 1.4. Resources: Requests y Limits

> **Nota**: Esta secciÃ³n es introductoria. Profundizaremos en [SecciÃ³n 4: Resource Management](#-4-resource-management)

```yaml
spec:
  containers:
  - name: app
    image: myapp
    resources:
      requests:              # Garantizado (usado por scheduler)
        memory: "128Mi"
        cpu: "250m"          # 250 millicores = 0.25 CPU
      limits:                # MÃ¡ximo permitido
        memory: "256Mi"
        cpu: "500m"
```

**Comportamiento**:
- **Memory limit excedido** â†’ OOMKilled (restart)
- **CPU limit excedido** â†’ Throttling (mÃ¡s lento, no restart)

ğŸ’¡ **Ejemplo inline**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-resources
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
```

```bash
# Aplicar
kubectl apply -f ejemplos/production-ready/01-with-resources.yaml

# Ver recursos asignados
kubectl describe pod app-with-resources | grep -A 5 "Limits\|Requests"
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/production-ready/01-with-resources.yaml`](./ejemplos/production-ready/01-with-resources.yaml)

---

### 1.5. Manifiesto Production-Ready Completo

**Checklist mÃ­nimo para producciÃ³n**:
- âœ… Tags especÃ­ficos de imagen
- âœ… Labels organizadas
- âœ… Resources definidos
- âœ… Health probes configurados (ver SecciÃ³n 5)
- âœ… Security context aplicado (ver SecciÃ³n 6)

ğŸ’¡ **Ejemplo inline - Pod production-ready**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: frontend-prod
  labels:
    app: frontend
    version: v1.2.0
    environment: production
  annotations:
    description: "Frontend web server"
spec:
  containers:
  - name: nginx
    image: nginx:1.25-alpine      # Tag especÃ­fico
    ports:
    - containerPort: 80
      name: http
    resources:
      requests:
        memory: "128Mi"
        cpu: "250m"
      limits:
        memory: "256Mi"
        cpu: "500m"
    livenessProbe:                # Ver SecciÃ³n 5
      httpGet:
        path: /healthz
        port: 80
      initialDelaySeconds: 30
    readinessProbe:
      httpGet:
        path: /ready
        port: 80
      initialDelaySeconds: 5
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/production-ready/02-complete-pod.yaml`](./ejemplos/production-ready/02-complete-pod.yaml)

---

### 1.6. Comandos Ãštiles para Manifiestos

```bash
# Generar manifiesto desde comando imperativo
kubectl run nginx --image=nginx:alpine --dry-run=client -o yaml > pod.yaml

# Aplicar manifiesto
kubectl apply -f pod.yaml

# Ver manifiesto aplicado
kubectl get pod nginx -o yaml

# Explicar campos de un recurso
kubectl explain pod
kubectl explain pod.spec
kubectl explain pod.spec.containers

# Validar sintaxis sin aplicar
kubectl apply -f pod.yaml --dry-run=client

# Ver diferencias antes de aplicar
kubectl diff -f pod.yaml
```

---

### âœ… Checkpoint SecciÃ³n 1

Antes de continuar, verifica que puedes:
- [ ] Explicar los 4 campos raÃ­z obligatorios de un manifiesto
- [ ] Distinguir entre labels y annotations
- [ ] Escribir un Pod con variables de entorno
- [ ] Crear un Pod con volume compartido entre contenedores
- [ ] Configurar resources bÃ¡sicos (requests/limits)

---

### ğŸ§ª Laboratorio 01: Crear Manifiestos YAML

**DuraciÃ³n**: 45 minutos

ğŸ“ **Laboratorio**: [`laboratorios/lab-01-crear-pods.md`](./laboratorios/lab-01-crear-pods.md)

**Objetivos**:
1. Crear Pod desde cero con todas las secciones
2. Agregar labels y annotations
3. Configurar variables de entorno
4. Implementar volume compartido
5. Aplicar resources bÃ¡sicos

---

## ğŸ”„ 2. GestiÃ³n del Ciclo de Vida
curl http://localhost:8080
# VerÃ¡s una pÃ¡gina HTML con informaciÃ³n del Pod
```

**CaracterÃ­sticas**:
- Servidor HTTP simple con Python
- Puerto 8080
- Genera contenido HTML dinÃ¡mico con hostname y fecha
- Ideal para testing de networking

---

#### **2. Pod con Variables de Entorno**

ğŸ“„ **Archivo**: [`ejemplos/basicos/pod-con-env.yaml`](./ejemplos/basicos/pod-con-env.yaml)

```bash
# Crear Pod
kubectl apply -f ejemplos/basicos/pod-con-env.yaml

# Verificar que estÃ¡ corriendo
kubectl get pod env-demo

# Ver variables de entorno configuradas
kubectl exec env-demo -- env | grep -E "ENV|APP_NAME|VERSION|LOG_LEVEL"

# Ver logs con el output
kubectl logs env-demo
```

**CaracterÃ­sticas**:
- Variables de entorno estÃ¡ndar
- Variables desde metadatos del Pod
- Ãštil para configuraciÃ³n de aplicaciones

---

#### **3. Pod con VolÃºmenes**

ğŸ“„ **Archivo**: [`ejemplos/basicos/pod-volumenes.yaml`](./ejemplos/basicos/pod-volumenes.yaml)

```bash
# Crear ConfigMap y Secret primero (estÃ¡n en el YAML)
kubectl apply -f ejemplos/basicos/pod-volumenes.yaml

# Verificar que estÃ¡ corriendo
kubectl get pod pod-volumenes

# Explorar volÃºmenes montados
kubectl exec -it pod-volumenes -- ls -la /data
kubectl exec -it pod-volumenes -- cat /config/app.conf
kubectl exec -it pod-volumenes -- cat /secrets/username

# Ver logs con demostraciÃ³n
kubectl logs pod-volumenes
```

**CaracterÃ­sticas**:
- EmptyDir: almacenamiento temporal
- ConfigMap: archivos de configuraciÃ³n
- Secret: credenciales sensibles
- Demuestra 3 tipos de volÃºmenes en un solo Pod

---

#### **4. Pod NGINX bÃ¡sico**

ğŸ“„ **Archivo**: [`ejemplos/basicos/pod-nginx.yaml`](./ejemplos/basicos/pod-nginx.yaml)

```bash
# Crear Pod
kubectl apply -f ejemplos/basicos/pod-nginx.yaml

# Verificar estado
kubectl get pod nginx-simple

# Port-forward
kubectl port-forward pod/nginx-simple 8080:80

# En otra terminal:
curl http://localhost:8080
```

**CaracterÃ­sticas**:
- NGINX Alpine (imagen ligera)
- Recursos definidos (requests/limits)
- Puerto 80
- Ideal para testing rÃ¡pido

---

### **ğŸ’¡ Comandos Ãštiles para Estos Ejemplos**

```bash
# Aplicar todos los ejemplos bÃ¡sicos
kubectl apply -f ejemplos/basicos/

# Ver todos los Pods con labels
kubectl get pods --show-labels

# Filtrar solo ejemplos bÃ¡sicos
kubectl get pods -l category=basico

# Ver detalles de recursos
kubectl describe pod python-server
kubectl describe pod env-demo
kubectl describe pod pod-volumenes
kubectl describe pod nginx-simple

# Limpiar todos los ejemplos
kubectl delete -f ejemplos/basicos/
```

---

### **ğŸ’¡ PrÃ¡ctica Recomendada**

ğŸ§ª **Laboratorio prÃ¡ctico**: [`laboratorios/lab-01-crear-pods.md`](./laboratorios/lab-01-crear-pods.md)

Este laboratorio te guÃ­a paso a paso en la creaciÃ³n de Pods usando mÃ©todos imperativos y declarativos con ejercicios prÃ¡cticos.

---

## ğŸ” 3. InspecciÃ³n y Debugging

### **3.1 Ver informaciÃ³n de Pods**

```bash
# Listar todos los Pods
kubectl get pods

# MÃ¡s detalles (IP, nodo, etc.)
kubectl get pods -o wide

# Ver con labels
kubectl get pods --show-labels

# Filtrar por label
kubectl get pods -l app=nginx

# Watch mode (actualizaciÃ³n en tiempo real)
kubectl get pods --watch

# Ver todos los recursos
kubectl get all
```

### **3.2 Describir un Pod (troubleshooting)**

```bash
# Ver detalles completos del Pod
kubectl describe pod nginx-pod
```

**Salida importante**:
```
Name:         nginx-pod
Namespace:    default
Node:         minikube/192.168.49.2
Status:       Running
IP:           10.244.0.5
Containers:
  nginx:
    Image:        nginx:1.25-alpine
    Port:         80/TCP
    State:        Running
      Started:    Sat, 09 Nov 2025 14:30:00 -0500

Events:         # â† MUY IMPORTANTE para debugging
  Type    Reason     Message
  ----    ------     -------
  Normal  Scheduled  Successfully assigned default/nginx-pod to minikube
  Normal  Pulling    Pulling image "nginx:1.25-alpine"
  Normal  Pulled     Successfully pulled image
  Normal  Created    Created container nginx
  Normal  Started    Started container nginx
```

**Casos de error comunes**:

#### **Error: ImagePullBackOff**

```bash
# Crear Pod con imagen inexistente
kubectl run error-pod --image=nginx:version-que-no-existe

# Ver el error
kubectl describe pod error-pod
```

**Eventos mostrarÃ¡n**:
```
Events:
  Normal   Scheduled  pod/error-pod
  Normal   Pulling    pulling image "nginx:version-que-no-existe"
  Warning  Failed     Failed to pull image: rpc error: code = NotFound
  Warning  Failed     Error: ErrImagePull
  Normal   BackOff    Back-off pulling image
```

**SoluciÃ³n**:
```bash
# Eliminar Pod con error
kubectl delete pod error-pod

# Crear con imagen correcta
kubectl run nginx-ok --image=nginx:alpine
```

### **3.3 Ver Logs de un Pod**

```bash
# Ver logs del Pod
kubectl logs nginx-pod

# Seguir logs en tiempo real (-f = follow)
kubectl logs nginx-pod -f

# Ver Ãºltimas 20 lÃ­neas
kubectl logs nginx-pod --tail=20

# Logs desde hace 1 hora
kubectl logs nginx-pod --since=1h

# Logs de un contenedor especÃ­fico (si hay mÃºltiples)
kubectl logs nginx-pod -c nginx

# Logs del Pod anterior (si se reiniciÃ³)
kubectl logs nginx-pod --previous
```

**Ejemplo con aplicaciÃ³n que loguea**:

```bash
# Crear Pod que genera logs
kubectl run log-generator --image=busybox -- sh -c \
  'while true; do echo "Log mensaje: $(date)"; sleep 2; done'

# Ver logs en tiempo real
kubectl logs log-generator -f

# Salida:
# Log mensaje: Sat Nov 9 19:30:00 UTC 2025
# Log mensaje: Sat Nov 9 19:30:02 UTC 2025
# ...
```

### **3.4 Ejecutar comandos en un Pod**

```bash
# Ejecutar comando simple
kubectl exec nginx-pod -- ls -la /usr/share/nginx/html

# Modo interactivo (-it)
kubectl exec -it nginx-pod -- sh

# Dentro del Pod:
# / # hostname
# nginx-pod
# / # cat /etc/os-release
# / # exit
```

**Ejemplo: Modificar contenido de nginx**:

```bash
# Entrar al Pod
kubectl exec -it nginx-pod -- sh

# Dentro del Pod:
cd /usr/share/nginx/html
echo "<h1>Hola desde Kubernetes!</h1>" > index.html
exit

# Verificar cambios (usando port-forward)
kubectl port-forward pod/nginx-pod 8080:80

# En otra terminal:
curl http://localhost:8080
# <h1>Hola desde Kubernetes!</h1>
```

### **3.5 Ver recursos utilizados**

```bash
# Instalar metrics-server en minikube
minikube addons enable metrics-server

# Esperar unos segundos y ver mÃ©tricas


> **Objetivo**: Comprender y gestionar eficientemente los estados y transiciones de los Pods

### 2.1. Estados del Pod (Pod Phases)

Un Pod pasa por diferentes **fases** durante su ciclo de vida:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ESTADOS DEL CICLO DE VIDA                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1. Pending      â†’ Esperando scheduling         â”‚
â”‚  2. Running      â†’ EjecutÃ¡ndose normalmente     â”‚
â”‚  3. Succeeded    â†’ TerminÃ³ exitosamente         â”‚
â”‚  4. Failed       â†’ TerminÃ³ con error            â”‚
â”‚  5. Unknown      â†’ Estado desconocido           â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **2.1.1. Pending**

**DescripciÃ³n**: Pod aceptado por K8s pero contenedores no estÃ¡n corriendo todavÃ­a.

**Causas comunes**:
- â³ Scheduler buscando nodo apropiado
- ğŸ“¥ Descargando imÃ¡genes
- âŒ Recursos insuficientes
- âŒ PersistentVolumeClaim no disponible

ğŸ’¡ **Ejemplo inline**:

```bash
# Crear Pod que permanecerÃ¡ en Pending (recursos imposibles)
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: pending-pod
spec:
  containers:
  - name: nginx
    image: nginx:alpine
    resources:
      requests:
        memory: "1000Gi"  # Imposible en cluster local
EOF

# Verificar estado
kubectl get pod pending-pod
# STATUS: Pending

# Ver razÃ³n especÃ­fica
kubectl describe pod pending-pod | grep -A 5 "Events:"
# Insufficient memory
```

---

#### **2.1.2. Running**

**DescripciÃ³n**: Pod asignado a nodo, al menos un contenedor corriendo.

**Condiciones**:
- âœ… Pod bound a un nodo
- âœ… Todos los containers creados
- âœ… Al menos 1 contenedor en estado Running

ğŸ’¡ **Ejemplo inline**:

```bash
# Pod simple que alcanza Running rÃ¡pidamente
kubectl run healthy-pod --image=nginx:alpine

# Ver estado y detalles
kubectl get pod healthy-pod -o wide
# STATUS: Running, NODE: minikube, IP: 10.244.0.x

# Ver condiciones especÃ­ficas
kubectl get pod healthy-pod -o jsonpath='{.status.conditions}' | jq
```

---

#### **2.1.3. Succeeded**

**DescripciÃ³n**: Todos los contenedores terminaron exitosamente (exit code 0).

**TÃ­pico en**:
- Jobs
- Batch processing
- Scripts one-time

ğŸ’¡ **Ejemplo inline**:

```bash
# Pod que ejecuta script y termina
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: success-pod
spec:
  restartPolicy: Never  # No reiniciar
  containers:
  - name: task
    image: busybox
    command: ["sh", "-c", "echo 'Task completed'; exit 0"]
EOF

# Esperar y verificar
sleep 5
kubectl get pod success-pod
# STATUS: Completed (Succeeded)

# Ver logs
kubectl logs success-pod
# Output: Task completed
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/patterns/01-job-pod.yaml`](./ejemplos/patterns/01-job-pod.yaml)

---

#### **2.1.4. Failed**

**DescripciÃ³n**: Al menos un contenedor terminÃ³ con error (exit code â‰  0).

**Causas comunes**:
- ğŸ’¥ AplicaciÃ³n crasheÃ³
- âŒ Command incorrecto
- âŒ OOMKilled (excediÃ³ memory limit)
- âŒ Error en cÃ³digo

ğŸ’¡ **Ejemplo inline**:

```bash
# Pod que falla intencionalmente
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: failed-pod
spec:
  restartPolicy: Never
  containers:
  - name: task
    image: busybox
    command: ["sh", "-c", "echo 'Starting...'; sleep 2; exit 1"]
EOF

# Verificar estado
sleep 5
kubectl get pod failed-pod
# STATUS: Error (Failed)

# Ver razÃ³n
kubectl describe pod failed-pod | grep -A 3 "State:"
# State: Terminated
# Exit Code: 1
```

---

#### **2.1.5. Unknown**

**DescripciÃ³n**: No se puede determinar el estado (usualmente problema de comunicaciÃ³n).

**Causas comunes**:
- ğŸ”Œ Nodo perdiÃ³ conectividad
- ğŸ’€ Kubelet no responde
- ğŸŒ Problemas de red

```bash
# Simular: detener minikube sin eliminar Pods
# (Solo para demostraciÃ³n, NO en producciÃ³n)

# Ver estado
kubectl get pods
# STATUS: Unknown
```

---

### 2.2. Restart Policies

Control de cÃ³mo K8s maneja reintentos de contenedores:

```yaml
spec:
  restartPolicy: Always  # Opciones: Always, OnFailure, Never
```

| Policy | Comportamiento | Uso tÃ­pico |
|--------|----------------|------------|
| `Always` | Siempre reinicia (default) | Services, long-running apps |
| `OnFailure` | Solo si exit code â‰  0 | Jobs, batch processing |
| `Never` | Nunca reinicia | One-time tasks |

ğŸ’¡ **Ejemplo comparativo**:

```yaml
# Always (default)
apiVersion: v1
kind: Pod
metadata:
  name: always-restart
spec:
  restartPolicy: Always
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "echo 'Running'; sleep 10; exit 1"]
# ReiniciarÃ¡ indefinidamente

---
# OnFailure
apiVersion: v1
kind: Pod
metadata:
  name: onfailure-restart
spec:
  restartPolicy: OnFailure
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "exit 1"]
# ReiniciarÃ¡ solo si falla

---
# Never
apiVersion: v1
kind: Pod
metadata:
  name: never-restart
spec:
  restartPolicy: Never
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "exit 1"]
# No reiniciarÃ¡, quedarÃ¡ en Failed
```

ğŸ“„ **Ver ejemplos completos**: [`ejemplos/patterns/02-restart-policies.yaml`](./ejemplos/patterns/02-restart-policies.yaml)

---

### 2.3. Container States

Cada contenedor dentro de un Pod tiene su propio estado:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       ESTADOS DE CONTAINER         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Waiting     â†’ PreparÃ¡ndose        â”‚
â”‚  Running     â†’ EjecutÃ¡ndose        â”‚
â”‚  Terminated  â†’ FinalizÃ³            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```bash
# Ver estado detallado de containers
kubectl get pod <pod-name> -o jsonpath='{.status.containerStatuses}' | jq

# Output ejemplo:
# {
#   "state": {
#     "running": {
#       "startedAt": "2025-11-12T10:30:00Z"
#     }
#   },
#   "ready": true,
#   "restartCount": 0
# }
```

---

### 2.4. Comandos de GestiÃ³n

#### **Crear Pods**

```bash
# Imperativo (rÃ¡pido para testing)
kubectl run nginx --image=nginx:alpine

# Declarativo (recomendado para producciÃ³n)
kubectl apply -f pod.yaml

# Crear desde stdin
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: quick-pod
spec:
  containers:
  - name: nginx
    image: nginx:alpine
EOF
```

#### **Actualizar Pods**

âš ï¸ **IMPORTANTE**: Pods son **inmutables**. Solo algunos campos se pueden modificar:

**Campos modificables**:
- `spec.containers[*].image` (solo imagen)
- `spec.activeDeadlineSeconds`
- `spec.tolerations`

**Campos NO modificables**:
- `spec.containers[*].resources`
- `spec.containers[*].command`
- `spec.containers[*].env`
- La mayorÃ­a de campos en `spec`

**SoluciÃ³n: Recrear**

```bash
# OpciÃ³n 1: Delete + Apply
kubectl delete pod nginx-pod
kubectl apply -f pod-updated.yaml

# OpciÃ³n 2: Replace --force (automÃ¡tico)
kubectl replace --force -f pod-updated.yaml
# Elimina y recrea en un comando
```

#### **Eliminar Pods**

```bash
# Eliminar por nombre
kubectl delete pod nginx-pod

# Eliminar por archivo
kubectl delete -f pod.yaml

# Eliminar por label
kubectl delete pods -l app=nginx

# Eliminar con grace period
kubectl delete pod nginx-pod --grace-period=30

# Forzar eliminaciÃ³n (âš ï¸ peligroso)
kubectl delete pod nginx-pod --force --grace-period=0
```

#### **Observar transiciones**

```bash
# Watch en tiempo real
kubectl get pods --watch

# Ver eventos de un Pod
kubectl get events --field-selector involvedObject.name=<pod-name> --sort-by='.lastTimestamp'

# Ver historial de reinicios
kubectl get pod <pod-name> -o jsonpath='{.status.containerStatuses[*].restartCount}'
```

---

### 2.5. Debugging de Estados

#### **CrashLoopBackOff**

**SÃ­ntoma**: Pod reinicia repetidamente

```bash
# Identificar problema
kubectl describe pod <pod-name>

# Ver logs del intento actual
kubectl logs <pod-name>

# Ver logs del intento anterior (crucial)
kubectl logs <pod-name> --previous

# Ver eventos
kubectl get events --field-selector involvedObject.name=<pod-name>
```

**Causas comunes**:
1. AplicaciÃ³n crashea al inicio
2. Liveness probe fallando
3. Command/args incorrectos
4. Permisos insuficientes

ğŸ’¡ **Ejemplo inline - Pod que crashea**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: crashloop-demo
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "echo 'Crashing...'; exit 1"]
# STATUS: CrashLoopBackOff despuÃ©s de algunos segundos
```

ğŸ“„ **Ver ejemplos de troubleshooting**: [`ejemplos/troubleshooting/01-crashloop.yaml`](./ejemplos/troubleshooting/01-crashloop.yaml)

---

#### **ImagePullBackOff**

**SÃ­ntoma**: No puede descargar imagen

```bash
# Ver detalles
kubectl describe pod <pod-name> | grep -A 5 "Events:"

# Causas:
# - Imagen no existe
# - Tag incorrecto
# - Registry privado sin credentials
```

---

### âœ… Checkpoint SecciÃ³n 2

Antes de continuar, verifica que puedes:
- [ ] Explicar los 5 estados de un Pod
- [ ] Distinguir entre Succeeded y Failed
- [ ] Configurar restart policies apropiadamente
- [ ] Identificar por quÃ© un Pod estÃ¡ en Pending
- [ ] Debuggear un CrashLoopBackOff
- [ ] Recrear un Pod para modificarlo

---

### ğŸ§ª Laboratorio 02: GestiÃ³n del Ciclo de Vida

**DuraciÃ³n**: 40 minutos

ğŸ“ **Laboratorio**: [`laboratorios/lab-02-multi-contenedor-labels.md`](./laboratorios/lab-02-multi-contenedor-labels.md) *(adaptar para ciclo de vida)* o **propuesto**: `lab-02-ciclo-vida.md`

**Objetivos**:
1. Observar transiciones de estados
2. Experimentar con restart policies
3. Simular y resolver CrashLoopBackOff
4. Practicar recreaciÃ³n de Pods
5. Analizar eventos y logs

---

## ğŸ·ï¸ 3. Labels, Selectors y Annotations

> **Objetivo**: Dominar la organizaciÃ³n y selecciÃ³n de Pods mediante metadata

### 3.1. Â¿QuÃ© son los Labels?

**Labels** son pares `clave=valor` adjuntos a objetos K8s para:
- ğŸ·ï¸ Organizar recursos lÃ³gicamente
- ğŸ” Filtrar y buscar eficientemente
- ğŸ¯ Permitir que Deployments/Services/ReplicaSets seleccionen Pods

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LABELS vs ANNOTATIONS            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Labels                                  â”‚
â”‚  âœ… Usadas para selecciÃ³n               â”‚
â”‚  âœ… Indexadas (bÃºsqueda rÃ¡pida)         â”‚
â”‚  âŒ Limitadas (63 chars max value)      â”‚
â”‚                                         â”‚
â”‚ Annotations                             â”‚
â”‚  âŒ NO usadas para selecciÃ³n            â”‚
â”‚  âœ… Sin lÃ­mite de tamaÃ±o                â”‚
â”‚  âœ… Metadata descriptiva                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Sintaxis de labels**:
- **Clave**: `[prefijo/]nombre`
  - `prefijo` (opcional): dominio DNS (max 253 chars)
  - `nombre`: requerido (max 63 chars), alfanumÃ©rico + `-` `_` `.`
- **Valor**: max 63 chars, alfanumÃ©rico + `-` `_` `.`

ğŸ’¡ **Ejemplo inline - Labels comunes**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: frontend-prod
  labels:
    # OrganizaciÃ³n bÃ¡sica
    app: nginx                    # Â¿QuÃ© aplicaciÃ³n?
    environment: production       # Â¿QuÃ© ambiente?
    tier: frontend               # Â¿QuÃ© capa?
    version: "1.0.5"             # Â¿QuÃ© versiÃ³n?
    
    # GestiÃ³n operacional
    team: platform               # Â¿QuiÃ©n es responsable?
    cost-center: marketing       # Â¿QuiÃ©n paga?
    
    # Release management
    release: stable              # Â¿QuÃ© canal?
    track: daily                 # Â¿QuÃ© track?
```

```bash
# Crear Pod con labels
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: labeled-pod
  labels:
    app: nginx
    environment: production
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:alpine
EOF

# Ver labels
kubectl get pod labeled-pod --show-labels
# NAME          READY   STATUS    LABELS
# labeled-pod   1/1     Running   app=nginx,environment=production,tier=frontend
```

---

### 3.2. Selectors (Filtrado)

#### **3.2.1. Equality-based (Igualdad)**

```bash
# app = frontend
kubectl get pods -l app=frontend

# app != frontend
kubectl get pods -l app!=frontend

# environment = production
kubectl get pods -l environment=production
```

#### **3.2.2. Set-based (Conjuntos)**

```bash
# environment IN (production, staging)
kubectl get pods -l 'environment in (production,staging)'

# tier NOT IN (backend)
kubectl get pods -l 'tier notin (backend)'

# EXISTS: tiene label "version"
kubectl get pods -l version

# NOT EXISTS: NO tiene label "version"
kubectl get pods -l '!version'
```

#### **3.2.3. CombinaciÃ³n (AND)**

```bash
# app=frontend AND environment=production
kubectl get pods -l 'app=frontend,environment=production'

# tier=frontend AND version in (1.0, 2.0)
kubectl get pods -l 'tier=frontend,version in (1.0,2.0)'
```

ğŸ’¡ **Ejemplo prÃ¡ctico - Filtrado avanzado**:

```bash
# Crear conjunto de Pods para demostraciÃ³n
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: frontend-prod
  labels:
    app: frontend
    environment: production
    tier: web
    version: "1.0"
spec:
  containers:
  - name: nginx
    image: nginx:alpine
---
apiVersion: v1
kind: Pod
metadata:
  name: frontend-dev
  labels:
    app: frontend
    environment: development
    tier: web
    version: "1.1"
spec:
  containers:
  - name: nginx
    image: nginx:alpine
---
apiVersion: v1
kind: Pod
metadata:
  name: backend-prod
  labels:
    app: backend
    environment: production
    tier: api
    version: "2.0"
spec:
  containers:
  - name: nginx
    image: nginx:alpine
EOF

# Filtros prÃ¡cticos
kubectl get pods -l app=frontend
# Resultado: frontend-prod, frontend-dev

kubectl get pods -l environment=production
# Resultado: frontend-prod, backend-prod

kubectl get pods -l 'app=frontend,environment=production'
# Resultado: solo frontend-prod

kubectl get pods -l 'tier in (web,api),environment=production'
# Resultado: frontend-prod, backend-prod

# Mostrar labels como columnas
kubectl get pods -L app,environment,tier,version
```

ğŸ“„ **Ver ejemplos completos**: [`ejemplos/basicos/pods-con-labels.yaml`](./ejemplos/basicos/pods-con-labels.yaml)

---

### 3.3. GestiÃ³n de Labels

#### **Agregar labels**

```bash
# Agregar label a Pod existente
kubectl label pod frontend-prod team=platform

# Agregar mÃºltiples labels
kubectl label pod frontend-prod cost-center=marketing release=stable

# Ver cambio
kubectl get pod frontend-prod --show-labels
```

#### **Modificar labels**

```bash
# Sobrescribir valor (requiere --overwrite)
kubectl label pod frontend-prod version=1.1 --overwrite

# Sin --overwrite falla
kubectl label pod frontend-prod version=1.2
# Error: already has a value (1.1)
```

#### **Eliminar labels**

```bash
# Eliminar label especÃ­fico (usar -)
kubectl label pod frontend-prod team-

# Verificar eliminaciÃ³n
kubectl get pod frontend-prod --show-labels
```

#### **Labels en selecciÃ³n de recursos**

```bash
# Eliminar todos los Pods con label app=frontend
kubectl delete pods -l app=frontend

# Eliminar Pods en development
kubectl delete pods -l environment=development

# Ver recursos sin eliminaciÃ³n (dry-run)
kubectl delete pods -l tier=web --dry-run=client
```

---

### 3.4. Annotations

**Annotations** son metadata NO usada para selecciÃ³n. Ãštiles para:
- ğŸ“ DocumentaciÃ³n
- ğŸ”§ InformaciÃ³n de tooling
- ğŸ“Š Tracking de cambios
- ğŸ”— URLs de dashboards

ğŸ’¡ **Ejemplo inline - Annotations vs Labels**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: annotated-pod
  labels:
    # Labels: PARA SELECCIÃ“N
    app: nginx
    environment: production
  
  annotations:
    # Annotations: METADATA DESCRIPTIVA
    description: "Frontend web server for product catalog"
    buildVersion: "build-1234"
    imageRepository: "https://hub.docker.com/_/nginx"
    lastModified: "2025-01-15T10:30:00Z"
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    contact: "platform-team@company.com"
spec:
  containers:
  - name: nginx
    image: nginx:alpine
```

```bash
# Crear Pod con annotations
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: annotated-pod
  labels:
    app: nginx
  annotations:
    description: "Production nginx server"
    buildVersion: "v1.2.3"
    contact: "devops@company.com"
spec:
  containers:
  - name: nginx
    image: nginx:alpine
EOF

# Ver annotations
kubectl describe pod annotated-pod | grep -A 10 "Annotations:"

# Agregar annotation
kubectl annotate pod annotated-pod lastRestart="2025-01-15T14:00:00Z"

# Modificar annotation (requiere --overwrite)
kubectl annotate pod annotated-pod buildVersion="v1.2.4" --overwrite

# Eliminar annotation
kubectl annotate pod annotated-pod contact-
```

**Â¿CuÃ¡ndo usar annotations vs labels?**

| Criterio | Labels | Annotations |
|----------|--------|-------------|
| **SelecciÃ³n por Services/Deployments** | âœ… SÃ­ | âŒ No |
| **Filtrar con `-l`** | âœ… SÃ­ | âŒ No |
| **LÃ­mite de tamaÃ±o** | 63 chars | Sin lÃ­mite prÃ¡ctico |
| **DocumentaciÃ³n extensa** | âŒ No | âœ… SÃ­ |
| **URLs/JSON/metadata compleja** | âŒ No | âœ… SÃ­ |

---

### 3.5. Use Cases PrÃ¡cticos

#### **Caso 1: Deployment que selecciona Pods**

```yaml
# Pod con labels especÃ­ficos
apiVersion: v1
kind: Pod
metadata:
  name: web-pod
  labels:
    app: webserver    # â† Deployment seleccionarÃ¡ esto
    tier: frontend
spec:
  containers:
  - name: nginx
    image: nginx:alpine
---
# Deployment que usa selector
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webserver  # â† Coincide con Pod labels
  template:
    metadata:
      labels:
        app: webserver
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
```

#### **Caso 2: SegregaciÃ³n por ambientes**

```bash
# Crear Pods en diferentes ambientes
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: db-prod
  labels:
    app: database
    environment: production
spec:
  containers:
  - name: postgres
    image: postgres:alpine
---
apiVersion: v1
kind: Pod
metadata:
  name: db-dev
  labels:
    app: database
    environment: development
spec:
  containers:
  - name: postgres
    image: postgres:alpine
EOF

# Operaciones selectivas
kubectl get pods -l environment=production
kubectl delete pods -l environment=development

# Escalar solo production
# (usado en Deployments/ReplicaSets)
```

#### **Caso 3: Canary deployments**

```yaml
# 95% de trÃ¡fico a stable
apiVersion: v1
kind: Pod
metadata:
  name: app-stable
  labels:
    app: myapp
    track: stable    # â† Service selecciona esto
spec:
  containers:
  - name: app
    image: myapp:v1.0
---
# 5% de trÃ¡fico a canary
apiVersion: v1
kind: Pod
metadata:
  name: app-canary
  labels:
    app: myapp
    track: canary    # â† Service tambiÃ©n selecciona esto
spec:
  containers:
  - name: app
    image: myapp:v2.0-beta
```

ğŸ“„ **Ver ejemplos avanzados**: [`ejemplos/patterns/03-labels-advanced.yaml`](./ejemplos/patterns/03-labels-advanced.yaml)

---

### âœ… Checkpoint SecciÃ³n 3

Antes de continuar, verifica que puedes:
- [ ] Explicar diferencia entre labels y annotations
- [ ] Crear Pods con labels especÃ­ficos
- [ ] Filtrar Pods con equality-based selectors
- [ ] Filtrar Pods con set-based selectors
- [ ] Combinar mÃºltiples condiciones (AND)
- [ ] Agregar/modificar/eliminar labels dinÃ¡micamente
- [ ] Decidir cuÃ¡ndo usar label vs annotation
- [ ] Entender cÃ³mo Deployments seleccionan Pods

---

### ğŸ§ª Laboratorio 03: Labels y Selectors

**DuraciÃ³n**: 30 minutos

ğŸ“ **Laboratorio**: [`laboratorios/lab-02-multi-contenedor-labels.md`](./laboratorios/lab-02-multi-contenedor-labels.md) *(incluye labels)* o **propuesto**: `lab-03-labels-selectors.md`

**Objetivos**:
1. Crear Pods con estrategia de labels multi-dimensionales
2. Practicar filtrado avanzado con selectors
3. Simular canary deployment con labels
4. Gestionar labels dinÃ¡micamente
5. Diferenciar annotations de labels en casos reales

---

## âš™ï¸ 4. Resource Management: Requests y Limits

> **Objetivo**: Optimizar uso de recursos y garantizar estabilidad mediante requests y limits

### 4.1. Â¿Por quÃ© gestionar recursos?

**Sin lÃ­mites**:
- ğŸ’¥ Un Pod puede consumir todos los recursos del nodo
- ğŸ’¥ Otros Pods mueren por falta de recursos (OOMKilled)
- ğŸ’¥ Nodo completo puede volverse inestable

**Con lÃ­mites**:
- âœ… Recursos garantizados (requests)
- âœ… ProtecciÃ³n contra consumo excesivo (limits)
- âœ… Scheduler puede decidir placement Ã³ptimo
- âœ… QoS (Quality of Service) classes automÃ¡ticas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        REQUESTS vs LIMITS                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚  Requests                                  â”‚
â”‚  â€¢ Recursos GARANTIZADOS                   â”‚
â”‚  â€¢ Scheduler usa esto para placement       â”‚
â”‚  â€¢ Pod puede usar MÃS si hay disponible    â”‚
â”‚                                            â”‚
â”‚  Limits                                    â”‚
â”‚  â€¢ Recursos MÃXIMOS                        â”‚
â”‚  â€¢ CPU: throttling                         â”‚
â”‚  â€¢ Memory: OOMKilled si excede             â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.2. Requests (GarantÃ­as)

**Requests** = mÃ­nimo garantizado que el Pod necesita.

ğŸ’¡ **Ejemplo inline - Requests bÃ¡sico**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-requests
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"   # 64 mebibytes garantizados
        cpu: "250m"      # 250 millicores = 0.25 CPU garantizados
```

```bash
# Crear Pod
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-requests
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
EOF

# Ver recursos asignados
kubectl describe pod pod-with-requests | grep -A 5 "Requests:"

# Output:
#   Requests:
#     cpu:        250m
#     memory:     64Mi
```

**Unidades de medida**:

| Recurso | Unidades | Ejemplos |
|---------|----------|----------|
| **CPU** | millicores (m) | `100m` = 0.1 CPU<br>`500m` = 0.5 CPU<br>`1` = 1 CPU<br>`2` = 2 CPUs |
| **Memory** | bytes, Ki, Mi, Gi | `128Mi` = 128 mebibytes<br>`1Gi` = 1 gibibyte<br>`512000000` = 512 MB |

**Comportamiento del Scheduler**:

```bash
# Si nodo tiene solo 1 CPU disponible
# Pod con request 500m âœ… se programa
# Pod con request 1500m âŒ queda Pending
```

ğŸ’¡ **Ejemplo - Pod que no cabe**:

```bash
# Crear Pod con request imposible
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: impossible-request
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "1000Gi"  # 1 TB - imposible en minikube
        cpu: "100"        # 100 CPUs - imposible
EOF

# Ver estado
kubectl get pod impossible-request
# STATUS: Pending

# Ver razÃ³n
kubectl describe pod impossible-request | grep -A 5 "Events:"
# Warning: FailedScheduling - Insufficient cpu/memory
```

---

### 4.3. Limits (Restricciones)

**Limits** = mÃ¡ximo que el Pod puede consumir.

ğŸ’¡ **Ejemplo inline - Limits bÃ¡sico**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-limits
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"   # MÃ¡ximo 128Mi (si excede â†’ OOMKilled)
        cpu: "500m"       # MÃ¡ximo 0.5 CPU (si excede â†’ throttling)
```

**Comportamiento al exceder limits**:

| Recurso | Comportamiento |
|---------|----------------|
| **CPU** | ğŸ¢ **Throttling** - se ralentiza, NO se mata |
| **Memory** | ğŸ’€ **OOMKilled** - se termina el contenedor |

ğŸ’¡ **Ejemplo - Memory OOMKilled**:

```bash
# Crear Pod con memory limit bajo
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: oom-demo
spec:
  containers:
  - name: memory-hog
    image: polinux/stress
    resources:
      requests:
        memory: "50Mi"
      limits:
        memory: "100Mi"
    command: ["stress"]
    args:
    - "--vm"
    - "1"
    - "--vm-bytes"
    - "150M"  # â† Intenta usar 150Mi, limit es 100Mi
    - "--vm-hang"
    - "1"
EOF

# Observar estado
kubectl get pod oom-demo --watch
# VerÃ¡s: Running â†’ OOMKilled â†’ CrashLoopBackOff

# Ver razÃ³n
kubectl describe pod oom-demo | grep -A 3 "Last State:"
# Last State:     Terminated
#   Reason:       OOMKilled
#   Exit Code:    137
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/production-ready/02-resources.yaml`](./ejemplos/production-ready/02-resources.yaml)

---

### 4.4. QoS Classes (Quality of Service)

Kubernetes asigna automÃ¡ticamente una **QoS class** segÃºn requests/limits:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QoS CLASSES                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                   â”‚
â”‚  1. Guaranteed (mÃ¡s prioritario)                 â”‚
â”‚     requests = limits (ambos CPU y Memory)       â”‚
â”‚     Ãšltimo en ser evicted                        â”‚
â”‚                                                   â”‚
â”‚  2. Burstable (prioridad media)                  â”‚
â”‚     requests < limits (o solo requests)          â”‚
â”‚     Evicted si nodo bajo presiÃ³n                 â”‚
â”‚                                                   â”‚
â”‚  3. BestEffort (menos prioritario)               â”‚
â”‚     Sin requests ni limits                       â”‚
â”‚     Primer en ser evicted                        â”‚
â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ **Ejemplo inline - QoS classes**:

```yaml
# 1. Guaranteed
apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-pod
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "128Mi"
        cpu: "500m"
      limits:
        memory: "128Mi"  # â† Igual a requests
        cpu: "500m"      # â† Igual a requests
# QoS Class: Guaranteed

---
# 2. Burstable
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod
spec:
  containers:
  - name: app
    image: nginx:alpine
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"  # â† Mayor a requests
        cpu: "500m"      # â† Mayor a requests
# QoS Class: Burstable

---
# 3. BestEffort
apiVersion: v1
kind: Pod
metadata:
  name: besteffort-pod
spec:
  containers:
  - name: app
    image: nginx:alpine
    # Sin resources
# QoS Class: BestEffort
```

```bash
# Crear los 3 Pods
kubectl apply -f - <<EOF
[copiar YAMLs de arriba]
EOF

# Ver QoS class
kubectl get pod guaranteed-pod -o jsonpath='{.status.qosClass}'
# Output: Guaranteed

kubectl get pod burstable-pod -o jsonpath='{.status.qosClass}'
# Output: Burstable

kubectl get pod besteffort-pod -o jsonpath='{.status.qosClass}'
# Output: BestEffort

# Ver en describe
kubectl describe pod guaranteed-pod | grep "QoS Class:"
```

**Orden de eviction** (cuando nodo sin recursos):
1. BestEffort primero ğŸ’¥
2. Burstable despuÃ©s ğŸ’¥
3. Guaranteed Ãºltimo ğŸ’¥

---

### 4.5. Monitoring de Recursos

```bash
# Ver consumo actual de CPU/Memory
kubectl top pods

# Output:
# NAME        CPU(cores)   MEMORY(bytes)
# nginx-pod   1m           3Mi

# Ver recursos configurados vs consumo
kubectl describe pod nginx-pod | grep -A 10 "Limits:"

# Comparar request vs limit vs actual
kubectl get pod nginx-pod -o json | jq '.spec.containers[0].resources'
kubectl top pod nginx-pod
```

**Instalar Metrics Server** (si no estÃ¡ disponible):

```bash
# Verificar si existe
kubectl top nodes

# Si falla, instalar en minikube
minikube addons enable metrics-server

# Esperar 30 segundos y probar
kubectl top pods
```

---

### 4.6. Best Practices - Resource Management

#### **1. SIEMPRE define requests**

```yaml
# âŒ MAL - Sin requests
spec:
  containers:
  - name: app
    image: myapp

# âœ… BIEN - Con requests
spec:
  containers:
  - name: app
    image: myapp
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
```

**RazÃ³n**: Scheduler necesita requests para placement Ã³ptimo.

---

#### **2. Define limits para evitar resource hogging**

```yaml
# âœ… RECOMENDADO - Requests + Limits
spec:
  containers:
  - name: app
    image: myapp
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"  # 2x requests
        cpu: "500m"      # 5x requests (permite bursting)
```

---

#### **3. Calcular requests apropiados**

```bash
# MÃ©todo empÃ­rico:
# 1. Desplegar sin limits
# 2. Observar consumo real con load
kubectl top pods --containers
# 3. Configurar:
#    requests = consumo promedio
#    limits = consumo pico + 20% buffer
```

---

#### **4. Memory: lÃ­mites conservadores**

```yaml
# Memory:
# - Exceder limit = OOMKilled (servicio muere)
# - Usar limits realistas
resources:
  requests:
    memory: "256Mi"
  limits:
    memory: "512Mi"  # Solo 2x, no 10x
```

---

#### **5. CPU: lÃ­mites generosos**

```yaml
# CPU:
# - Exceder limit = throttling (solo lentitud)
# - Permitir bursting para picos de trÃ¡fico
resources:
  requests:
    cpu: "100m"      # Normal load
  limits:
    cpu: "1"         # 10x para picos (OK)
```

---

### 4.7. Troubleshooting Resources

#### **Pending por recursos insuficientes**

```bash
# SÃ­ntoma
kubectl get pods
# STATUS: Pending

# DiagnÃ³stico
kubectl describe pod <pod-name> | grep -A 5 "Events:"
# Warning: FailedScheduling - Insufficient cpu/memory

# Soluciones:
# 1. Reducir requests del Pod
# 2. Agregar mÃ¡s nodos al cluster
# 3. Escalar down otros Pods
```

---

#### **OOMKilled repetidamente**

```bash
# SÃ­ntoma
kubectl get pods
# STATUS: CrashLoopBackOff

# DiagnÃ³stico
kubectl describe pod <pod-name> | grep "Reason:"
# Reason: OOMKilled

# Ver memory actual vs limit
kubectl top pod <pod-name>
kubectl describe pod <pod-name> | grep -A 3 "Limits:"

# SoluciÃ³n: Incrementar memory limit
# requests:
#   memory: "256Mi"
# limits:
#   memory: "512Mi"  â† Incrementar esto
```

---

#### **CPU Throttling**

```bash
# DiagnÃ³stico
kubectl top pods
# CPU(cores) cerca de limit pero pod lento

# Ver throttling metrics (requiere monitoring avanzado)
# SoluciÃ³n: Incrementar CPU limit
```

---

### âœ… Checkpoint SecciÃ³n 4

Antes de continuar, verifica que puedes:
- [ ] Explicar diferencia entre requests y limits
- [ ] Configurar resources en un Pod
- [ ] Entender unidades (millicores, Mi, Gi)
- [ ] Predecir comportamiento al exceder limit (CPU vs Memory)
- [ ] Identificar las 3 QoS classes
- [ ] Diagnosticar un Pod Pending por recursos
- [ ] Resolver un OOMKilled ajustando limits
- [ ] Usar `kubectl top` para monitoring

---

### ğŸ§ª Laboratorio 04: Resource Management

**DuraciÃ³n**: 50 minutos

ğŸ“ **Laboratorio propuesto**: `laboratorios/lab-04-resources.md` *(pendiente de crear)*

**Objetivos**:
1. Configurar requests y limits apropiados
2. Observar comportamiento de QoS classes
3. Simular y resolver OOMKilled
4. Practicar cÃ¡lculo de recursos Ã³ptimos
5. Implementar resource quotas a nivel namespace

---

## ğŸ’Š 5. Health Checks: Probes

> **Objetivo**: Garantizar que Kubernetes solo envÃ­e trÃ¡fico a Pods sanos y reinicie Pods problemÃ¡ticos automÃ¡ticamente

### 5.1. Â¿Por quÃ© necesitamos Health Checks?

**Sin probes**:
- ğŸ’¥ Pod puede estar "Running" pero app crasheada internamente
- ğŸ’¥ Traffic enviado a Pods que no estÃ¡n listos
- ğŸ’¥ Pods muertos que K8s cree que estÃ¡n sanos
- ğŸ’¥ Deadlocks no detectados

**Con probes**:
- âœ… DetecciÃ³n automÃ¡tica de problemas
- âœ… Restart automÃ¡tico de Pods enfermos
- âœ… Traffic solo a Pods completamente listos
- âœ… Tiempo de recuperaciÃ³n optimizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TIPOS DE PROBES                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                   â”‚
â”‚  1. Liveness Probe                               â”‚
â”‚     Â¿EstÃ¡ VIVO el contenedor?                    â”‚
â”‚     Si falla â†’ Kubernetes REINICIA el Pod        â”‚
â”‚                                                   â”‚
â”‚  2. Readiness Probe                              â”‚
â”‚     Â¿EstÃ¡ LISTO para recibir trÃ¡fico?           â”‚
â”‚     Si falla â†’ Se ELIMINA de endpoints           â”‚
â”‚                                                   â”‚
â”‚  3. Startup Probe                                â”‚
â”‚     Â¿CompletÃ³ el arranque inicial?              â”‚
â”‚     Protege apps con startup lento               â”‚
â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5.2. Liveness Probe (Â¿EstÃ¡ vivo?)

**PropÃ³sito**: Detectar si el contenedor estÃ¡ muerto/bloqueado y necesita reiniciarse.

**CuÃ¡ndo falla**: K8s **mata y reinicia** el contenedor.

ğŸ’¡ **Ejemplo inline - HTTP Liveness Probe**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: liveness-http
spec:
  containers:
  - name: web
    image: nginx:alpine
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /         # â† Endpoint a verificar
        port: 80
      initialDelaySeconds: 5   # Esperar 5s antes de primera prueba
      periodSeconds: 10        # Probar cada 10s
      timeoutSeconds: 1        # Timeout de 1s
      failureThreshold: 3      # 3 fallos consecutivos = reiniciar
```

```bash
# Crear Pod
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: liveness-http
spec:
  containers:
  - name: web
    image: nginx:alpine
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 1
      failureThreshold: 3
EOF

# Ver eventos de liveness
kubectl describe pod liveness-http | grep -A 10 "Liveness:"

# Simular fallo: detener nginx dentro del contenedor
kubectl exec liveness-http -- sh -c "killall nginx"

# Observar reinicio automÃ¡tico
kubectl get pod liveness-http --watch
# VerÃ¡s RESTARTS incrementar
```

---

#### **5.2.1. Tipos de Liveness Probes**

**A. HTTP GET**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
    httpHeaders:
    - name: Custom-Header
      value: Awesome
  initialDelaySeconds: 3
  periodSeconds: 3
```

**Uso**: APIs REST, web servers.

---

**B. TCP Socket**

```yaml
livenessProbe:
  tcpSocket:
    port: 3306
  initialDelaySeconds: 15
  periodSeconds: 10
```

**Uso**: Databases (MySQL, PostgreSQL), servicios que no tienen HTTP.

---

**C. Exec Command**

```yaml
livenessProbe:
  exec:
    command:
    - cat
    - /tmp/healthy
  initialDelaySeconds: 5
  periodSeconds: 5
```

**Uso**: Custom health checks, file-based readiness.

ğŸ’¡ **Ejemplo prÃ¡ctico - Exec Liveness**:

```bash
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
EOF

# Observar comportamiento
kubectl get pod liveness-exec --watch

# DespuÃ©s de 30s, archivo se elimina â†’ probe falla â†’ Pod reinicia
# RESTARTS: 0 â†’ 1 â†’ 2 â†’ ...
```

ğŸ“„ **Ver ejemplos completos**: [`ejemplos/production-ready/03-health-checks.yaml`](./ejemplos/production-ready/03-health-checks.yaml)

---

### 5.3. Readiness Probe (Â¿EstÃ¡ listo?)

**PropÃ³sito**: Determinar si el Pod estÃ¡ listo para recibir trÃ¡fico.

**CuÃ¡ndo falla**: K8s **NO envÃ­a trÃ¡fico** al Pod (se elimina de Service endpoints).

ğŸ’¡ **Diferencia clave con Liveness**:

| Probe | Si falla... |
|-------|-------------|
| **Liveness** | ğŸ’€ Contenedor se REINICIA |
| **Readiness** | ğŸš« Pod se ELIMINA de endpoints (sin reinicio) |

ğŸ’¡ **Ejemplo inline - Readiness Probe**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: readiness-demo
  labels:
    app: web
spec:
  containers:
  - name: web
    image: nginx:alpine
    ports:
    - containerPort: 80
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5
      failureThreshold: 3
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 15
      periodSeconds: 10
```

```bash
# Crear Pod con readiness
kubectl apply -f - <<EOF
[usar YAML de arriba]
EOF

# Ver estado READY
kubectl get pod readiness-demo
# NAME             READY   STATUS    RESTARTS
# readiness-demo   1/1     Running   0

# Simular fallo de readiness (detener nginx)
kubectl exec readiness-demo -- sh -c "killall nginx"

# Ver estado cambia a NOT READY
kubectl get pod readiness-demo
# NAME             READY   STATUS    RESTARTS
# readiness-demo   0/1     Running   0

# Readiness falla, pero Pod NO se reinicia
# Solo se marca como "Not Ready"
```

**Caso de uso tÃ­pico**: App necesita cargar configuraciÃ³n, conectar a DB, etc.

```yaml
readinessProbe:
  httpGet:
    path: /api/ready  # â† Endpoint que verifica: DB conectada, configs cargadas
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 5
```

---

### 5.4. Startup Probe (Â¿CompletÃ³ el inicio?)

**PropÃ³sito**: Proteger apps con **startup lento** (30s+) de ser matadas prematuramente.

**Comportamiento**:
- âœ… Startup Probe se ejecuta **primero**
- â¸ï¸ Liveness/Readiness se **pausan** hasta que Startup tenga Ã©xito
- â° Permite mÃ¡s tiempo para arranque inicial

ğŸ’¡ **Ejemplo inline - App con startup lento**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: slow-startup
spec:
  containers:
  - name: app
    image: myapp:v1
    ports:
    - containerPort: 8080
    
    # Startup probe: permite hasta 5 min para arrancar
    startupProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      failureThreshold: 30     # 30 intentos Ã— 10s = 5 minutos mÃ¡ximo
    
    # Liveness: una vez started, verificar cada 10s
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      periodSeconds: 10
      failureThreshold: 3      # Solo 30s despuÃ©s de startup
    
    # Readiness: verificar si listo para trÃ¡fico
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
```

**Flujo temporal**:

```
t=0s    â†’ Startup probe inicia (cada 10s, hasta 30 intentos)
        â†’ Liveness/Readiness PAUSADOS

t=120s  â†’ Startup probe OK (app finalmente arrancÃ³)
        â†’ Liveness probe ACTIVO (cada 10s)
        â†’ Readiness probe ACTIVO (cada 5s)

t=130s  â†’ Si liveness falla 3 veces consecutivas â†’ REINICIO
        â†’ Si readiness falla â†’ eliminar de endpoints
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/production-ready/04-startup-probe.yaml`](./ejemplos/production-ready/04-startup-probe.yaml)

---

### 5.5. ConfiguraciÃ³n de Probes

#### **ParÃ¡metros clave**

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  
  initialDelaySeconds: 10    # â° Esperar antes de primera prueba
  periodSeconds: 10          # ğŸ” Frecuencia de pruebas
  timeoutSeconds: 1          # â±ï¸ Timeout por prueba
  successThreshold: 1        # âœ… Ã‰xitos consecutivos para "healthy"
  failureThreshold: 3        # âŒ Fallos consecutivos para "unhealthy"
```

| ParÃ¡metro | Liveness | Readiness | Startup |
|-----------|----------|-----------|---------|
| `initialDelaySeconds` | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ |
| `periodSeconds` | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ |
| `timeoutSeconds` | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ |
| `successThreshold` | âŒ Siempre 1 | âœ… SÃ­ | âŒ Siempre 1 |
| `failureThreshold` | âœ… SÃ­ | âœ… SÃ­ | âœ… SÃ­ |

---

#### **5.5.1. CÃ¡lculo de tiempos**

**Tiempo mÃ¡ximo hasta reinicio (Liveness)**:

```
Tiempo = initialDelaySeconds + (periodSeconds Ã— failureThreshold)

Ejemplo:
initialDelaySeconds: 10
periodSeconds: 5
failureThreshold: 3

Tiempo = 10 + (5 Ã— 3) = 25 segundos
```

**Tiempo mÃ¡ximo de startup (Startup)**:

```
Tiempo = initialDelaySeconds + (periodSeconds Ã— failureThreshold)

Ejemplo:
initialDelaySeconds: 0
periodSeconds: 10
failureThreshold: 30

Tiempo = 0 + (10 Ã— 30) = 300 segundos (5 minutos)
```

---

### 5.6. Best Practices - Health Checks

#### **1. SIEMPRE define readiness probe**

```yaml
# âœ… BIEN
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
```

**RazÃ³n**: Evita trÃ¡fico a Pods no listos durante deploys.

---

#### **2. Liveness probe diferente de readiness**

```yaml
# âŒ MAL - mismo endpoint
livenessProbe:
  httpGet:
    path: /healthz
readinessProbe:
  httpGet:
    path: /healthz  # â† Mismo endpoint

# âœ… BIEN - endpoints diferentes
livenessProbe:
  httpGet:
    path: /healthz/live   # â† Solo verifica si proceso vive
readinessProbe:
  httpGet:
    path: /healthz/ready  # â† Verifica DB, cache, etc.
```

---

#### **3. Liveness: checks simples y rÃ¡pidos**

```yaml
# âŒ MAL - liveness que verifica DB
livenessProbe:
  httpGet:
    path: /api/check-db  # â† Si DB falla, reinicia Pod innecesariamente
  
# âœ… BIEN - liveness simple
livenessProbe:
  httpGet:
    path: /ping  # â† Solo verifica si app responde
```

**RazÃ³n**: Liveness debe verificar si el **proceso estÃ¡ vivo**, no dependencias externas.

---

#### **4. Readiness: checks comprehensivos**

```yaml
# âœ… BIEN - readiness verifica dependencias
readinessProbe:
  httpGet:
    path: /api/ready  # â† Verifica: DB conectada, cache ready, configs cargadas
```

---

#### **5. Usar startup probe para apps lentas**

```yaml
# App que tarda 2 minutos en arrancar

# âŒ MAL - sin startup probe
livenessProbe:
  httpGet:
    path: /healthz
  initialDelaySeconds: 120  # â† Delay muy largo para TODO el lifetime
  periodSeconds: 10

# âœ… BIEN - con startup probe
startupProbe:
  httpGet:
    path: /healthz
  periodSeconds: 10
  failureThreshold: 18  # 3 minutos mÃ¡ximo para startup

livenessProbe:
  httpGet:
    path: /healthz
  periodSeconds: 10  # â† DespuÃ©s de startup, checks cada 10s
```

---

#### **6. Valores recomendados**

```yaml
# Fast-starting apps (< 10s)
livenessProbe:
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 3

readinessProbe:
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 1
  failureThreshold: 3

# Slow-starting apps (> 30s)
startupProbe:
  initialDelaySeconds: 0
  periodSeconds: 10
  failureThreshold: 30  # 5 minutos

livenessProbe:
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  periodSeconds: 5
  failureThreshold: 3
```

---

### 5.7. Debugging Probes

#### **Ver estado de probes**

```bash
# Ver eventos de probes
kubectl describe pod <pod-name> | grep -A 10 "Liveness:"
kubectl describe pod <pod-name> | grep -A 10 "Readiness:"

# Ver eventos recientes
kubectl get events --field-selector involvedObject.name=<pod-name>

# Filtrar solo eventos de probes
kubectl get events --field-selector involvedObject.name=<pod-name> \
  | grep -i "liveness\|readiness\|startup"
```

---

#### **Probe fallando - DiagnÃ³stico**

```bash
# SÃ­ntoma: Pod con RESTARTS incrementando
kubectl get pods
# NAME      READY   STATUS    RESTARTS
# my-pod    1/1     Running   5        â† Liveness probe fallando

# Ver razÃ³n
kubectl describe pod my-pod | grep -A 5 "Liveness:"
# Liveness: http-get http://:8080/healthz delay=0s timeout=1s period=10s
# Warning  Unhealthy  Liveness probe failed: HTTP probe failed with statuscode: 500

# Probar manualmente el endpoint
kubectl port-forward pod/my-pod 8080:8080
curl http://localhost:8080/healthz
# Analizar respuesta
```

---

#### **Readiness probe fallando**

```bash
# SÃ­ntoma: Pod Running pero 0/1 READY
kubectl get pods
# NAME      READY   STATUS    RESTARTS
# my-pod    0/1     Running   0        â† Readiness probe fallando

# Ver endpoints del Service
kubectl get endpoints my-service
# ENDPOINTS: <none>  â† Pod no aparece porque no estÃ¡ "ready"

# Diagnosticar
kubectl describe pod my-pod | grep -A 5 "Readiness:"
# Ver logs
kubectl logs my-pod
```

---

### âœ… Checkpoint SecciÃ³n 5

Antes de continuar, verifica que puedes:
- [ ] Explicar diferencia entre liveness, readiness, y startup probes
- [ ] Configurar los 3 tipos de probes (HTTP, TCP, Exec)
- [ ] Calcular tiempo mÃ¡ximo hasta reinicio con failureThreshold
- [ ] Decidir cuÃ¡ndo usar startup probe vs solo liveness
- [ ] DiseÃ±ar endpoints /healthz/live y /healthz/ready apropiadamente
- [ ] Diagnosticar por quÃ© un Pod reinicia repetidamente
- [ ] Diagnosticar por quÃ© un Pod no recibe trÃ¡fico

---

### ğŸ§ª Laboratorio 05: Health Checks y Probes

**DuraciÃ³n**: 60 minutos

ğŸ“ **Laboratorio propuesto**: `laboratorios/lab-05-health-checks.md` *(pendiente de crear)*

**Objetivos**:
1. Implementar liveness probe y observar reinicios automÃ¡ticos
2. Implementar readiness probe y verificar eliminaciÃ³n de endpoints
3. Usar startup probe para app con arranque lento
4. Simular y resolver fallos de probes
5. Optimizar configuraciÃ³n de probes para diferentes escenarios

---

## ğŸ”’ 6. Security Contexts

> **Objetivo**: Endurecer Pods mediante configuraciones de seguridad para reducir superficie de ataque

### 6.1. Â¿QuÃ© es un Security Context?

**Security Context** = configuraciones de seguridad a nivel de Pod o Container.

**Sin Security Context**:
- ğŸ’¥ Contenedores corren como root (UID 0)
- ğŸ’¥ Acceso completo al filesystem
- ğŸ’¥ Capabilities privilegiadas activadas
- ğŸ’¥ Mayor superficie de ataque

**Con Security Context**:
- âœ… Contenedores corren como usuario no-root
- âœ… Filesystem read-only
- âœ… Capabilities mÃ­nimas necesarias
- âœ… Defensa en profundidad

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         NIVELES DE SECURITY CONTEXT             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Pod-level (spec.securityContext)              â”‚
â”‚  â”œâ”€ Aplica a TODOS los containers              â”‚
â”‚  â”œâ”€ runAsUser, fsGroup, etc.                   â”‚
â”‚  â””â”€ Valores por defecto                        â”‚
â”‚                                                 â”‚
â”‚  Container-level (spec.containers[].securityContext)â”‚
â”‚  â”œâ”€ Sobrescribe valores de Pod-level           â”‚
â”‚  â”œâ”€ MÃ¡s especÃ­fico                             â”‚
â”‚  â””â”€ Prioridad sobre Pod-level                  â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 6.2. runAsUser y runAsGroup

**Problema**: Por defecto, contenedores pueden correr como root (UID 0).

ğŸ’¡ **Ejemplo inline - runAsUser**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000      # â† UID del usuario
    runAsGroup: 3000     # â† GID del grupo
    fsGroup: 2000        # â† GID para volumes
  containers:
  - name: sec-ctx-demo
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
```

```bash
# Crear Pod
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: security-demo
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
  containers:
  - name: demo
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
EOF

# Verificar UID/GID dentro del contenedor
kubectl exec security-demo -- id
# Output:
# uid=1000 gid=3000 groups=3000

# Comparar con Pod sin securityContext (corre como root)
kubectl run insecure --image=busybox --command -- sleep 3600
kubectl exec insecure -- id
# Output:
# uid=0(root) gid=0(root) groups=0(root)
```

**Niveles de aplicaciÃ³n**:

```yaml
# Pod-level (aplica a todos los containers)
apiVersion: v1
kind: Pod
metadata:
  name: pod-level-security
spec:
  securityContext:
    runAsUser: 1000     # â† Todos los containers como UID 1000
  containers:
  - name: container1
    image: nginx:alpine
  - name: container2
    image: busybox
    command: ["sleep", "3600"]

---
# Container-level (sobrescribe Pod-level)
apiVersion: v1
kind: Pod
metadata:
  name: container-level-security
spec:
  securityContext:
    runAsUser: 1000     # â† Default para todos
  containers:
  - name: container1
    image: nginx:alpine
    # Usa UID 1000 (heredado)
  
  - name: container2
    image: busybox
    command: ["sleep", "3600"]
    securityContext:
      runAsUser: 2000   # â† Sobrescribe, usa UID 2000
```

---

### 6.3. runAsNonRoot

**Forzar ejecuciÃ³n como no-root**: prevenir contenedores que arrancan como root.

ğŸ’¡ **Ejemplo inline - runAsNonRoot**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: non-root-pod
spec:
  securityContext:
    runAsNonRoot: true   # â† K8s verifica que no sea root
    runAsUser: 1000
  containers:
  - name: app
    image: nginx:alpine
```

```bash
# Pod que FALLA si intenta correr como root
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: must-run-as-nonroot
spec:
  securityContext:
    runAsNonRoot: true
  containers:
  - name: nginx
    image: nginx:alpine
    # nginx por defecto corre como root â†’ FALLA
EOF

# Ver error
kubectl describe pod must-run-as-nonroot
# Error: container has runAsNonRoot and image will run as root

# SoluciÃ³n: especificar runAsUser
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: runs-as-nonroot
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000     # â† Especificar usuario no-root
  containers:
  - name: nginx
    image: nginx:alpine
EOF
```

---

### 6.4. allowPrivilegeEscalation

**Prevenir escalada de privilegios**: evitar que procesos obtengan mÃ¡s privilegios que su padre.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: no-privilege-escalation
spec:
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false  # â† No permitir sudo, setuid, etc.
```

ğŸ’¡ **Ejemplo comparativo**:

```bash
# Con privilege escalation (INSEGURO)
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: with-escalation
spec:
  containers:
  - name: app
    image: ubuntu
    command: ["sleep", "3600"]
    securityContext:
      allowPrivilegeEscalation: true
EOF

# Sin privilege escalation (SEGURO)
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: no-escalation
spec:
  containers:
  - name: app
    image: ubuntu
    command: ["sleep", "3600"]
    securityContext:
      allowPrivilegeEscalation: false
EOF
```

---

### 6.5. readOnlyRootFilesystem

**Filesystem inmutable**: prevenir escritura en `/` (root filesystem).

ğŸ’¡ **Ejemplo inline - readOnlyRootFilesystem**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: readonly-fs
spec:
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      readOnlyRootFilesystem: true  # â† No se puede escribir en /
    volumeMounts:
    - name: cache-volume
      mountPath: /var/cache/nginx   # â† ExcepciÃ³n: volume writable
    - name: run-volume
      mountPath: /var/run
  volumes:
  - name: cache-volume
    emptyDir: {}
  - name: run-volume
    emptyDir: {}
```

```bash
# Crear Pod con readonly FS
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: readonly-demo
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
    securityContext:
      readOnlyRootFilesystem: true
EOF

# Intentar escribir en / (FALLA)
kubectl exec readonly-demo -- touch /test.txt
# touch: /test.txt: Read-only file system

# Pero se puede escribir en /tmp si montamos volume
kubectl delete pod readonly-demo
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: readonly-with-tmp
spec:
  containers:
  - name: app
    image: busybox
    command: ["sh", "-c", "sleep 3600"]
    securityContext:
      readOnlyRootFilesystem: true
    volumeMounts:
    - name: tmp-volume
      mountPath: /tmp
  volumes:
  - name: tmp-volume
    emptyDir: {}
EOF

# Ahora SÃ funciona
kubectl exec readonly-with-tmp -- touch /tmp/test.txt
kubectl exec readonly-with-tmp -- ls -la /tmp/test.txt
```

---

### 6.6. Linux Capabilities

**Capabilities** = permisos granulares del kernel Linux (en lugar de root completo).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CAPABILITIES COMUNES               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚  CAP_NET_BIND_SERVICE  â†’ Bind a puertos < 1024 â”‚
â”‚  CAP_SYS_TIME          â†’ Cambiar hora del sistema â”‚
â”‚  CAP_CHOWN             â†’ Cambiar ownership de archivos â”‚
â”‚  CAP_SETUID/SETGID     â†’ Cambiar UID/GID  â”‚
â”‚  CAP_NET_RAW           â†’ Usar raw sockets  â”‚
â”‚  CAP_SYS_ADMIN         â†’ Admin del sistema â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ **Ejemplo inline - Drop ALL Capabilities**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: drop-all-caps
spec:
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      capabilities:
        drop:
        - ALL              # â† Eliminar TODAS las capabilities
        add:
        - NET_BIND_SERVICE # â† Agregar solo la necesaria
```

```bash
# Pod con capabilities mÃ­nimas
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: minimal-caps
spec:
  containers:
  - name: web
    image: nginx:alpine
    ports:
    - containerPort: 80
    securityContext:
      capabilities:
        drop:
        - ALL
        add:
        - NET_BIND_SERVICE  # Solo para bind a puerto 80
EOF

# Verificar capabilities
kubectl exec minimal-caps -- cat /proc/1/status | grep Cap
```

ğŸ“„ **Ver ejemplo completo**: [`ejemplos/production-ready/05-security-context.yaml`](./ejemplos/production-ready/05-security-context.yaml)

---

### 6.7. Pod Security Context Completo

ğŸ’¡ **Ejemplo production-ready - Security Context**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hardened-pod
  labels:
    app: secure-app
spec:
  # Pod-level security
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  
  containers:
  - name: app
    image: nginx:alpine
    ports:
    - containerPort: 8080  # Puerto > 1024 (no requiere root)
    
    # Container-level security
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
    
    # Volumes writable necesarios
    volumeMounts:
    - name: cache
      mountPath: /var/cache/nginx
    - name: run
      mountPath: /var/run
    
    # Resources
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "128Mi"
        cpu: "200m"
    
    # Health checks
    livenessProbe:
      httpGet:
        path: /
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
    
    readinessProbe:
      httpGet:
        path: /
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
  
  volumes:
  - name: cache
    emptyDir: {}
  - name: run
    emptyDir: {}
```

---

### 6.8. Best Practices - Security

#### **1. SIEMPRE correr como non-root**

```yaml
# âœ… BIEN
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000

# âŒ MAL - corre como root por defecto
spec:
  containers:
  - name: app
    image: nginx
```

---

#### **2. Drop ALL capabilities**

```yaml
# âœ… BIEN - capabilities mÃ­nimas
securityContext:
  capabilities:
    drop:
    - ALL
    add:
    - NET_BIND_SERVICE  # Solo si necesario

# âŒ MAL - capabilities por defecto (muchas)
securityContext: {}
```

---

#### **3. ReadOnly filesystem cuando sea posible**

```yaml
# âœ… BIEN
securityContext:
  readOnlyRootFilesystem: true
volumeMounts:
- name: tmp
  mountPath: /tmp  # Solo /tmp writable
```

---

#### **4. allowPrivilegeEscalation: false**

```yaml
# âœ… BIEN
securityContext:
  allowPrivilegeEscalation: false

# âŒ MAL - permite escalada
securityContext:
  allowPrivilegeEscalation: true
```

---

#### **5. Seccomp profile**

```yaml
# âœ… BIEN - seccomp profile
spec:
  securityContext:
    seccompProfile:
      type: RuntimeDefault  # Perfil seguro por defecto
```

---

### 6.9. Security Context Template

**Template completo para copiar**:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod-template
spec:
  # Pod-level security
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  
  containers:
  - name: app
    image: your-app:tag
    
    # Container-level security
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
        # add:
        # - NET_BIND_SERVICE  # Si necesitas puerto < 1024
    
    # Volumes necesarios para apps que escriben
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: cache
      mountPath: /var/cache
    
    # Siempre incluir resources
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    
    # Siempre incluir probes
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 10
      periodSeconds: 10
    
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: cache
    emptyDir: {}
```

---

### 6.10. VerificaciÃ³n de Security Context

```bash
# Ver security context aplicado
kubectl get pod <pod-name> -o jsonpath='{.spec.securityContext}' | jq

# Ver security context de container especÃ­fico
kubectl get pod <pod-name> -o jsonpath='{.spec.containers[0].securityContext}' | jq

# Verificar UID/GID dentro del Pod
kubectl exec <pod-name> -- id

# Ver capabilities del proceso
kubectl exec <pod-name> -- cat /proc/1/status | grep Cap

# Ver si filesystem es readonly
kubectl exec <pod-name> -- touch /test.txt
# Si falla: Read-only file system âœ…
```

---

### âœ… Checkpoint SecciÃ³n 6

Antes de continuar, verifica que puedes:
- [ ] Explicar quÃ© es un Security Context
- [ ] Configurar runAsUser y runAsNonRoot
- [ ] Implementar readOnlyRootFilesystem con volumes necesarios
- [ ] Drop ALL capabilities y agregar solo las necesarias
- [ ] Entender allowPrivilegeEscalation
- [ ] Diferenciar Pod-level vs Container-level security
- [ ] Usar el template de security completo

---

### ğŸ§ª Laboratorio 06: Security Contexts

**DuraciÃ³n**: 50 minutos

ğŸ“ **Laboratorio propuesto**: `laboratorios/lab-06-security-contexts.md` *(pendiente de crear)*

**Objetivos**:
1. Crear Pod inseguro vs Pod hardened
2. Implementar readOnlyRootFilesystem con volumes
3. Configurar capabilities mÃ­nimas
4. Verificar security contexts aplicados
5. Aplicar template de security a aplicaciÃ³n real

---


## ğŸ› 7. Debugging Avanzado

> **Objetivo**: Dominar troubleshooting de Pods

### 7.1. kubectl debug

```bash
kubectl debug my-pod -it --image=busybox --target=app
```

### 7.2. Checklist

**Pending**: `kubectl describe pod <name>`  
**CrashLoopBackOff**: `kubectl logs <name> --previous`  
**No responde**: `kubectl port-forward pod/<name> 8080:8080`

---

## âœ… 8. Best Practices

| âŒ Evitar | âœ… Hacer |
|-----------|----------|
| `:latest` | Tags especÃ­ficos |
| Sin resources | Requests + Limits |
| Sin probes | Liveness + Readiness |

---

## ğŸ“š 9. Resumen

**Has dominado**: Manifiestos, Ciclo de vida, Labels, Resources, Health Checks, Security, Debugging

**Clave**: Usa **Deployments** en producciÃ³n, no Pods directos

---

**â¬…ï¸ Anterior**: [MÃ³dulo 04](../modulo-04-pods-vs-contenedores/README.md)  
**â¡ï¸ Siguiente**: [MÃ³dulo 06](../modulo-06-replicasets-replicas/README.md)
