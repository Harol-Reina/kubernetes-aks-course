# Ejemplos - MÃ³dulo 22: Cluster Setup con Kubeadm

> **Enfoque**: Archivos de configuraciÃ³n para instalaciÃ³n y setup de clusters  
> **Total**: 4 configuraciones de producciÃ³n

## ğŸ“ Estructura

```
ejemplos/
â”œâ”€â”€ README.md                   # Este archivo
â”œâ”€â”€ 01-calico-custom/          # Calico CNI personalizado
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ calico-custom.yaml
â”‚   â””â”€â”€ cleanup.sh
â”œâ”€â”€ 02-containerd-config/      # ConfiguraciÃ³n de containerd
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ containerd-config.toml
â”‚   â””â”€â”€ cleanup.sh
â”œâ”€â”€ 03-kubeadm-config/         # Kubeadm init config
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ kubeadm-config.yaml
â”‚   â””â”€â”€ cleanup.sh
â””â”€â”€ 04-kubeadm-ha-config/      # Kubeadm HA config
    â”œâ”€â”€ README.md
    â”œâ”€â”€ kubeadm-ha-config.yaml
    â””â”€â”€ cleanup.sh
```

## ğŸ“‹ Configuraciones Disponibles

### [01: Calico Custom](./01-calico-custom/)
ConfiguraciÃ³n personalizada de Calico CNI

**CaracterÃ­sticas:**
- âœ… Control plane de un solo nodo
- âœ… ConfiguraciÃ³n de API server con audit logging
- âœ… ConfiguraciÃ³n de kubelet con systemd cgroup driver
- âœ… ConfiguraciÃ³n de kube-proxy con IPVS mode
- âœ… ParÃ¡metros de etcd optimizados
- âœ… Configuraciones de red (Pod CIDR, Service CIDR)

**Uso:**
```bash
# Inicializar control plane con configuraciÃ³n personalizada
sudo kubeadm init --config kubeadm-config.yaml

# Verificar configuraciÃ³n aplicada
kubectl cluster-info
kubectl get nodes -o wide
```

**Personalizar:**
- `localAPIEndpoint.advertiseAddress`: IP del control plane
- `controlPlaneEndpoint`: Hostname/IP del endpoint
- `networking.podSubnet`: CIDR de pods (debe coincidir con CNI)
- `apiServer.certSANs`: SANs adicionales para certificado API server

---

### 2. **kubeadm-ha-config.yaml**
ConfiguraciÃ³n para cluster High Availability con 3+ control plane nodes.

**CaracterÃ­sticas:**
- âœ… 3 control plane nodes (recomendado: impar)
- âœ… Load balancer endpoint para HA
- âœ… Leader election para controller-manager y scheduler
- âœ… Etcd en topologÃ­a stacked (co-located)
- âœ… Certificate SANs para todos los control planes
- âœ… Configuraciones de failover

**Arquitectura:**
```
                Load Balancer (HAProxy/nginx)
                     192.168.1.100:6443
                            |
         +------------------+------------------+
         |                  |                  |
   Control Plane 1    Control Plane 2    Control Plane 3
   192.168.1.10       192.168.1.11       192.168.1.12
   (API + etcd)       (API + etcd)       (API + etcd)
         |                  |                  |
         +------------------+------------------+
                            |
                    Worker Nodes Pool
```

**Uso:**
```bash
# En el PRIMER control plane
sudo kubeadm init --config kubeadm-ha-config.yaml --upload-certs

# Guardar el output:
# - certificate-key para control planes adicionales
# - token para workers

# En control planes ADICIONALES
sudo kubeadm join k8s-lb.example.com:6443 \
  --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash> \
  --control-plane \
  --certificate-key <certificate-key>

# En workers
sudo kubeadm join k8s-lb.example.com:6443 \
  --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash>
```

**Load Balancer:**
Configurar HAProxy o nginx para balancear trÃ¡fico API server (puerto 6443).

Ejemplo HAProxy:
```
frontend kubernetes-frontend
    bind *:6443
    mode tcp
    default_backend kubernetes-backend

backend kubernetes-backend
    mode tcp
    balance roundrobin
    server master-01 192.168.1.10:6443 check
    server master-02 192.168.1.11:6443 check
    server master-03 192.168.1.12:6443 check
```

---

### 3. **containerd-config.toml**
ConfiguraciÃ³n optimizada del container runtime containerd.

**CaracterÃ­sticas:**
- âœ… SystemdCgroup = true (CRÃTICO para Kubernetes)
- âœ… Sandbox image sincronizada con Kubernetes
- âœ… CNI plugin configuration
- âœ… Registry mirrors para private registries
- âœ… GRPC settings optimizados
- âœ… Garbage collection configurado

**InstalaciÃ³n:**
```bash
# Generar configuraciÃ³n por defecto
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# O usar configuraciÃ³n personalizada
sudo cp containerd-config.toml /etc/containerd/config.toml

# Reiniciar containerd
sudo systemctl restart containerd
sudo systemctl status containerd

# Verificar configuraciÃ³n
sudo crictl info
sudo crictl images
```

**Puntos crÃ­ticos:**
- **SystemdCgroup = true**: Debe coincidir con kubelet cgroupDriver
- **sandbox_image**: Debe coincidir con versiÃ³n de Kubernetes
- **Registry mirrors**: Configurar para private registries (Harbor, Nexus)

---

### 4. **calico-custom.yaml**
ConfiguraciÃ³n personalizada del CNI plugin Calico.

**CaracterÃ­sticas:**
- âœ… IPIP mode: CrossSubnet (mejor performance)
- âœ… MTU optimizado para redes overlay
- âœ… Prometheus metrics habilitados
- âœ… IP autodetection configurado
- âœ… BlockSize personalizado (/26 = 64 IPs por nodo)
- âœ… GlobalNetworkPolicy ejemplo

**InstalaciÃ³n:**
```bash
# Aplicar configuraciÃ³n personalizada
kubectl apply -f calico-custom.yaml

# Verificar instalaciÃ³n
kubectl get pods -n kube-system | grep calico
kubectl get daemonset -n kube-system calico-node

# Ver IP pools configurados (requiere calicoctl)
calicoctl get ippool -o wide

# Ver estado de nodos Calico
calicoctl node status
```

**Troubleshooting:**
```bash
# Logs de Calico node
kubectl logs -n kube-system -l k8s-app=calico-node

# Ver configuraciÃ³n aplicada
kubectl get configmap -n kube-system calico-config -o yaml

# Verificar conectividad de red
kubectl run test-pod --image=busybox --restart=Never -- sleep 3600
kubectl exec test-pod -- ping <pod-ip>
```

**Alternativas CNI:**
- **Flannel**: Simple, VXLAN overlay (menor performance)
- **Weave**: Mesh networking, encriptaciÃ³n built-in
- **Cilium**: eBPF-based, alto performance, observabilidad avanzada

---

## ğŸš€ Flujo de InstalaciÃ³n Completa

### OpciÃ³n A: Cluster Single Master

```bash
# 1. Instalar prerequisites (todos los nodos)
sudo ./scripts/install-prerequisites.sh

# 2. Inicializar control plane (solo master)
sudo kubeadm init --config ejemplos/kubeadm-config.yaml

# 3. Configurar kubeconfig
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 4. Instalar CNI (Calico)
kubectl apply -f ejemplos/calico-custom.yaml

# 5. Verificar control plane
kubectl get nodes
kubectl get pods -n kube-system

# 6. Obtener join command para workers
kubeadm token create --print-join-command

# 7. En workers: ejecutar join command
sudo kubeadm join <control-plane-ip>:6443 --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash>
```

### OpciÃ³n B: Cluster High Availability

```bash
# 1. Configurar load balancer (HAProxy/nginx) en servidor separado
# Ver ejemplo de configuraciÃ³n en kubeadm-ha-config.yaml

# 2. Instalar prerequisites (todos los control planes y workers)
sudo ./scripts/install-prerequisites.sh

# 3. Inicializar PRIMER control plane
sudo kubeadm init --config ejemplos/kubeadm-ha-config.yaml --upload-certs

# 4. Guardar outputs:
#    - certificate-key (para control planes adicionales)
#    - join command para control planes
#    - join command para workers

# 5. Configurar kubeconfig en primer master
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 6. Instalar CNI (Calico)
kubectl apply -f ejemplos/calico-custom.yaml

# 7. Agregar control planes ADICIONALES (master-02, master-03)
sudo kubeadm join k8s-lb.example.com:6443 \
  --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash> \
  --control-plane \
  --certificate-key <certificate-key>

# 8. Agregar workers
sudo kubeadm join k8s-lb.example.com:6443 \
  --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash>

# 9. Verificar HA cluster
kubectl get nodes -o wide
kubectl get pods -n kube-system -o wide
kubectl get endpoints -n kube-system  # Ver etcd endpoints
```

---

## ğŸ”§ PersonalizaciÃ³n

### Cambiar Pod Network CIDR

1. Modificar en `kubeadm-config.yaml`:
```yaml
networking:
  podSubnet: 10.244.0.0/16  # Cambiar segÃºn necesidad
```

2. Actualizar en `calico-custom.yaml`:
```yaml
data:
  calico_ipv4pool_cidr: "10.244.0.0/16"  # Debe coincidir
```

### Configurar Private Registry

1. Modificar en `containerd-config.toml`:
```toml
[plugins."io.containerd.grpc.v1.cri".registry.mirrors."private-registry.example.com"]
  endpoint = ["https://private-registry.example.com"]
```

2. Agregar credentials (si requiere autenticaciÃ³n):
```bash
crictl pull private-registry.example.com/image:tag \
  --creds username:password
```

---

## ğŸ“š Referencias

- [kubeadm Configuration (v1beta3)](https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/)
- [Calico Documentation](https://docs.projectcalico.org/)
- [containerd Configuration](https://github.com/containerd/containerd/blob/main/docs/ops.md)
- [Creating Highly Available Clusters](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)

---

## âš ï¸ Notas Importantes

1. **CIDR de Red**: Asegurar que `podSubnet` no colisione con redes existentes
2. **SystemdCgroup**: Debe estar en `true` en containerd para systemd
3. **Certificate SANs**: Incluir todas las IPs/hostnames del API server
4. **Token Expiration**: Tokens por defecto expiran en 24h, regenerar si es necesario
5. **etcd Backup**: Configurar backups automÃ¡ticos antes de producciÃ³n
6. **Load Balancer**: Para HA, el LB es un SPOF - considerar redundancia

---

**Ver tambiÃ©n:**
- [Laboratorios](../laboratorios/README.md) - Labs prÃ¡cticos paso a paso
- [Scripts](../scripts/) - Scripts de automatizaciÃ³n
- [README principal](../README.md) - DocumentaciÃ³n completa del mÃ³dulo
