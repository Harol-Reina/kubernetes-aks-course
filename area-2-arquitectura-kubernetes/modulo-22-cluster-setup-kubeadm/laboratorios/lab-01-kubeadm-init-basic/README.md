# Lab 01: Cluster BÃ¡sico con kubeadm init

## ğŸ“‹ InformaciÃ³n del Laboratorio

- **Nombre**: Cluster BÃ¡sico con kubeadm init
- **MÃ³dulo**: 22 - Cluster Setup with kubeadm
- **Ãrea**: 2 - Arquitectura Kubernetes
- **DuraciÃ³n**: 2-3 horas
- **Dificultad**: â­â­â­ Avanzado
- **CKA relevance**: â­â­â­â­â­ (25% del examen - Cluster Architecture, Installation & Configuration)

## ğŸ¯ Objetivos de Aprendizaje

Al completar este laboratorio, serÃ¡s capaz de:

1. **Instalar y configurar** todos los prerequisitos para un cluster de Kubernetes
2. **Inicializar** un cluster con `kubeadm init` usando configuraciÃ³n personalizada
3. **Configurar** networking del cluster con CNI plugin (Calico)
4. **Verificar** la salud del cluster y componentes del control plane
5. **Configurar** kubectl para administraciÃ³n del cluster
6. **Entender** la arquitectura de un cluster single-node bÃ¡sico

## ğŸ“ Arquitectura del Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTROL PLANE NODE                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Control Plane Components                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚   etcd   â”‚  â”‚ API      â”‚  â”‚ Schedulerâ”‚            â”‚  â”‚
â”‚  â”‚  â”‚  :2379   â”‚  â”‚ Server   â”‚  â”‚          â”‚            â”‚  â”‚
â”‚  â”‚  â”‚          â”‚  â”‚ :6443    â”‚  â”‚          â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚  â”‚
â”‚  â”‚  â”‚ Controllerâ”‚  â”‚ Cloud    â”‚                          â”‚  â”‚
â”‚  â”‚  â”‚ Manager  â”‚  â”‚ Controllerâ”‚                          â”‚  â”‚
â”‚  â”‚  â”‚          â”‚  â”‚ (optional)â”‚                          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                Node Components                         â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚ kubelet  â”‚  â”‚ kube-    â”‚  â”‚Container â”‚            â”‚  â”‚
â”‚  â”‚  â”‚          â”‚  â”‚ proxy    â”‚  â”‚ Runtime  â”‚            â”‚  â”‚
â”‚  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚(containerd)â”‚           â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  CNI Network Plugin                    â”‚  â”‚
â”‚  â”‚                   Calico (v3.26+)                      â”‚  â”‚
â”‚  â”‚              Pod CIDR: 192.168.0.0/16                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”‘ Conceptos Clave

### kubeadm init Workflow

```
1. Pre-flight checks
   â”œâ”€â”€ System validation
   â”œâ”€â”€ Port availability (6443, 2379-2380, 10250-10252)
   â”œâ”€â”€ Container runtime (containerd)
   â””â”€â”€ Required tools (kubectl, kubelet)

2. Certificate generation
   â”œâ”€â”€ CA certificates
   â”œâ”€â”€ API server certificates
   â”œâ”€â”€ etcd certificates
   â””â”€â”€ Service account key pair

3. Control plane static pods
   â”œâ”€â”€ kube-apiserver
   â”œâ”€â”€ kube-controller-manager
   â”œâ”€â”€ kube-scheduler
   â””â”€â”€ etcd

4. kubeconfig generation
   â”œâ”€â”€ admin.conf
   â”œâ”€â”€ kubelet.conf
   â”œâ”€â”€ controller-manager.conf
   â””â”€â”€ scheduler.conf

5. Bootstrap tokens
   â””â”€â”€ For worker node join

6. Addons (optional)
   â”œâ”€â”€ CoreDNS
   â””â”€â”€ kube-proxy
```

### Componentes Instalados

| Componente | VersiÃ³n | DescripciÃ³n | Puerto |
|------------|---------|-------------|--------|
| **kubelet** | 1.28+ | Node agent | 10250 |
| **kubeadm** | 1.28+ | Cluster bootstrap tool | - |
| **kubectl** | 1.28+ | CLI tool | - |
| **containerd** | 1.7+ | Container runtime | - |
| **etcd** | 3.5+ | Key-value store | 2379-2380 |
| **API Server** | 1.28+ | REST API frontend | 6443 |
| **Calico** | 3.26+ | CNI network plugin | - |

### Directorios CrÃ­ticos

```bash
/etc/kubernetes/
â”œâ”€â”€ manifests/              # Static pod manifests
â”‚   â”œâ”€â”€ kube-apiserver.yaml
â”‚   â”œâ”€â”€ kube-controller-manager.yaml
â”‚   â”œâ”€â”€ kube-scheduler.yaml
â”‚   â””â”€â”€ etcd.yaml
â”œâ”€â”€ admin.conf              # Admin kubeconfig
â”œâ”€â”€ kubelet.conf            # Kubelet kubeconfig
â”œâ”€â”€ controller-manager.conf # Controller manager kubeconfig
â”œâ”€â”€ scheduler.conf          # Scheduler kubeconfig
â””â”€â”€ pki/                    # Certificates
    â”œâ”€â”€ ca.crt
    â”œâ”€â”€ ca.key
    â”œâ”€â”€ apiserver.crt
    â”œâ”€â”€ apiserver.key
    â”œâ”€â”€ apiserver-kubelet-client.crt
    â”œâ”€â”€ apiserver-kubelet-client.key
    â”œâ”€â”€ front-proxy-ca.crt
    â”œâ”€â”€ front-proxy-ca.key
    â”œâ”€â”€ front-proxy-client.crt
    â”œâ”€â”€ front-proxy-client.key
    â”œâ”€â”€ sa.key
    â”œâ”€â”€ sa.pub
    â””â”€â”€ etcd/
        â”œâ”€â”€ ca.crt
        â”œâ”€â”€ ca.key
        â”œâ”€â”€ server.crt
        â””â”€â”€ server.key

/var/lib/kubelet/           # Kubelet data
/var/lib/etcd/              # etcd data
```

## ğŸ“‹ Prerequisitos

Ver [SETUP.md](./SETUP.md) para:
- Sistema operativo soportado (Ubuntu 20.04/22.04, RHEL 8/9)
- Recursos mÃ­nimos (2 CPU, 2GB RAM, 20GB disk)
- Acceso root/sudo
- Network requirements (puertos, firewall)
- Container runtime instalado

## ğŸ”¬ Procedimiento del Laboratorio

### Parte 1: PreparaciÃ³n del Sistema (30 min)

#### 1.1 Deshabilitar swap

```bash
# Deshabilitar swap temporalmente
sudo swapoff -a

# Deshabilitar swap permanentemente
sudo sed -i '/ swap / s/^/#/' /etc/fstab

# Verificar
free -h
# Debe mostrar swap: 0B total
```

**Â¿Por quÃ©?** Kubernetes requiere swap deshabilitado para garantizar rendimiento predecible de pods.

#### 1.2 Configurar mÃ³dulos kernel y sysctl

```bash
# Cargar mÃ³dulos necesarios
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# Configurar parÃ¡metros sysctl
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Aplicar configuraciÃ³n
sudo sysctl --system

# Verificar
lsmod | grep br_netfilter
lsmod | grep overlay
sysctl net.bridge.bridge-nf-call-iptables net.ipv4.ip_forward
```

#### 1.3 Instalar containerd

```bash
# Instalar dependencias
sudo apt-get update
sudo apt-get install -y ca-certificates curl gnupg lsb-release

# Agregar Docker GPG key
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

# Agregar repositorio
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
  https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list

# Instalar containerd
sudo apt-get update
sudo apt-get install -y containerd.io

# Generar configuraciÃ³n por defecto
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

# Configurar systemd cgroup driver
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' \
  /etc/containerd/config.toml

# Reiniciar containerd
sudo systemctl restart containerd
sudo systemctl enable containerd

# Verificar
sudo systemctl status containerd
```

#### 1.4 Instalar kubeadm, kubelet, kubectl

```bash
# Agregar Kubernetes GPG key
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | \
  sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Agregar repositorio Kubernetes
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] \
  https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | \
  sudo tee /etc/apt/sources.list.d/kubernetes.list

# Instalar paquetes
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl

# Bloquear versiones
sudo apt-mark hold kubelet kubeadm kubectl

# Verificar versiones
kubeadm version
kubelet --version
kubectl version --client
```

### Parte 2: InicializaciÃ³n del Cluster (20 min)

#### 2.1 Crear configuraciÃ³n kubeadm

```bash
# Crear kubeadm-config.yaml
cat <<EOF > ~/kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: $(hostname -I | awk '{print $1}')
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  imagePullPolicy: IfNotPresent
  name: $(hostname)
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: v1.28.0
controlPlaneEndpoint: "$(hostname -I | awk '{print $1}'):6443"
networking:
  podSubnet: "192.168.0.0/16"
  serviceSubnet: "10.96.0.0/12"
apiServer:
  timeoutForControlPlane: 4m0s
  extraArgs:
    authorization-mode: "Node,RBAC"
controllerManager:
  extraArgs:
    bind-address: "0.0.0.0"
scheduler:
  extraArgs:
    bind-address: "0.0.0.0"
etcd:
  local:
    dataDir: /var/lib/etcd
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: systemd
EOF

# Revisar configuraciÃ³n
cat ~/kubeadm-config.yaml
```

**ParÃ¡metros Clave:**
- `advertiseAddress`: IP del control plane (IP principal del nodo)
- `podSubnet`: CIDR para pods (192.168.0.0/16 para Calico)
- `serviceSubnet`: CIDR para services
- `cgroupDriver`: systemd (debe coincidir con containerd)

#### 2.2 Ejecutar kubeadm init

```bash
# Ejecutar pre-flight checks primero
sudo kubeadm init phase preflight --config ~/kubeadm-config.yaml

# Inicializar cluster
sudo kubeadm init --config ~/kubeadm-config.yaml --upload-certs

# OUTPUT ESPERADO:
# [init] Using Kubernetes version: v1.28.0
# [preflight] Running pre-flight checks
# [certs] Generating "ca" certificate and key
# [certs] Generating "apiserver" certificate and key
# ...
# [kubelet-start] Starting the kubelet
# [control-plane] Using manifest folder "/etc/kubernetes/manifests"
# [control-plane] Creating static Pod manifest for "kube-apiserver"
# [control-plane] Creating static Pod manifest for "kube-controller-manager"
# [control-plane] Creating static Pod manifest for "kube-scheduler"
# [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
# [wait-control-plane] Waiting for the kubelet to boot up the control plane
# [apiclient] All control plane components are healthy
# [upload-config] Storing the configuration used in ConfigMap "kubeadm-config"
# [mark-control-plane] Marking the node as control-plane
# [bootstrap-token] Configuring bootstrap tokens
# 
# Your Kubernetes control-plane has initialized successfully!
```

**âš ï¸ IMPORTANTE**: Guarda el output, especialmente:
1. **kubeadm join command** (para agregar workers)
2. **Certificate key** (para agregar control planes en HA)

#### 2.3 Configurar kubectl para usuario regular

```bash
# Crear directorio .kube
mkdir -p $HOME/.kube

# Copiar admin.conf
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

# Cambiar ownership
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Verificar
kubectl cluster-info

# OUTPUT:
# Kubernetes control plane is running at https://192.168.1.100:6443
# CoreDNS is running at https://192.168.1.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

### Parte 3: Instalar CNI Network Plugin (15 min)

#### 3.1 Instalar Calico

```bash
# Descargar Calico manifest
curl https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml \
  -O

# Aplicar Calico
kubectl apply -f calico.yaml

# Verificar despliegue de Calico
kubectl get pods -n kube-system -l k8s-app=calico-node -w

# Esperar hasta que todos los pods estÃ©n Running
# CTRL+C para salir del watch

# Verificar calico-kube-controllers
kubectl get deployment -n kube-system calico-kube-controllers
```

#### 3.2 Verificar networking

```bash
# Verificar que el nodo estÃ© Ready
kubectl get nodes

# NAME            STATUS   ROLES           AGE   VERSION
# control-plane   Ready    control-plane   5m    v1.28.0

# Verificar que todos los pods system estÃ©n Running
kubectl get pods -n kube-system

# Verificar componentes del control plane
kubectl get pods -n kube-system -o wide | grep -E 'kube-apiserver|kube-scheduler|kube-controller|etcd'
```

### Parte 4: VerificaciÃ³n del Cluster (30 min)

#### 4.1 Verificar componentes del control plane

```bash
# Verificar API server
kubectl get --raw /healthz
# ok

kubectl get --raw /readyz
# ok

# Verificar etcd
sudo ETCDCTL_API=3 etcdctl \
  --endpoints=127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint health

# 127.0.0.1:2379 is healthy: successfully committed proposal

# Verificar componentes como services
kubectl get componentstatuses
# (deprecated en 1.19+, usar endpoints)

kubectl get endpoints -n kube-system
```

#### 4.2 Verificar certificados

```bash
# Listar certificados
sudo kubeadm certs check-expiration

# CERTIFICATE                EXPIRES                  RESIDUAL TIME   ...
# admin.conf                 Nov 14, 2026 00:00 UTC   364d           ...
# apiserver                  Nov 14, 2026 00:00 UTC   364d           ...
# apiserver-kubelet-client   Nov 14, 2026 00:00 UTC   364d           ...
# ...

# Verificar CA certificate
openssl x509 -in /etc/kubernetes/pki/ca.crt -text -noout | grep -A 2 Validity

# Verificar API server certificate
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | \
  grep -E 'Subject:|DNS:|IP Address:'
```

#### 4.3 Verificar logs de componentes

```bash
# Logs de kubelet
sudo journalctl -u kubelet -n 50 --no-pager

# Logs de API server
kubectl logs -n kube-system kube-apiserver-$(hostname) | tail -20

# Logs de scheduler
kubectl logs -n kube-system kube-scheduler-$(hostname) | tail -20

# Logs de controller-manager
kubectl logs -n kube-system kube-controller-manager-$(hostname) | tail -20

# Logs de etcd
kubectl logs -n kube-system etcd-$(hostname) | tail -20
```

#### 4.4 Probar funcionalidad bÃ¡sica

```bash
# Crear namespace de prueba
kubectl create namespace test-cluster

# Crear deployment de prueba
kubectl create deployment nginx --image=nginx:latest -n test-cluster

# Verificar pod
kubectl get pods -n test-cluster -w

# Exponer deployment
kubectl expose deployment nginx --port=80 --type=NodePort -n test-cluster

# Obtener NodePort
kubectl get svc -n test-cluster

# Probar conectividad
NODE_PORT=$(kubectl get svc nginx -n test-cluster -o jsonpath='{.spec.ports[0].nodePort}')
curl http://localhost:$NODE_PORT

# Escalar deployment
kubectl scale deployment nginx --replicas=3 -n test-cluster

# Verificar pods distribuidos
kubectl get pods -n test-cluster -o wide

# Verificar logs
kubectl logs -n test-cluster deployment/nginx --tail=10

# Limpiar
kubectl delete namespace test-cluster
```

### Parte 5: ConfiguraciÃ³n Post-InstalaciÃ³n (20 min)

#### 5.1 Habilitar autocompletion de kubectl

```bash
# Para bash
echo 'source <(kubectl completion bash)' >>~/.bashrc
echo 'alias k=kubectl' >>~/.bashrc
echo 'complete -o default -F __start_kubectl k' >>~/.bashrc

# Para zsh
echo 'source <(kubectl completion zsh)' >>~/.zshrc
echo 'alias k=kubectl' >>~/.zshrc

# Aplicar cambios
source ~/.bashrc  # o source ~/.zshrc
```

#### 5.2 Configurar bash prompt con contexto

```bash
# Instalar kube-ps1
git clone https://github.com/jonmosco/kube-ps1.git ~/.kube-ps1

# Agregar a .bashrc
cat <<'EOF' >> ~/.bashrc
source ~/.kube-ps1/kube-ps1.sh
PS1='[\u@\h \W $(kube_ps1)]\$ '
EOF

# Aplicar
source ~/.bashrc
```

#### 5.3 Instalar herramientas Ãºtiles

```bash
# kubectx/kubens (cambiar contextos/namespaces)
sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens

# k9s (TUI para Kubernetes)
wget https://github.com/derailed/k9s/releases/latest/download/k9s_Linux_amd64.tar.gz
tar -xzf k9s_Linux_amd64.tar.gz
sudo mv k9s /usr/local/bin/
rm k9s_Linux_amd64.tar.gz

# Verificar instalaciÃ³n
kubectx
kubens
k9s version
```

#### 5.4 Backup de certificados y kubeconfig

```bash
# Crear directorio de backups
mkdir -p ~/k8s-backups/$(date +%Y%m%d)

# Backup de PKI
sudo tar -czf ~/k8s-backups/$(date +%Y%m%d)/pki-backup.tar.gz \
  /etc/kubernetes/pki

# Backup de kubeconfig
sudo cp /etc/kubernetes/admin.conf \
  ~/k8s-backups/$(date +%Y%m%d)/admin.conf.backup

# Backup de manifests
sudo tar -czf ~/k8s-backups/$(date +%Y%m%d)/manifests-backup.tar.gz \
  /etc/kubernetes/manifests

# Verificar backups
ls -lh ~/k8s-backups/$(date +%Y%m%d)/
```

## ğŸ” Troubleshooting

### Problema 1: kubeadm init falla en preflight checks

**SÃ­ntoma:**
```
[ERROR Port-6443]: Port 6443 is in use
[ERROR Port-10259]: Port 10259 is in use
```

**SoluciÃ³n:**
```bash
# Verificar quÃ© proceso usa el puerto
sudo netstat -tulpn | grep 6443

# Si hay un cluster anterior, hacer reset
sudo kubeadm reset -f
sudo rm -rf /etc/kubernetes
sudo rm -rf /var/lib/kubelet
sudo rm -rf /var/lib/etcd

# Reiniciar servicios
sudo systemctl restart containerd
sudo systemctl restart kubelet

# Reintentar kubeadm init
```

### Problema 2: Nodo permanece NotReady

**SÃ­ntoma:**
```bash
kubectl get nodes
# NAME     STATUS      ROLES           AGE   VERSION
# node1    NotReady    control-plane   5m    v1.28.0
```

**SoluciÃ³n:**
```bash
# Verificar CNI plugin instalado
kubectl get pods -n kube-system | grep calico

# Si no hay pods de Calico, reinstalar
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml

# Verificar logs de kubelet
sudo journalctl -u kubelet -f

# Verificar logs de containerd
sudo journalctl -u containerd -f

# Reiniciar kubelet si es necesario
sudo systemctl restart kubelet
```

### Problema 3: Pods en CrashLoopBackOff

**SÃ­ntoma:**
```bash
kubectl get pods -n kube-system
# NAME                        READY   STATUS             RESTARTS
# kube-apiserver-node1        0/1     CrashLoopBackOff   5
```

**SoluciÃ³n:**
```bash
# Ver logs del pod
kubectl logs -n kube-system kube-apiserver-$(hostname) --previous

# Verificar manifest del static pod
sudo cat /etc/kubernetes/manifests/kube-apiserver.yaml

# Verificar permisos de certificados
sudo ls -la /etc/kubernetes/pki/

# Regenerar certificados si es necesario
sudo kubeadm init phase certs apiserver --config ~/kubeadm-config.yaml

# Esperar que kubelet reinicie el pod
kubectl get pods -n kube-system -w
```

### Problema 4: CoreDNS en Pending

**SÃ­ntoma:**
```bash
kubectl get pods -n kube-system
# NAME                      READY   STATUS    RESTARTS   AGE
# coredns-787d4945fb-xxx    0/1     Pending   0          5m
```

**SoluciÃ³n:**
```bash
# Verificar CNI plugin
kubectl get pods -n kube-system -l k8s-app=calico-node

# Ver detalles del pod CoreDNS
kubectl describe pod -n kube-system -l k8s-app=kube-dns

# Verificar eventos
kubectl get events -n kube-system --sort-by='.lastTimestamp'

# Si el nodo tiene taint control-plane, CoreDNS no podrÃ¡ schedulear
# Remover taint si es cluster single-node
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

### Problema 5: Error de conexiÃ³n a API server

**SÃ­ntoma:**
```bash
kubectl get nodes
# The connection to the server 192.168.1.100:6443 was refused
```

**SoluciÃ³n:**
```bash
# Verificar que API server estÃ© corriendo
sudo crictl ps | grep kube-apiserver

# Verificar puerto 6443
sudo netstat -tulpn | grep 6443

# Verificar manifest
sudo cat /etc/kubernetes/manifests/kube-apiserver.yaml

# Verificar logs de kubelet
sudo journalctl -u kubelet -n 100 --no-pager | grep apiserver

# Verificar conectividad
curl -k https://$(hostname -I | awk '{print $1}'):6443/healthz

# Si es problema de certificados, regenerar
sudo kubeadm init phase certs all --config ~/kubeadm-config.yaml
```

## ğŸ“š Comandos Ãštiles para CKA

### InformaciÃ³n del Cluster

```bash
# VersiÃ³n del cluster
kubectl version

# Info del cluster
kubectl cluster-info
kubectl cluster-info dump

# Componentes del cluster
kubectl get componentstatuses  # deprecated
kubectl get --raw /healthz
kubectl get --raw /livez
kubectl get --raw /readyz

# ConfiguraciÃ³n de kubeadm
kubectl get cm -n kube-system kubeadm-config -o yaml
```

### GestiÃ³n de Nodos

```bash
# Listar nodos con detalles
kubectl get nodes -o wide

# Describir nodo
kubectl describe node <node-name>

# Ver labels del nodo
kubectl get nodes --show-labels

# Ver capacity y allocatable
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
CPU-CAP:.status.capacity.cpu,\
CPU-ALLOC:.status.allocatable.cpu,\
MEM-CAP:.status.capacity.memory,\
MEM-ALLOC:.status.allocatable.memory
```

### GestiÃ³n de Pods

```bash
# Pods por nodo
kubectl get pods -A -o wide --field-selector spec.nodeName=<node-name>

# Pods en namespace kube-system
kubectl get pods -n kube-system -o wide

# Static pods (control plane)
kubectl get pods -n kube-system -o wide | grep $(hostname)

# Logs de pods del sistema
kubectl logs -n kube-system <pod-name>
```

### Certificados

```bash
# Verificar expiraciÃ³n
sudo kubeadm certs check-expiration

# Renovar todos los certificados
sudo kubeadm certs renew all

# Renovar certificado especÃ­fico
sudo kubeadm certs renew apiserver

# Ver detalles del certificado
openssl x509 -in /etc/kubernetes/pki/ca.crt -text -noout
```

## ğŸ“ PreparaciÃ³n para el Examen CKA

### Escenario TÃ­pico del Examen

**Tarea**: "Inicializa un nuevo cluster de Kubernetes usando kubeadm. Configura el pod network CIDR como 10.244.0.0/16 y el service CIDR como 10.96.0.0/12. Instala Calico como CNI plugin."

**SoluciÃ³n en 5 minutos:**

```bash
# 1. Crear kubeadm config (1 min)
cat <<EOF > /tmp/kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
networking:
  podSubnet: "10.244.0.0/16"
  serviceSubnet: "10.96.0.0/12"
EOF

# 2. Inicializar cluster (2 min)
sudo kubeadm init --config /tmp/kubeadm-config.yaml

# 3. Configurar kubectl (30 seg)
mkdir -p $HOME/.kube
sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 4. Instalar Calico (1 min)
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml

# 5. Verificar (30 seg)
kubectl get nodes
kubectl get pods -n kube-system
```

### Comandos CrÃ­ticos para Memorizar

```bash
# kubeadm init bÃ¡sico
sudo kubeadm init --pod-network-cidr=192.168.0.0/16

# kubeadm con config file
sudo kubeadm init --config kubeadm-config.yaml

# Reset cluster
sudo kubeadm reset -f

# Verificar certificados
sudo kubeadm certs check-expiration

# Renovar certificados
sudo kubeadm certs renew all

# Ver configuraciÃ³n de kubeadm
kubectl get cm -n kube-system kubeadm-config -o yaml

# Configurar kubectl
export KUBECONFIG=/etc/kubernetes/admin.conf
```

### Tiempo Estimado en Examen

- **kubeadm init**: ~3-4 minutos
- **Configurar kubectl**: ~30 segundos
- **Instalar CNI**: ~1 minuto
- **VerificaciÃ³n**: ~1 minuto
- **Total**: ~6 minutos (de 120 minutos totales del examen)

## ğŸ§¹ Limpieza

Para limpiar completamente el laboratorio:

```bash
# Usar script de cleanup
./cleanup.sh

# O manual:
# 1. Eliminar namespace de prueba
kubectl delete namespace test-cluster --ignore-not-found

# 2. Reset kubeadm
sudo kubeadm reset -f

# 3. Limpiar directorios
sudo rm -rf /etc/kubernetes
sudo rm -rf /var/lib/kubelet
sudo rm -rf /var/lib/etcd
sudo rm -rf $HOME/.kube

# 4. Limpiar iptables
sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F && sudo iptables -X

# 5. Reiniciar servicios
sudo systemctl restart containerd
sudo systemctl restart kubelet
```

## ğŸ“– Referencias

- [kubeadm Official Documentation](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/)
- [kubeadm Configuration API](https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/)
- [Installing Calico](https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart)
- [Container Runtime](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
- [PKI certificates and requirements](https://kubernetes.io/docs/setup/best-practices/certificates/)

## âœ… VerificaciÃ³n de Conocimientos

- [ ] Entiendes el flujo completo de `kubeadm init`
- [ ] Puedes configurar prerequisitos del sistema (swap, mÃ³dulos, sysctl)
- [ ] Sabes instalar y configurar containerd
- [ ] Puedes crear un archivo de configuraciÃ³n de kubeadm personalizado
- [ ] Entiendes la estructura de directorios de `/etc/kubernetes`
- [ ] Sabes instalar y verificar un CNI plugin (Calico)
- [ ] Puedes troubleshoot problemas comunes de inicializaciÃ³n
- [ ] Sabes verificar la salud del cluster y componentes
- [ ] Entiendes la importancia de backup de certificados
- [ ] Puedes completar `kubeadm init` en menos de 5 minutos (CKA)

---

**PrÃ³ximo Lab**: [Lab 02 - Worker Node Join](../lab-02-worker-node-join/README.md)
