# Lab 01: Setup de Cluster Kubernetes BÃ¡sico con kubeadm

**DuraciÃ³n estimada:** 45-60 minutos  
**Dificultad:** â­â­ Intermedio

## ğŸ¯ Objetivos

Al completar este laboratorio, serÃ¡s capaz de:
- âœ… Instalar y configurar prerequisites para Kubernetes
- âœ… Inicializar un control plane con kubeadm
- âœ… Configurar networking con Calico CNI
- âœ… Agregar worker nodes al cluster
- âœ… Verificar el estado del cluster

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         k8s-master-01                    â”‚
â”‚       192.168.1.10                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Control Plane Components:       â”‚   â”‚
â”‚  â”‚  - API Server (6443)            â”‚   â”‚
â”‚  â”‚  - Controller Manager           â”‚   â”‚
â”‚  â”‚  - Scheduler                    â”‚   â”‚
â”‚  â”‚  - etcd                         â”‚   â”‚
â”‚  â”‚  - kubelet + containerd         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |                   |
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ k8s-worker-01 â”‚   â”‚ k8s-worker-02 â”‚
â”‚ 192.168.1.20  â”‚   â”‚ 192.168.1.21  â”‚
â”‚               â”‚   â”‚               â”‚
â”‚ - kubelet     â”‚   â”‚ - kubelet     â”‚
â”‚ - kube-proxy  â”‚   â”‚ - kube-proxy  â”‚
â”‚ - containerd  â”‚   â”‚ - containerd  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

### Hardware
- **Control Plane**: 2 CPU, 2GB RAM, 20GB disk
- **Workers**: 1 CPU, 1GB RAM, 20GB disk (mÃ­nimo)

### Software
- Ubuntu 20.04+ o 22.04 LTS (recomendado)
- Acceso root (sudo)
- Conectividad de red entre nodos

### PreparaciÃ³n
```bash
# En TODOS los nodos: Configurar hostnames y /etc/hosts
sudo hostnamectl set-hostname k8s-master-01  # En master
sudo hostnamectl set-hostname k8s-worker-01  # En worker-01
sudo hostnamectl set-hostname k8s-worker-02  # En worker-02

# Agregar entradas en /etc/hosts (todos los nodos)
sudo tee -a /etc/hosts <<EOF
192.168.1.10 k8s-master-01
192.168.1.20 k8s-worker-01
192.168.1.21 k8s-worker-02
EOF

# Verificar conectividad
ping -c 3 k8s-master-01
ping -c 3 k8s-worker-01
ping -c 3 k8s-worker-02
```

---

## ğŸš€ Paso 1: Instalar Prerequisites (TODOS los nodos)

### 1.1 Usar Script de InstalaciÃ³n

```bash
# Descargar o copiar el script install-prerequisites.sh
# Ver: ../scripts/install-prerequisites.sh

# Hacer ejecutable
chmod +x install-prerequisites.sh

# Ejecutar con sudo
sudo ./install-prerequisites.sh
```

El script realizarÃ¡:
- âœ… Deshabilitar swap
- âœ… Configurar mÃ³dulos del kernel (overlay, br_netfilter)
- âœ… Configurar sysctl (ip_forward, bridge-nf-call)
- âœ… Instalar containerd
- âœ… Configurar systemd cgroup driver
- âœ… Instalar kubeadm, kubelet, kubectl

### 1.2 Verificar InstalaciÃ³n

```bash
# Verificar versiones instaladas
kubeadm version
kubelet --version
kubectl version --client

# Verificar containerd
sudo systemctl status containerd

# Verificar que swap estÃ¡ deshabilitado
free -h  # Swap debe mostrar 0

# Verificar mÃ³dulos del kernel
lsmod | grep br_netfilter
lsmod | grep overlay
```

**âœ… Checkpoint**: Todos los comandos deben ejecutarse sin errores.

---

## ğŸ® Paso 2: Inicializar Control Plane (SOLO MASTER)

### 2.1 Ejecutar kubeadm init

```bash
# En k8s-master-01
sudo kubeadm init \
  --pod-network-cidr=192.168.0.0/16 \
  --apiserver-advertise-address=192.168.1.10 \
  --control-plane-endpoint=k8s-master-01:6443

# O usar configuraciÃ³n personalizada
sudo kubeadm init --config ../ejemplos/kubeadm-config.yaml
```

**âš ï¸ IMPORTANTE**: Guardar el output completo, especialmente:
```
kubeadm join k8s-master-01:6443 --token abcdef.0123456789abcdef \
  --discovery-token-ca-cert-hash sha256:1234567890abcdef...
```

### 2.2 Configurar kubeconfig

```bash
# Configurar acceso para usuario normal
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Verificar acceso al cluster
kubectl cluster-info
kubectl get nodes
```

**Salida esperada:**
```
NAME            STATUS     ROLES           AGE   VERSION
k8s-master-01   NotReady   control-plane   30s   v1.28.0
```

**NotReady** es normal, falta instalar CNI plugin.

### 2.3 Verificar Componentes del Control Plane

```bash
# Ver pods del sistema
kubectl get pods -n kube-system

# Verificar componentes especÃ­ficos
kubectl get pods -n kube-system -l component=kube-apiserver
kubectl get pods -n kube-system -l component=kube-controller-manager
kubectl get pods -n kube-system -l component=kube-scheduler
kubectl get pods -n kube-system -l component=etcd
```

**âœ… Checkpoint**: Todos los pods deben estar Running.

---

## ğŸŒ Paso 3: Instalar CNI Plugin - Calico (SOLO MASTER)

### 3.1 Aplicar Manifesto de Calico

```bash
# OpciÃ³n A: Calico por defecto
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# OpciÃ³n B: Calico personalizado
kubectl apply -f ../ejemplos/calico-custom.yaml
```

### 3.2 Verificar InstalaciÃ³n de Calico

```bash
# Ver pods de Calico iniciando
kubectl get pods -n kube-system -w

# Verificar DaemonSet
kubectl get daemonset -n kube-system calico-node

# Verificar deployment
kubectl get deployment -n kube-system calico-kube-controllers

# Esperar hasta que todos estÃ©n Running (2-3 minutos)
watch kubectl get pods -n kube-system
```

### 3.3 Verificar Nodo Ready

```bash
# El nodo debe pasar a Ready despuÃ©s de CNI
kubectl get nodes

# Salida esperada:
# NAME            STATUS   ROLES           AGE   VERSION
# k8s-master-01   Ready    control-plane   5m    v1.28.0
```

**âœ… Checkpoint**: Nodo master en estado **Ready**.

---

## ğŸ‘· Paso 4: Agregar Worker Nodes

### 4.1 Obtener Join Command (En Master)

Si perdiste el join command original:

```bash
# Generar nuevo token
kubeadm token create --print-join-command

# Salida:
# kubeadm join k8s-master-01:6443 --token abc123.xyz456 \
#   --discovery-token-ca-cert-hash sha256:789abc...
```

### 4.2 Ejecutar Join en Workers

```bash
# En k8s-worker-01 y k8s-worker-02
sudo kubeadm join k8s-master-01:6443 \
  --token abc123.xyz456 \
  --discovery-token-ca-cert-hash sha256:789abc...
```

**Salida esperada:**
```
[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[kubelet-start] Writing kubelet configuration to file
[kubelet-start] Starting the kubelet
This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.
```

### 4.3 Verificar Workers en el Cluster (En Master)

```bash
# Ver todos los nodos
kubectl get nodes

# Ver detalles de nodos
kubectl get nodes -o wide

# Ver labels de nodos
kubectl get nodes --show-labels
```

**Salida esperada:**
```
NAME            STATUS   ROLES           AGE     VERSION
k8s-master-01   Ready    control-plane   10m     v1.28.0
k8s-worker-01   Ready    <none>          2m      v1.28.0
k8s-worker-02   Ready    <none>          1m      v1.28.0
```

**âœ… Checkpoint**: 3 nodos en estado **Ready**.

---

## ğŸ§ª Paso 5: VerificaciÃ³n y Testing

### 5.1 Test de Conectividad de Red

```bash
# Crear deployment de prueba
kubectl create deployment nginx --image=nginx --replicas=3

# Verificar pods distribuidos en workers
kubectl get pods -o wide

# Exponer servicio
kubectl expose deployment nginx --port=80 --type=NodePort

# Obtener NodePort asignado
kubectl get svc nginx

# Probar acceso
curl http://k8s-worker-01:<NODE_PORT>
curl http://k8s-worker-02:<NODE_PORT>
```

### 5.2 Test de DNS

```bash
# Crear pod de prueba
kubectl run test-pod --image=busybox --restart=Never -- sleep 3600

# Probar DNS interno
kubectl exec test-pod -- nslookup kubernetes.default
kubectl exec test-pod -- nslookup nginx

# Probar DNS externo
kubectl exec test-pod -- nslookup google.com
```

### 5.3 Verificar Logs

```bash
# Logs del API server
kubectl logs -n kube-system -l component=kube-apiserver

# Logs de kubelet (en cualquier nodo)
sudo journalctl -u kubelet -f

# Logs de containerd
sudo journalctl -u containerd -f
```

### 5.4 Cluster Info

```bash
# InformaciÃ³n del cluster
kubectl cluster-info

# Dump completo (para debugging)
kubectl cluster-info dump > cluster-dump.txt

# Versiones de componentes
kubectl version
kubectl get nodes -o yaml | grep kubelet
```

---

## ğŸ“Š Paso 6: Validaciones Finales

### Checklist de ValidaciÃ³n

Ejecuta cada comando y verifica:

```bash
# âœ… 1. Todos los nodos Ready
kubectl get nodes
# Esperado: 3 nodos, STATUS=Ready

# âœ… 2. Todos los pods del sistema Running
kubectl get pods -n kube-system
# Esperado: No pods en Error o CrashLoopBackOff

# âœ… 3. Componentes del control plane saludables
kubectl get componentstatuses  # Deprecated en 1.28+
kubectl get --raw='/readyz?verbose'
# Esperado: [+]ping ok, [+]etcd ok, etc.

# âœ… 4. Endpoints del API server
kubectl get endpoints -n default kubernetes
# Esperado: IP del master en ENDPOINTS

# âœ… 5. DNS funcionando
kubectl run dns-test --image=busybox --restart=Never --rm -it -- nslookup kubernetes.default
# Esperado: ResoluciÃ³n exitosa

# âœ… 6. Calico funcionando
kubectl get pods -n kube-system -l k8s-app=calico-node
# Esperado: 3 pods (1 por nodo), STATUS=Running

# âœ… 7. Workloads pueden ejecutarse
kubectl run test-nginx --image=nginx --port=80
kubectl expose pod test-nginx --type=NodePort
kubectl get svc test-nginx
curl http://<NODE_IP>:<NODE_PORT>
# Esperado: PÃ¡gina de bienvenida de nginx

# Limpieza de test
kubectl delete pod test-nginx
kubectl delete svc test-nginx
```

---

## ğŸ“ DesafÃ­os Opcionales

### DesafÃ­o 1: Etiquetar Workers
```bash
# Agregar labels a workers
kubectl label node k8s-worker-01 node-role.kubernetes.io/worker=worker
kubectl label node k8s-worker-02 node-role.kubernetes.io/worker=worker

# Verificar
kubectl get nodes
```

### DesafÃ­o 2: Configurar Autocompletion
```bash
# Bash completion para kubectl
echo 'source <(kubectl completion bash)' >>~/.bashrc
echo 'alias k=kubectl' >>~/.bashrc
echo 'complete -o default -F __start_kubectl k' >>~/.bashrc
source ~/.bashrc

# Probar
k get no<TAB>  # Autocompleta a 'nodes'
```

### DesafÃ­o 3: Instalar Metrics Server
```bash
# Instalar metrics-server
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Verificar
kubectl top nodes
kubectl top pods -A
```

---

## ğŸ§¹ Limpieza (Opcional)

Si necesitas destruir el cluster:

```bash
# En CADA worker
sudo kubeadm reset -f
sudo rm -rf /etc/cni/net.d
sudo rm -rf $HOME/.kube

# En el master
sudo kubeadm reset -f
sudo rm -rf /etc/cni/net.d
sudo rm -rf $HOME/.kube
sudo rm -rf /var/lib/etcd

# En TODOS los nodos (opcional, limpiar iptables)
sudo iptables -F && sudo iptables -t nat -F && sudo iptables -t mangle -F && sudo iptables -X
```

---

## ğŸ› Troubleshooting

### Problema: Nodo en NotReady

```bash
# Verificar kubelet
sudo systemctl status kubelet
sudo journalctl -u kubelet -f

# ComÃºn: CNI plugin no instalado
kubectl get pods -n kube-system | grep calico
```

### Problema: Pods en Pending

```bash
# Ver eventos
kubectl describe pod <pod-name>

# ComÃºn: Taint en master impide scheduling
kubectl describe node k8s-master-01 | grep Taint
```

### Problema: Error "swap is enabled"

```bash
# Deshabilitar swap
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab
```

### Problema: Token expirado

```bash
# Generar nuevo token (en master)
kubeadm token create --print-join-command
```

---

## ğŸ“š Recursos Adicionales

- [kubeadm init documentation](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/)
- [Calico Installation](https://docs.projectcalico.org/getting-started/kubernetes/)
- [Troubleshooting kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/)

---

## âœ… Criterios de Completitud

Has completado exitosamente este lab si:
- [ ] 3 nodos en estado Ready (1 master + 2 workers)
- [ ] Todos los pods kube-system en Running
- [ ] DNS resuelve correctamente
- [ ] Pods pueden ejecutarse en workers
- [ ] Networking funciona entre pods
- [ ] kubectl funciona sin sudo

**Â¡Felicitaciones!** ğŸ‰ Tienes un cluster Kubernetes funcional.

**PrÃ³ximo paso:** [Lab 02: Multi-Node Production Cluster](./lab-02-multi-node-cluster.md)
